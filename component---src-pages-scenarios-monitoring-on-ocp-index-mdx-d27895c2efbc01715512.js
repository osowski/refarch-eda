(window.webpackJsonp=window.webpackJsonp||[]).push([[37],{WBpb:function(e,t,a){"use strict";a.r(t),a.d(t,"_frontmatter",(function(){return l})),a.d(t,"default",(function(){return h}));var n=a("wx14"),i=a("zLVn"),r=(a("q1tI"),a("7ljp")),o=a("013z"),l=(a("qKvR"),{}),s=function(e){return function(t){return console.warn("Component '"+e+"' was not imported, exported, or provided by MDXProvider as global scope"),Object(r.b)("div",t)}},c=s("AnchorLinks"),b=s("AnchorLink"),p=s("InlineNotification"),m={_frontmatter:l},u=o.a;function h(e){var t=e.components,a=Object(i.a)(e,["components"]);return Object(r.b)(u,Object(n.a)({},m,a,{components:t,mdxType:"MDXLayout"}),Object(r.b)(c,{mdxType:"AnchorLinks"},Object(r.b)(b,{mdxType:"AnchorLink"},"Overview"),Object(r.b)(b,{mdxType:"AnchorLink"},"Scenario Prereqs"),Object(r.b)(b,{mdxType:"AnchorLink"},"Generate Event Load"),Object(r.b)(b,{mdxType:"AnchorLink"},"Explore the preconfigured Event Streams Dashboard"),Object(r.b)(b,{mdxType:"AnchorLink"},"Import Grafana Dashboards"),Object(r.b)(b,{mdxType:"AnchorLink"},"View Grafana Dashboards"),Object(r.b)(b,{mdxType:"AnchorLink"},"Create an Alert"),Object(r.b)(b,{mdxType:"AnchorLink"},"External Monitoring Tools"),Object(r.b)(b,{mdxType:"AnchorLink"},"Advanced Scenarios"),Object(r.b)(b,{mdxType:"AnchorLink"},"Additional Reading")),Object(r.b)(p,{kind:"warning",mdxType:"InlineNotification"},Object(r.b)("strong",null,"TODO")," - needs screenshots"),Object(r.b)("h2",null,"Overview"),Object(r.b)("p",null,"Deploying IBM Event Streams on OpenShift Cloud Platform (OCP) as the Apache Kafka-based event backbone is a great first step in your Event-Driven Architecture implementation. However, now you must maintain that Kafka cluster and understand the intricate details of what a ",Object(r.b)("em",{parentName:"p"},"“healthy”")," cluster looks like. This tutorial will walk you through some of the initial monitoring scenarios that are available for IBM Event Streams deployed on OCP."),Object(r.b)("p",null,"The raw monitoring use cases and capabilities are available from the official IBM Event Streams documentation via the links below:"),Object(r.b)("ul",null,Object(r.b)("li",{parentName:"ul"},Object(r.b)("a",Object(n.a)({parentName:"li"},{href:"https://ibm.github.io/event-streams/administering/deployment-health/"}),"Monitoring deployment health")),Object(r.b)("li",{parentName:"ul"},Object(r.b)("a",Object(n.a)({parentName:"li"},{href:"https://ibm.github.io/event-streams/administering/cluster-health/"}),"Monitoring Kafka cluster health")),Object(r.b)("li",{parentName:"ul"},Object(r.b)("a",Object(n.a)({parentName:"li"},{href:"https://ibm.github.io/event-streams/administering/topic-health/"}),"Monitoring topic health")),Object(r.b)("li",{parentName:"ul"},Object(r.b)("a",Object(n.a)({parentName:"li"},{href:"https://ibm.github.io/event-streams/administering/consumer-lag/"}),"Monitoring Kafka consumer group lag"))),Object(r.b)("p",null,"This tutorial will focus on a more guided approach to understanding the foundation of Apache Kafka monitoring capabilities provided by IBM Event Streams and the IBM Cloud Pak for Integration. Upon completion of this tutorial, you can extend your own experience through the ",Object(r.b)("a",Object(n.a)({parentName:"p"},{href:"#advanced-scenarios"}),"Advanced Scenarios")," section to adapt Kafka monitoring capabilites to your project’s needs."),Object(r.b)("h2",null,"Scenario Prereqs"),Object(r.b)("p",null,Object(r.b)("strong",{parentName:"p"},"OpenShift Container Platform")),Object(r.b)("ul",null,Object(r.b)("li",{parentName:"ul"},"This deployment scenario was developed for use on the OpenShift Container Platform, with a minimum version of ",Object(r.b)("inlineCode",{parentName:"li"},"4.4"),".")),Object(r.b)("p",null,Object(r.b)("strong",{parentName:"p"},"Cloud Pak for Integration")),Object(r.b)("ul",null,Object(r.b)("li",{parentName:"ul"},"This deployment scenario was developed for use with the 2020.2.x release of the Cloud Pak for Integration, installed on OpenShift 4.4.")),Object(r.b)("p",null,Object(r.b)("strong",{parentName:"p"},"IBM Event Streams")),Object(r.b)("ul",null,Object(r.b)("li",{parentName:"ul"},"This deployment scenario requires a working installation of ",Object(r.b)("a",Object(n.a)({parentName:"li"},{href:"https://ibm.github.io/event-streams/"}),"IBM Event Streams V10.0")," or greater, deployed on the Cloud Pak for Integration environment mentioned above."),Object(r.b)("li",{parentName:"ul"},"For Cloud Pak installation guidance, you can follow the ",Object(r.b)("a",Object(n.a)({parentName:"li"},{href:"https://cloudpak8s.io/integration/cp4i-deploy-eventstreams/"}),"Cloud Pak Playbook")," installation instructions.")),Object(r.b)("p",null,Object(r.b)("strong",{parentName:"p"},"Git")),Object(r.b)("ul",null,Object(r.b)("li",{parentName:"ul"},"We will need to clone repositories.")),Object(r.b)("p",null,Object(r.b)("strong",{parentName:"p"},"Java")),Object(r.b)("ul",null,Object(r.b)("li",{parentName:"ul"},"Java Development Kit (JDK) v1.8+ (Java 8+)")),Object(r.b)("p",null,Object(r.b)("strong",{parentName:"p"},"Maven")),Object(r.b)("ul",null,Object(r.b)("li",{parentName:"ul"},"The scenario uses Maven v3.6.x")),Object(r.b)("h2",null,"Generate Event Load"),Object(r.b)("p",null,"This section details walking through the generation of a starter application for usage with IBM Event Streams, as documented in the ",Object(r.b)("a",Object(n.a)({parentName:"p"},{href:"https://ibm.github.io/event-streams/getting-started/generating-starter-app/"}),"official product documentation"),"."),Object(r.b)("ul",null,Object(r.b)("li",{parentName:"ul"},Object(r.b)("p",{parentName:"li"},"Access the Event Streams Dashboard via ",Object(r.b)("inlineCode",{parentName:"p"},"https://es-1-ibm-es-ui-integration.apps.[cluster-name]")," and login.")),Object(r.b)("li",{parentName:"ul"},Object(r.b)("p",{parentName:"li"},"Click the ",Object(r.b)("strong",{parentName:"p"},"Try the starter application")," button from the ",Object(r.b)("em",{parentName:"p"},"Getting Started")," page")),Object(r.b)("li",{parentName:"ul"},Object(r.b)("p",{parentName:"li"},"Click ",Object(r.b)("strong",{parentName:"p"},"Download JAR from GitHub"),". This will open a new window to ",Object(r.b)("inlineCode",{parentName:"p"},"https://github.com/ibm-messaging/kafka-java-vertx-starter/releases")),Object(r.b)("ul",{parentName:"li"},Object(r.b)("li",{parentName:"ul"},"Click the link for ",Object(r.b)("inlineCode",{parentName:"li"},"demo-all.jar")," from the latest release available. At the time of this writing, the latest version was ",Object(r.b)("inlineCode",{parentName:"li"},"1.0.0"),"."))),Object(r.b)("li",{parentName:"ul"},Object(r.b)("p",{parentName:"li"},"Return to the Event Streams console and click ",Object(r.b)("strong",{parentName:"p"},"Generate properties"),".")),Object(r.b)("li",{parentName:"ul"},Object(r.b)("p",{parentName:"li"},"In dialog that pops up from the right-hand side of the screen, enter the following information:"),Object(r.b)("ul",{parentName:"li"},Object(r.b)("li",{parentName:"ul"},Object(r.b)("strong",{parentName:"li"},"Starter application name:")," ",Object(r.b)("inlineCode",{parentName:"li"},"monitoring-lab-[your-initials]")),Object(r.b)("li",{parentName:"ul"},"Leave ",Object(r.b)("strong",{parentName:"li"},"New topic")," selected and enter a ",Object(r.b)("strong",{parentName:"li"},"Topic name")," of ",Object(r.b)("inlineCode",{parentName:"li"},"monitoring-lab-topic-[your-initials]"),"."),Object(r.b)("li",{parentName:"ul"},"Click ",Object(r.b)("strong",{parentName:"li"},"Generate and download .zip")))),Object(r.b)("li",{parentName:"ul"},Object(r.b)("p",{parentName:"li"},"In a Terminal window, unzip the generated ZIP file from the previous window to the same directory with the ",Object(r.b)("inlineCode",{parentName:"p"},"demo-all.jar")," file.")),Object(r.b)("li",{parentName:"ul"},Object(r.b)("p",{parentName:"li"},"Review the extracted ",Object(r.b)("inlineCode",{parentName:"p"},"kafka.properties")," to understand how Event Streams has generated credentials and configuration information for this sample application to connect.")),Object(r.b)("li",{parentName:"ul"},Object(r.b)("p",{parentName:"li"},"Run the command ",Object(r.b)("inlineCode",{parentName:"p"},"java -Dproperties_path=./kafka.properties -jar demo-all.jar"),".")),Object(r.b)("li",{parentName:"ul"},Object(r.b)("p",{parentName:"li"},"Wait until you see the string ",Object(r.b)("inlineCode",{parentName:"p"},"Application started in X ms")," in the output and then visit the application’s user interface via ",Object(r.b)("inlineCode",{parentName:"p"},"http://localhost:8080"),".")),Object(r.b)("li",{parentName:"ul"},Object(r.b)("p",{parentName:"li"},"Once in the User Interface, enter a message to be contained for the Kafka record value then click ",Object(r.b)("strong",{parentName:"p"},"Start producing"),".")),Object(r.b)("li",{parentName:"ul"},Object(r.b)("p",{parentName:"li"},"Wait a few moments until the UI updates to show some of the confirmed produced messages and offsets, then click on ",Object(r.b)("strong",{parentName:"p"},"Start consuming")," on the right side of the application.")),Object(r.b)("li",{parentName:"ul"},Object(r.b)("p",{parentName:"li"},"You can let the application continue running while you continue with the rest of this lab."),Object(r.b)("ul",{parentName:"li"},Object(r.b)("li",{parentName:"ul"},"If you would like to stop the application from producing, you can click ",Object(r.b)("strong",{parentName:"li"},"Stop producing"),"."),Object(r.b)("li",{parentName:"ul"},"If you would like to stop the application from consuming, you can click ",Object(r.b)("strong",{parentName:"li"},"Stop consuming"),"."),Object(r.b)("li",{parentName:"ul"},"If you would like to stop the application entirely, you can input ",Object(r.b)("inlineCode",{parentName:"li"},"Control+C")," in the Terminal session where the application is running.")))),Object(r.b)("p",null,"An ",Object(r.b)("a",Object(n.a)({parentName:"p"},{href:"https://ibm.github.io/event-streams/getting-started/testing-loads/"}),"alternative sample application")," can be leveraged from the official documentation to generate higher amounts of load."),Object(r.b)("h2",null,"Explore the preconfigured Event Streams Dashboard"),Object(r.b)("p",null,"This section will walk through the default dashboard and user interface available on every IBM Event Streams deployment."),Object(r.b)("ul",null,Object(r.b)("li",{parentName:"ul"},"Access the Event Streams Dashboard via ",Object(r.b)("inlineCode",{parentName:"li"},"https://es-1-ibm-es-ui-integration.apps.[cluster-name]")," and login."),Object(r.b)("li",{parentName:"ul"},"Click the ",Object(r.b)("strong",{parentName:"li"},"Monitoring")," tab from the primary navigation menu."),Object(r.b)("li",{parentName:"ul"},"From here, you can view information on messages, partitions, and replicas for the past hour, day, week, or month."),Object(r.b)("li",{parentName:"ul"},"Click the ",Object(r.b)("strong",{parentName:"li"},"Topics")," tab from the primary navigation menu."),Object(r.b)("li",{parentName:"ul"},"Click the name of your topic that you previously created in the ",Object(r.b)("a",Object(n.a)({parentName:"li"},{href:"#generate-event-load"}),"Generate Event Load")," section. This should be in the format of ",Object(r.b)("inlineCode",{parentName:"li"},"monitoring-lab-topic-[your-initials]"),"."),Object(r.b)("li",{parentName:"ul"},"You are presented with a ",Object(r.b)("strong",{parentName:"li"},"Producers")," page showing the number of active producers, as well as the average message size produced per second and average number of messages produced per second. You can modify the time window by changing the values in the ",Object(r.b)("em",{parentName:"li"},"View producers by time")," box."),Object(r.b)("li",{parentName:"ul"},"Click the ",Object(r.b)("strong",{parentName:"li"},"Messages")," tab to view all the data and metadata for events stored in the topic."),Object(r.b)("li",{parentName:"ul"},"You can view messages across partitions or on specific partitions, as well as jump to specific offsets or timestamps."),Object(r.b)("li",{parentName:"ul"},"Click ",Object(r.b)("strong",{parentName:"li"},"Consumer Groups")," to be shown the number of consumer groups that have previously registered or are currently registered as consuming from the topic."),Object(r.b)("li",{parentName:"ul"},"You are able to see how many active members a consumer group has, as well as have many unconsumed partitions a topic has inside of a consumer group (also known as ",Object(r.b)("em",{parentName:"li"},"consumer group lag"),")- a key metric for driving parallelism in event-driven microservices!")),Object(r.b)("h2",null,"Import Grafana Dashboards"),Object(r.b)("p",null,"This section will walk through the Grafana Dashboard capabilities documented in the ",Object(r.b)("a",Object(n.a)({parentName:"p"},{href:"https://ibm.github.io/event-streams/administering/cluster-health/#grafana"}),"official IBM Event Streams documentation"),"."),Object(r.b)("ol",null,Object(r.b)("li",{parentName:"ol"},"Apply the Grafana Dashboard for overall Kafka Health via a ",Object(r.b)("inlineCode",{parentName:"li"},"MonitoringDashboard")," custom resource:")),Object(r.b)("pre",null,Object(r.b)("code",Object(n.a)({parentName:"pre"},{className:"language-bash"}),"oc apply -f https://raw.githubusercontent.com/ibm-messaging/event-streams-operator-resources/master/grafana-dashboards/ibm-eventstreams-kafka-health-dashboard.yaml\n")),Object(r.b)("h2",null,"View Grafana Dashboards"),Object(r.b)("p",null,"To view the newly imported Event Streams Grafana dashboard for overall Kafka Health, follow these steps:"),Object(r.b)("ul",null,Object(r.b)("li",{parentName:"ul"},"Navigate to the IBM Cloud Platform Common Services console homepage via ",Object(r.b)("inlineCode",{parentName:"li"},"https://cp-console.apps.[cluster-name]")),Object(r.b)("li",{parentName:"ul"},"Click the hamburger icon in the top left."),Object(r.b)("li",{parentName:"ul"},"Expand ",Object(r.b)("strong",{parentName:"li"},"Monitor Health"),"."),Object(r.b)("li",{parentName:"ul"},"Click the ",Object(r.b)("strong",{parentName:"li"},"Monitoring")," in the expanded menu to open the Grafana homepage."),Object(r.b)("li",{parentName:"ul"},"Click the user icon in the bottom left corner to open the user profile page."),Object(r.b)("li",{parentName:"ul"},"In the ",Object(r.b)("strong",{parentName:"li"},"Organizations")," table, find the namespace where you installed the Event Streams ",Object(r.b)("inlineCode",{parentName:"li"},"monitoringdashboard")," custom resource, and switch the user profile to that namespace."),Object(r.b)("li",{parentName:"ul"},"Hover over the ",Object(r.b)("em",{parentName:"li"},"Dashboards")," square on the left and click ",Object(r.b)("strong",{parentName:"li"},"Manage"),"."),Object(r.b)("li",{parentName:"ul"},"Click on ",Object(r.b)("strong",{parentName:"li"},"IBM Event Streams Kafka")," dashboard in the Dashboard table to view the newly imported resource."),Object(r.b)("li",{parentName:"ul"},"Using the drop-down selectors at the top, select the following:",Object(r.b)("ul",{parentName:"li"},Object(r.b)("li",{parentName:"ul"},Object(r.b)("strong",{parentName:"li"},"Namespace")," which has the running instance of your Event Streams deployment,"),Object(r.b)("li",{parentName:"ul"},Object(r.b)("strong",{parentName:"li"},"Cluster Name")," for the desired Event Streams cluster"),Object(r.b)("li",{parentName:"ul"},Object(r.b)("strong",{parentName:"li"},"Topic")," that matches desired topics for viewing ",Object(r.b)("em",{parentName:"li"},"(only topics that have been published to will appear in this list)")),Object(r.b)("li",{parentName:"ul"},Object(r.b)("strong",{parentName:"li"},"Broker")," to select individual or multiple brokers in the cluster.")))),Object(r.b)("h2",null,"Create an Alert"),Object(r.b)(p,{kind:"warning",mdxType:"InlineNotification"},Object(r.b)("strong",null,"TODO")," - Create Alert of some signifigance"),Object(r.b)("ul",null,Object(r.b)("li",{parentName:"ul"},Object(r.b)("a",Object(n.a)({parentName:"li"},{href:"https://ibm.github.io/event-streams/tutorials/monitoring-alerts/#selecting-the-metric-to-monitor"}),"https://ibm.github.io/event-streams/tutorials/monitoring-alerts/#selecting-the-metric-to-monitor")),Object(r.b)("li",{parentName:"ul"},Object(r.b)("a",Object(n.a)({parentName:"li"},{href:"https://cp-console.apps.eda-solutions.gse-ocp.net/prometheus/api/v1/label/__name__/values"}),"https://cp-console.apps.eda-solutions.gse-ocp.net/prometheus/api/v1/label/__name__/values")),Object(r.b)("li",{parentName:"ul"},Object(r.b)("a",Object(n.a)({parentName:"li"},{href:"https://cp-console.apps.eda-solutions.gse-ocp.net/prometheus/graph"}),"https://cp-console.apps.eda-solutions.gse-ocp.net/prometheus/graph")),Object(r.b)("li",{parentName:"ul"},Object(r.b)("a",Object(n.a)({parentName:"li"},{href:"https://cp-console.apps.eda-solutions.gse-ocp.net/alertmanager/#/alerts"}),"https://cp-console.apps.eda-solutions.gse-ocp.net/alertmanager/#/alerts"))),Object(r.b)("pre",null,Object(r.b)("code",Object(n.a)({parentName:"pre"},{}),"For example, to test the triggering of alerts, you can monitor the total number of partitions for all topics by using the kafka_server_replicamanager_partitioncount_value metric. When topics are created, this metric can trigger notifications.\n\nFor production environments, a good metric to monitor is the number of under-replicated partitions as it tells you about potential problems with your Kafka cluster, such as load or network problems where the cluster becomes overloaded and followers are not able to catch up on leaders. Under-replicated partitions might be a temporary problem, but if it continues for longer, it probably requires urgent attention. An example is to set up a notification trigger to your Slack channel if the number of under-replicated partitions is greater than 0 for more than a minute. You can do this with the kafka_server_replicamanager_underreplicatedpartitions_value metric.\n")),Object(r.b)("p",null,Object(r.b)("strong",{parentName:"p"},"Note:")," Not all of the metrics that Kafka uses are published to Prometheus by default. The metrics that are published are controlled by a ConfigMap. You can publish metrics by adding them to the ConfigMap."),Object(r.b)("h2",null,"Next Steps"),Object(r.b)("h3",null,"External Monitoring Tools"),Object(r.b)("p",null,"IBM Event Streams supports additional monitoring capabilities with third-party monitoring tools via a connection to the clusters JMX port on the Kafka brokers."),Object(r.b)("p",null,"You must first ",Object(r.b)("a",Object(n.a)({parentName:"p"},{href:"https://ibm.github.io/event-streams/installing/configuring/#configuring-external-monitoring-through-jmx"}),"configure")," your IBM Event Streams instance for specific access by these external monitoring tools."),Object(r.b)("p",null,"You can then follow along with the ",Object(r.b)("a",Object(n.a)({parentName:"p"},{href:"https://ibm.github.io/event-streams/tutorials/"}),"tutorials")," defined in the official IBM Event Streams documentation to monitor Event Streams with tools such as Datadog and Splunk."),Object(r.b)("h3",null,"Advanced Scenarios"),Object(r.b)("p",null,"As shown in this tutorial, IBM Event Streams provides a robust default set of monitoring metrics which are available to use right out of the box. However, you will most likely need to define custom metrics or extend existing metrics for use in custom dashboards or reporting processes. The following links ",Object(r.b)("em",{parentName:"p"},"(in order of recommended usage)")," discuss additional monitoring capabilities, technologies, and endpoints that are supported with IBM Event Streams to extend your custom monitoring solution as needed:"),Object(r.b)("ul",null,Object(r.b)("li",{parentName:"ul"},Object(r.b)("p",{parentName:"li"},Object(r.b)("a",Object(n.a)({parentName:"p"},{href:"https://ibm.github.io/event-streams/installing/configuring/#configuring-the-kafka-exporter"}),Object(r.b)("strong",{parentName:"a"},"Kafka Exporter"))," - You can use Event Streams to export metrics to Prometheus. These metrics are otherwise only accessible through the Kafka command line tools and allow per-topic metrics, such as consumer group lag, to be colleced.")),Object(r.b)("li",{parentName:"ul"},Object(r.b)("p",{parentName:"li"},Object(r.b)("a",Object(n.a)({parentName:"p"},{href:"https://ibm.github.io/event-streams/installing/configuring#configuring-the-jmx-exporter"}),Object(r.b)("strong",{parentName:"a"},"JMX Exporter"))," - You can use Event Streams to collect JMX metrics from Kafka brokers, ZooKeeper nodes, and Kafka Connect nodes, and export them to Prometheus via the ",Object(r.b)("a",Object(n.a)({parentName:"p"},{href:"https://github.com/prometheus/jmx_exporter"}),"Prometheus JMX Exporter"),".")),Object(r.b)("li",{parentName:"ul"},Object(r.b)("p",{parentName:"li"},Object(r.b)("a",Object(n.a)({parentName:"p"},{href:"https://ibm.github.io/event-streams/security/secure-jmx-connections/#configuring-a-jmxtrans-deployment"}),Object(r.b)("strong",{parentName:"a"},"JmxTrans"))," - JmxTrans can be used to push JMX metrics from Kafka brokers to external applications or databases."))),Object(r.b)("h3",null,"Additional Reading"),Object(r.b)("ul",null,Object(r.b)("li",{parentName:"ul"},Object(r.b)("a",Object(n.a)({parentName:"li"},{href:"https://kafka.apache.org/documentation/#monitoring"}),"Monitoring Kafka")," via official Apache Kafka documentation"),Object(r.b)("li",{parentName:"ul"},Object(r.b)("a",Object(n.a)({parentName:"li"},{href:"https://www.datadoghq.com/blog/monitoring-kafka-performance-metrics/"}),"Monitoring Kafka performance metrics")," via ",Object(r.b)("strong",{parentName:"li"},"Datadog")),Object(r.b)("li",{parentName:"ul"},Object(r.b)("a",Object(n.a)({parentName:"li"},{href:"https://blog.serverdensity.com/how-to-monitor-kafka/"}),"How to Monitor Kafka")," via ",Object(r.b)("strong",{parentName:"li"},"Server Density")),Object(r.b)("li",{parentName:"ul"},Object(r.b)("a",Object(n.a)({parentName:"li"},{href:"https://cloudpak8s.io/day2/Monitoring/"}),"OpenShift Day 2 Monitoring")," via ",Object(r.b)("strong",{parentName:"li"},"IBM Cloud Paks Playbook")),Object(r.b)("li",{parentName:"ul"},Object(r.b)("a",Object(n.a)({parentName:"li"},{href:"https://ibm.github.io/event-streams/administering/cluster-health/"}),"Monitoring Kafka cluster health")," via ",Object(r.b)("strong",{parentName:"li"},"IBM Event Streams documentation")),Object(r.b)("li",{parentName:"ul"},Object(r.b)("a",Object(n.a)({parentName:"li"},{href:"https://docs.openshift.com/container-platform/4.3/monitoring/cluster_monitoring/configuring-the-monitoring-stack.html"}),"Configuring the monitoring stack")," via ",Object(r.b)("strong",{parentName:"li"},"Red Hat OpenShift")," documentation"),Object(r.b)("li",{parentName:"ul"},Object(r.b)("a",Object(n.a)({parentName:"li"},{href:"https://docs.openshift.com/container-platform/4.3/monitoring/cluster_monitoring/examining-cluster-metrics.html"}),"Examining cluster metrics")," via ",Object(r.b)("strong",{parentName:"li"},"Red Hat OpenShift")," documentation")))}h.isMDXComponent=!0}}]);
//# sourceMappingURL=component---src-pages-scenarios-monitoring-on-ocp-index-mdx-d27895c2efbc01715512.js.map