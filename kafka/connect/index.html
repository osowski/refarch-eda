



<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      <meta http-equiv="x-ua-compatible" content="ie=edge">
      
      
      
      
        <meta name="lang:clipboard.copy" content="Copy to clipboard">
      
        <meta name="lang:clipboard.copied" content="Copied to clipboard">
      
        <meta name="lang:search.language" content="en">
      
        <meta name="lang:search.pipeline.stopwords" content="True">
      
        <meta name="lang:search.pipeline.trimmer" content="True">
      
        <meta name="lang:search.result.none" content="No matching documents">
      
        <meta name="lang:search.result.one" content="1 matching document">
      
        <meta name="lang:search.result.other" content="# matching documents">
      
        <meta name="lang:search.tokenizer" content="[\s\-]+">
      
      <link rel="shortcut icon" href="../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.0.4, mkdocs-material-4.4.2">
    
    
      
        <title>Kafka Connect - Event Driven Architecture</title>
      
    
    
      <link rel="stylesheet" href="../../assets/stylesheets/application.30686662.css">
      
      
    
    
      <script src="../../assets/javascripts/modernizr.74668098.js"></script>
    
    
      
        <link href="https://fonts.gstatic.com" rel="preconnect" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,400,400i,700|Roboto+Mono&display=fallback">
        <style>body,input{font-family:"Roboto","Helvetica Neue",Helvetica,Arial,sans-serif}code,kbd,pre{font-family:"Roboto Mono","Courier New",Courier,monospace}</style>
      
    
    <link rel="stylesheet" href="../../assets/fonts/material-icons.css">
    
    
      <link rel="stylesheet" href="../../extra.css">
    
    
      
        
<script>
  window.ga = window.ga || function() {
    (ga.q = ga.q || []).push(arguments)
  }
  ga.l = +new Date
  /* Setup integration and send page view */
  ga("create", "UA-149377589-3", "auto")
  ga("set", "anonymizeIp", true)
  ga("send", "pageview")
  /* Register handler to log search on blur */
  document.addEventListener("DOMContentLoaded", () => {
    if (document.forms.search) {
      var query = document.forms.search.query
      query.addEventListener("blur", function() {
        if (this.value) {
          var path = document.location.pathname;
          ga("send", "pageview", path + "?q=" + this.value)
        }
      })
    }
  })
</script>
<script async src="https://www.google-analytics.com/analytics.js"></script>
      
    
    
  </head>
  
    <body dir="ltr">
  
    <svg class="md-svg">
      <defs>
        
        
          <svg xmlns="http://www.w3.org/2000/svg" width="416" height="448" viewBox="0 0 416 448" id="__github"><path fill="currentColor" d="M160 304q0 10-3.125 20.5t-10.75 19T128 352t-18.125-8.5-10.75-19T96 304t3.125-20.5 10.75-19T128 256t18.125 8.5 10.75 19T160 304zm160 0q0 10-3.125 20.5t-10.75 19T288 352t-18.125-8.5-10.75-19T256 304t3.125-20.5 10.75-19T288 256t18.125 8.5 10.75 19T320 304zm40 0q0-30-17.25-51T296 232q-10.25 0-48.75 5.25Q229.5 240 208 240t-39.25-2.75Q130.75 232 120 232q-29.5 0-46.75 21T56 304q0 22 8 38.375t20.25 25.75 30.5 15 35 7.375 37.25 1.75h42q20.5 0 37.25-1.75t35-7.375 30.5-15 20.25-25.75T360 304zm56-44q0 51.75-15.25 82.75-9.5 19.25-26.375 33.25t-35.25 21.5-42.5 11.875-42.875 5.5T212 416q-19.5 0-35.5-.75t-36.875-3.125-38.125-7.5-34.25-12.875T37 371.5t-21.5-28.75Q0 312 0 260q0-59.25 34-99-6.75-20.5-6.75-42.5 0-29 12.75-54.5 27 0 47.5 9.875t47.25 30.875Q171.5 96 212 96q37 0 70 8 26.25-20.5 46.75-30.25T376 64q12.75 25.5 12.75 54.5 0 21.75-6.75 42 34 40 34 99.5z"/></svg>
        
      </defs>
    </svg>
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" data-md-component="overlay" for="__drawer"></label>
    
      <a href="#kafka-connect" tabindex="1" class="md-skip">
        Skip to content
      </a>
    
    
      <header class="md-header" data-md-component="header">
  <nav class="md-header-nav md-grid">
    <div class="md-flex">
      <div class="md-flex__cell md-flex__cell--shrink">
        <a href="../.." title="Event Driven Architecture" class="md-header-nav__button md-logo">
          
            <img src="../../images/cloud.png" width="24" height="24">
          
        </a>
      </div>
      <div class="md-flex__cell md-flex__cell--shrink">
        <label class="md-icon md-icon--menu md-header-nav__button" for="__drawer"></label>
      </div>
      <div class="md-flex__cell md-flex__cell--stretch">
        <div class="md-flex__ellipsis md-header-nav__title" data-md-component="title">
          
            <span class="md-header-nav__topic">
              Event Driven Architecture
            </span>
            <span class="md-header-nav__topic">
              
                Kafka Connect
              
            </span>
          
        </div>
      </div>
      <div class="md-flex__cell md-flex__cell--shrink">
        
          <label class="md-icon md-icon--search md-header-nav__button" for="__search"></label>
          
<div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="query" data-md-state="active">
      <label class="md-icon md-search__icon" for="__search"></label>
      <button type="reset" class="md-icon md-search__icon" data-md-component="reset" tabindex="-1">
        &#xE5CD;
      </button>
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="result">
          <div class="md-search-result__meta">
            Type to start searching
          </div>
          <ol class="md-search-result__list"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
        
      </div>
      
        <div class="md-flex__cell md-flex__cell--shrink">
          <div class="md-header-nav__source">
            


  

<a href="https://github.com/ibm-cloud-architecture/refarch-eda/" title="Go to repository" class="md-source" data-md-source="github">
  
    <div class="md-source__icon">
      <svg viewBox="0 0 24 24" width="24" height="24">
        <use xlink:href="#__github" width="24" height="24"></use>
      </svg>
    </div>
  
  <div class="md-source__repository">
    GitHub
  </div>
</a>
          </div>
        </div>
      
    </div>
  </nav>
</header>
    
    <div class="md-container">
      
        
      
      
      <main class="md-main" role="main">
        <div class="md-main__inner md-grid" data-md-component="container">
          
            
              <div class="md-sidebar md-sidebar--primary" data-md-component="navigation">
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    <nav class="md-nav md-nav--primary" data-md-level="0">
  <label class="md-nav__title md-nav__title--site" for="__drawer">
    <a href="../.." title="Event Driven Architecture" class="md-nav__button md-logo">
      
        <img src="../../images/cloud.png" width="48" height="48">
      
    </a>
    Event Driven Architecture
  </label>
  
    <div class="md-nav__source">
      


  

<a href="https://github.com/ibm-cloud-architecture/refarch-eda/" title="Go to repository" class="md-source" data-md-source="github">
  
    <div class="md-source__icon">
      <svg viewBox="0 0 24 24" width="24" height="24">
        <use xlink:href="#__github" width="24" height="24"></use>
      </svg>
    </div>
  
  <div class="md-source__repository">
    GitHub
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
      


  <li class="md-nav__item">
    <a href="../.." title="Home" class="md-nav__link">
      Home
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../../concepts/" title="Concepts" class="md-nav__link">
      Concepts
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-3" type="checkbox" id="nav-3">
    
    <label class="md-nav__link" for="nav-3">
      Architecture
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="1">
      <label class="md-nav__title" for="nav-3">
        Architecture
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../../architecture/" title="Reference diagrams" class="md-nav__link">
      Reference diagrams
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../evt-src/" title="Event sources" class="md-nav__link">
      Event sources
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../evt-backbone/" title="Event backbone" class="md-nav__link">
      Event backbone
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../evt-action/" title="Event actions" class="md-nav__link">
      Event actions
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../evt-state/" title="Event managed states" class="md-nav__link">
      Event managed states
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../arch/" title="Event Stream & Kafka architecture" class="md-nav__link">
      Event Stream & Kafka architecture
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

    
      
      
      


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-4" type="checkbox" id="nav-4">
    
    <label class="md-nav__link" for="nav-4">
      Methodology
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="1">
      <label class="md-nav__title" for="nav-4">
        Methodology
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../../methodology/readme/" title="Event driven methodology" class="md-nav__link">
      Event driven methodology
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../methodology/eventstorming/" title="Event Storming" class="md-nav__link">
      Event Storming
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="https://ibm-cloud-architecture.github.io/refarch-kc/analysis/readme/" title="Event Storming applied to container shipment analysis" class="md-nav__link">
      Event Storming applied to container shipment analysis
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../methodology/ddd/" title="Domain driven design for event based solution" class="md-nav__link">
      Domain driven design for event based solution
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

    
      
      
      


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-5" type="checkbox" id="nav-5">
    
    <label class="md-nav__link" for="nav-5">
      Event driven design patterns
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="1">
      <label class="md-nav__title" for="nav-5">
        Event driven design patterns
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../../evt-microservices/" title="Microservices" class="md-nav__link">
      Microservices
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../design-patterns/ED-patterns/" title="Event-driven patterns" class="md-nav__link">
      Event-driven patterns
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../design-patterns/event-sourcing/" title="Event Sourcing" class="md-nav__link">
      Event Sourcing
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../design-patterns/cqrs/" title="CQRS" class="md-nav__link">
      CQRS
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../design-patterns/saga/" title="Saga" class="md-nav__link">
      Saga
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../design-patterns/data-replication/" title="Data replication pattern" class="md-nav__link">
      Data replication pattern
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

    
      
      
      


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-6" type="checkbox" id="nav-6">
    
    <label class="md-nav__link" for="nav-6">
      Reference implementations
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="1">
      <label class="md-nav__title" for="nav-6">
        Reference implementations
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="https://ibm-cloud-architecture.github.io/refarch-kc" title="Container shipment implementation solution" class="md-nav__link">
      Container shipment implementation solution
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

    
      
      
      

  


  <li class="md-nav__item md-nav__item--active md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-7" type="checkbox" id="nav-7" checked>
    
    <label class="md-nav__link" for="nav-7">
      Product guidances
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="1">
      <label class="md-nav__title" for="nav-7">
        Product guidances
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../readme/" title="Kafka concepts summary" class="md-nav__link">
      Kafka concepts summary
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../arch/" title="Architecture considerations" class="md-nav__link">
      Architecture considerations
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../producers/" title="Kafka producer development practices" class="md-nav__link">
      Kafka producer development practices
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../consumers/" title="Kafka consumer development practices" class="md-nav__link">
      Kafka consumer development practices
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../kafka-stream/" title="Kafka streaming processing" class="md-nav__link">
      Kafka streaming processing
    </a>
  </li>

        
          
          
          

  


  <li class="md-nav__item md-nav__item--active">
    
    <input class="md-toggle md-nav__toggle" data-md-toggle="toc" type="checkbox" id="__toc">
    
      
    
    
      <label class="md-nav__link md-nav__link--active" for="__toc">
        Kafka Connect
      </label>
    
    <a href="./" title="Kafka Connect" class="md-nav__link md-nav__link--active">
      Kafka Connect
    </a>
    
      
<nav class="md-nav md-nav--secondary">
  
  
    
  
  
    <label class="md-nav__title" for="__toc">Table of contents</label>
    <ul class="md-nav__list" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#characteristics" class="md-nav__link">
    Characteristics
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#installation" class="md-nav__link">
    Installation
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#getting-started-with-kafka-connect-standalone-mode" class="md-nav__link">
    Getting started with kafka connect standalone mode
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#connecting-to-ibm-cloud-event-streams-remote-cluster" class="md-nav__link">
    Connecting to IBM Cloud Event Streams remote cluster
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#distributed-mode" class="md-nav__link">
    Distributed mode
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#verifying-the-connectors-via-the-rest-api" class="md-nav__link">
    Verifying the connectors via the REST api
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#deploy-the-kafka-connect-as-a-service-within-openshift-cluster" class="md-nav__link">
    Deploy the Kafka connect as a service within Openshift cluster
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#running-with-local-kafka-cluster" class="md-nav__link">
    Running with local kafka cluster
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#further-readings" class="md-nav__link">
    Further Readings
  </a>
  
</li>
      
      
      
      
      
    </ul>
  
</nav>
    
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../FAQ/" title="Kafka FAQ" class="md-nav__link">
      Kafka FAQ
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="https://ibm-cloud-architecture.github.io/refarch-kc/avro/avro" title="Adopting Avro with Kafka" class="md-nav__link">
      Adopting Avro with Kafka
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../monitoring/" title="Kafka monitoring" class="md-nav__link">
      Kafka monitoring
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../serverless/" title="Serverless" class="md-nav__link">
      Serverless
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

    
      
      
      


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-8" type="checkbox" id="nav-8">
    
    <label class="md-nav__link" for="nav-8">
      Deployments
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="1">
      <label class="md-nav__title" for="nav-8">
        Deployments
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../../deployments/eventstreams/es-ibm-cloud/" title="Event Streams IBM CLOUD deployment" class="md-nav__link">
      Event Streams IBM CLOUD deployment
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../deployments/eventstreams/" title="Event Streams Cloud Pak Integration deployment" class="md-nav__link">
      Event Streams Cloud Pak Integration deployment
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../deployments/kafka/" title="Kafka deployment" class="md-nav__link">
      Kafka deployment
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../deployments/zookeeper/" title="Zookeeper deployment" class="md-nav__link">
      Zookeeper deployment
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../deployments/postgresql/" title="Postgresql" class="md-nav__link">
      Postgresql
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../deployments/eventstreams/Install_Ceph_on_ICP/" title="Ceph deployment on ICP" class="md-nav__link">
      Ceph deployment on ICP
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../deployments/strimzi/deploy/" title="Kafka deployment with Strimzi" class="md-nav__link">
      Kafka deployment with Strimzi
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="https://github.com/ibm-cloud-architecture/refarch-integration/blob/master/docs/icp/troubleshooting.md" title="Troubleshouting" class="md-nav__link">
      Troubleshouting
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

    
      
      
      


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-9" type="checkbox" id="nav-9">
    
    <label class="md-nav__link" for="nav-9">
      Real time analytics
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="1">
      <label class="md-nav__title" for="nav-9">
        Real time analytics
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../../rt-analytics/" title="Concepts" class="md-nav__link">
      Concepts
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="https://ibm-cloud-architecture.github.io/refarch-reefer-ml" title="Reefer Container Predictive Maintenance" class="md-nav__link">
      Reefer Container Predictive Maintenance
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../../training/eda-skill-journey/" title="Skill journey" class="md-nav__link">
      Skill journey
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../../compendium/" title="Compendium" class="md-nav__link">
      Compendium
    </a>
  </li>

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              <div class="md-sidebar md-sidebar--secondary" data-md-component="toc">
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    
<nav class="md-nav md-nav--secondary">
  
  
    
  
  
    <label class="md-nav__title" for="__toc">Table of contents</label>
    <ul class="md-nav__list" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#characteristics" class="md-nav__link">
    Characteristics
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#installation" class="md-nav__link">
    Installation
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#getting-started-with-kafka-connect-standalone-mode" class="md-nav__link">
    Getting started with kafka connect standalone mode
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#connecting-to-ibm-cloud-event-streams-remote-cluster" class="md-nav__link">
    Connecting to IBM Cloud Event Streams remote cluster
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#distributed-mode" class="md-nav__link">
    Distributed mode
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#verifying-the-connectors-via-the-rest-api" class="md-nav__link">
    Verifying the connectors via the REST api
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#deploy-the-kafka-connect-as-a-service-within-openshift-cluster" class="md-nav__link">
    Deploy the Kafka connect as a service within Openshift cluster
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#running-with-local-kafka-cluster" class="md-nav__link">
    Running with local kafka cluster
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#further-readings" class="md-nav__link">
    Further Readings
  </a>
  
</li>
      
      
      
      
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          <div class="md-content">
            <article class="md-content__inner md-typeset">
              
                
                  <a href="https://github.com/ibm-cloud-architecture/refarch-eda/edit/master/docs/kafka/connect.md" title="Edit this page" class="md-icon md-content__icon">&#xE3C9;</a>
                
                
                <h1 id="kafka-connect">Kafka Connect</h1>
<p><a href="https://kafka.apache.org/documentation/#connect">Kafka connect</a> is an open source component for easily integrate external systems with Kafka. It works with IBM Event Streams and Red Hat AMQ Streams.   It uses the concepts of source and sink connectors to ingest or deliver data to / from  Kafka topics.</p>
<p><img alt="Kafka component" src="../images/kafka-components.png" /></p>
<p>The generate concepts are detailed in <a href="https://docs.confluent.io/current/connect/concepts.html">this note</a> or in the <a href="https://ibm.github.io/event-streams/connecting/connectors/">IBM Event streams product documentation</a>. Here is a quick summary:</p>
<ul>
<li><strong>connector</strong> represents a logical job to move data from / to kafka  to / from external systems. A lot of <a href="https://ibm.github.io/event-streams/connectors/">existing connectors</a> can be reused, or you can implement your owns.</li>
<li><strong>workers</strong> are JVM running the connector. For production deployment workers run in cluster or "distributed mode".</li>
<li><strong>tasks</strong>: each worker coordinates a set of tasks to copy data. Task states are saved in kafka topics. They can be started, stopped at any time to support resilience, and scalable data pipeline.</li>
</ul>
<p><img alt="Connectors and tasks" src="../images/connector-tasks.png" /></p>
<p>When a connector is submitted to the cluster, the workers rebalance the full set of connectors in the cluster and their tasks so that each worker has approximately the same amount of work.</p>
<h2 id="characteristics">Characteristics</h2>
<ul>
<li>Copy vast quantities of data from source to kafka: work at the database level.</li>
<li>Support streaming and batch.</li>
<li>Scale at the organization level, even if it can support a standalone, mono connector approach to start small, it is possible to run in parallel on distributed cluster.</li>
<li>Copy data, externalizing transformation in other framework.</li>
<li>Kafka Connect defines three models: data model, worker model and connector model.</li>
<li>Provide a REST interface to manage connectors and monitor jobs.</li>
</ul>
<h2 id="installation">Installation</h2>
<p>The  Kafka connect framework fits well into a kubernetes deployment. We have different options for that deployment.</p>
<p>We recommend reading the <a href="https://ibm.github.io/event-streams/connecting/setting-up-connectors/">IBM  event streams documentation</a> for installing Kafka connect with IBM Event Streams or you can also leverage the <a href="https://strimzi.io/docs/0.9.0/#kafka-connect-str">Strimzi Kafka connect operator</a>.</p>
<p>With IBM Event Streams on premise deployment, the connectors setup is part of the user admin console toolbox:</p>
<p><img alt="Event Streams connector" src="../images/es-connectors.png" /></p>
<p><em>Deploying connectors against an IBM Event Streams cluster, you need to have API key with permissions to produce and consume messages for all topics.</em></p>
<p>As an extendable framework, kafka connect, can have new connector plugins. To deploy new connector, the kafka docker image defining the connector needs to be updated with the connector jar and redeployed to kubernetes cluster or to other environment. With IBM Event Streams on Openshift, the toolbox includes a kafka connect environment packaging, that defines a Dockerfile and configuration files to build your own image with the connectors jar files you need. The configuration files defines the properties to connect to Event Streams kafka brokers using API keys and SASL.</p>
<p>Here is the <a href="https://ibm.github.io/event-streams/connectors/">list of supported connectors</a> for IBM Event Streams.</p>
<p>From the downloaded dockerfile we can build a new kafka connect environment image like:</p>
<div class="codehilite"><pre><span></span>docker build -t ibmcase/kafkaconnect:0.0.1 .
</pre></div>

<p>We will use this image to run the kafka connect in standalone mode or in <a href="#distributed-mode">the distributed mode section</a>.</p>
<h2 id="getting-started-with-kafka-connect-standalone-mode">Getting started with kafka connect standalone mode</h2>
<p>For development and test purposes, we can use Kafka connect in standalone mode, but still connected to IBM Event Streams running on-premise.  </p>
<ul>
<li>Start a container with kafka connector, to run a standalone connector: you need to use a worker configuration and a connector properties files under the <code>connectors</code> folder. Those files will be mounted under the <code>/opt/kafka/config</code> folder. Also, as we want to test sending the content of a file, we mount to the <code>/home/data</code> the folder with input file:</li>
</ul>
<div class="codehilite"><pre><span></span><span class="c1"># in the refarch-kc/docker/kafka-connect folder</span>
docker run -ti  --rm -v <span class="k">$(</span><span class="nb">pwd</span><span class="k">)</span>/config:/opt/kafka/config -v <span class="k">$(</span><span class="nb">pwd</span><span class="k">)</span>/data:/home/data --entrypoint bash -p <span class="m">8083</span>:8083 ibmcase/kafkaconnect:0.0.1
</pre></div>

<div class="admonition note">
<p class="admonition-title">Note<p>You need to modify those property files to set the API key for your own event streams cluster, and set any other properties.</p>
</p>
</div>
<ul>
<li>Inside the container starts the standalone connector:</li>
</ul>
<div class="codehilite"><pre><span></span><span class="nb">cd</span> /opt/kafka
./bin/connect-standalone.sh config/worker-standalone.properties config/file-source.properties config/file-sink.properties
</pre></div>

<p>The  file-source.properties configures a file reader to source the <code>data/access_log.txt</code> file to the <code>clickstream</code> topic:</p>
<div class="codehilite"><pre><span></span><span class="na">name</span><span class="o">=</span><span class="s">local-file-source</span>
<span class="na">connector.class</span><span class="o">=</span><span class="s">FileStreamSource</span>
<span class="na">tasks.max</span><span class="o">=</span><span class="s">1</span>
<span class="na">file</span><span class="o">=</span><span class="s">/home/kafka-connect/access_log.txt</span>
<span class="na">topic</span><span class="o">=</span><span class="s">clickstream</span>
</pre></div>

<p>While the <code>config/file-sink.properties</code> defines a file sink stream to create a json file by getting messages from the <code>clickstream</code> topic. The file sink connector can read from multiple topics to aggregate the content in the same file.</p>
<p>The standalone connector worker configuration specifies where to connect, and what converters to use:</p>
<div class="codehilite"><pre><span></span><span class="na">bootstrap.servers</span><span class="o">=</span><span class="s">....</span>
<span class="na">key.converter</span><span class="o">=</span><span class="s">org.apache.kafka.connect.json.JsonConverter</span>
<span class="na">value.converter</span><span class="o">=</span><span class="s">org.apache.kafka.connect.json.JsonConverter</span>

<span class="c"># Local storage file for offset data</span>
<span class="na">offset.storage.file.filename</span><span class="o">=</span><span class="s">/tmp/connect.offsets</span>
</pre></div>

<p>The execution trace shows the producer id, and the consumer id, and the task for each connector:</p>
<div class="codehilite"><pre><span></span><span class="nv">INFO</span> <span class="nv">Creating</span> <span class="nv">task</span> <span class="nv">local</span><span class="o">-</span><span class="nv">file</span><span class="o">-</span><span class="nv">source</span><span class="o">-</span><span class="mi">0</span> <span class="ss">(</span><span class="nv">org</span>.<span class="nv">apache</span>.<span class="nv">kafka</span>.<span class="k">connect</span>.<span class="nv">runtime</span>.<span class="nv">Worker</span>:<span class="mi">414</span><span class="ss">)</span>
...
<span class="nv">INFO</span> <span class="nv">TaskConfig</span> <span class="nv">values</span>: 
    <span class="nv">task</span>.<span class="nv">class</span> <span class="o">=</span> <span class="nv">class</span> <span class="nv">org</span>.<span class="nv">apache</span>.<span class="nv">kafka</span>.<span class="k">connect</span>.<span class="nv">file</span>.<span class="nv">FileStreamSourceTask</span>
...
 <span class="nv">INFO</span> <span class="nv">Creating</span> <span class="nv">connector</span> <span class="nv">local</span><span class="o">-</span><span class="nv">file</span><span class="o">-</span><span class="nv">sink</span> <span class="nv">of</span> <span class="nv">type</span> <span class="nv">FileStreamSink</span> <span class="ss">(</span><span class="nv">org</span>.<span class="nv">apache</span>.<span class="nv">kafka</span>.<span class="k">connect</span>.<span class="nv">runtime</span>.<span class="nv">Worker</span>:<span class="mi">246</span><span class="ss">)</span>
 <span class="nv">INFO</span> <span class="nv">Creating</span> <span class="nv">task</span> <span class="nv">local</span><span class="o">-</span><span class="nv">file</span><span class="o">-</span><span class="nv">sink</span><span class="o">-</span><span class="mi">0</span> <span class="ss">(</span><span class="nv">org</span>.<span class="nv">apache</span>.<span class="nv">kafka</span>.<span class="k">connect</span>.<span class="nv">runtime</span>.<span class="nv">Worker</span>:<span class="mi">414</span><span class="ss">)</span>
</pre></div>

<p>To validate the data are well published see the generated file under the <code>data</code> folder. As the Json converter was used, the message was wrapped into a json document with schema and payload.</p>
<div class="codehilite"><pre><span></span><span class="p">{</span><span class="nt">&quot;schema&quot;</span><span class="p">:{</span><span class="nt">&quot;type&quot;</span><span class="p">:</span><span class="s2">&quot;string&quot;</span><span class="p">,</span><span class="nt">&quot;optional&quot;</span><span class="p">:</span><span class="kc">false</span><span class="p">},</span><span class="nt">&quot;payload&quot;</span><span class="p">:</span><span class="s2">&quot;46.166.139.20 - - [01/Dec/2015:23:22:09 +0000] \&quot;POST /xmlrpc.php HTTP/1.0\&quot; 200 370 \&quot;-\&quot; \&quot;Mozilla/4.0 (compatible: MSIE 7.0; Windows NT 6.0)\&quot;&quot;</span><span class="p">}</span>
</pre></div>

<h2 id="connecting-to-ibm-cloud-event-streams-remote-cluster">Connecting to IBM Cloud Event Streams remote cluster</h2>
<p>To connect to Event Streams on IBM Cloud the properties needs to define the broker adviser URLs and the API key that you get from the service crendentials.</p>
<p>This API key must provide permission to produce and consume messages for all topics, and also to create topics.</p>
<p>With Event streams on Cloud the <a href="https://cloud.ibm.com/docs/services/EventStreams?topic=eventstreams-kafka_connect">following document</a> explains what properties to add to the worker and connectors configuration.</p>
<div class="codehilite"><pre><span></span><span class="na">bootstrap.servers</span><span class="o">=</span><span class="s">broker-3-qnsdz.kafka.svc01.us-east.eventstreams.cloud.ibm.com:9093,broker-1-qnprt...</span>
<span class="na">security.protocol</span><span class="o">=</span><span class="s">SASL_SSL</span>
<span class="na">ssl.protocol</span><span class="o">=</span><span class="s">TLSv1.2</span>
<span class="na">sasl.mechanism</span><span class="o">=</span><span class="s">PLAIN</span>
<span class="na">sasl.jaas.config</span><span class="o">=</span><span class="s">org.apache.kafka.common.security.plain.PlainLoginModule required username=&quot;token&quot; password=&quot;98....&quot;;</span>
</pre></div>

<p>Using the same <code>file source stream connector</code> to send records and a simple consumer console to trace the output like:</p>
<div class="codehilite"><pre><span></span>docker run -ti  -v <span class="k">$(</span><span class="nb">pwd</span><span class="k">)</span>/config:/opt/kafka/config --entrypoint bash  ibmcase/kafkaconnect:0.0.1

esuser@3245874dcdd3: <span class="nb">cd</span> /opt/kafka/bin/
esuser@3245874dcdd3: ./kafka-console-consumer.sh --bootstrap-server eventstream140-ibm-es-proxy-route-broker-0-eventstreams.apps.green.ocp.csplab.local:443 --consumer.config /opt/kafka/config/console-consumer.properties --topic clickstream --from-beginning<span class="s2">&quot;</span>
</pre></div>

<p>The console-consumer.properties specifies the SASL properties to connect to the remote broker using API key.</p>
<h2 id="distributed-mode">Distributed mode</h2>
<p>When running in distributed mode, the connectors need three topics as presented in the <code>create topics</code> table <a href="https://ibm.github.io/event-streams/connecting/setting-up-connectors/">here</a>. </p>
<ul>
<li><strong>connect-configs</strong>: This topic will store the connector and task configurations.</li>
<li><strong>connect-offsets</strong>: This topic is used to store offsets for Kafka Connect.</li>
<li><strong>connect-status</strong>: This topic will store status updates of connectors and tasks.</li>
</ul>
<p>Using IBM Event Streams CLI, the topics are created via the commands like:</p>
<div class="codehilite"><pre><span></span><span class="c1"># log to the kubernetes cluster:</span>
cloudctl login -a https://icp-console.apps.green.ocp.csplab.local
<span class="c1"># initialize the event streams CLI plugin</span>
cloudctl es init
<span class="c1"># Create the Kafka topic</span>
cloudctl es topic-create -n connect-configs -p <span class="m">1</span> -r <span class="m">3</span> -c cleanup.policy<span class="o">=</span>compact
cloudctl es topic-create -n connect-offsets -p <span class="m">25</span> -r <span class="m">3</span> -c cleanup.policy<span class="o">=</span>compact
cloudctl es topic-create -n connect-status -p <span class="m">5</span> -r <span class="m">3</span> -c cleanup.policy<span class="o">=</span>compact
cloudctl es topics
</pre></div>

<p>Then the connector configuration needs to specify some other properties (See <a href="https://kafka.apache.org/documentation/#connectconfigs">kafka documentation</a>):</p>
<ul>
<li>group.id to specify the connect cluster name.</li>
<li>key and value converters.</li>
<li>replication factors and topic name for the three needed topics, if Kafka connect is able to create topic on the cluster.</li>
<li>When using Event Streams as kafka cluster, add the <code>sasl</code> properties as described in the <a href="https://cloud.ibm.com/docs/services/EventStreams?topic=eventstreams-kafka_connect#distributed_worker">product documentation</a>.</li>
</ul>
<p>With Event Streams as part of the Cloud Pak for integration, the administration console explains the steps to setup connectors, get distributed configuration and how to add connectors.</p>
<p>See <a href="https://github.com/ibm-cloud-architecture/refarch-kc/blob/master/docker/kafka-connect/distributed-workers.properties">this properties file</a> as an example.</p>
<p>To start locally a Kafka connect in distributed mode, connected to Event Streams deployed on-premise use the following command (the entry point in the dockerfile use the connect-distributed mode script):</p>
<div class="codehilite"><pre><span></span>docker run -v <span class="k">$(</span><span class="nb">pwd</span><span class="k">)</span>/config:/opt/kafka/config -p <span class="m">8083</span>:8083 ibmcase/kafkaconnect:0.0.1
</pre></div>

<p>To illustrate the Kakfa Connect distributed mode, we will add a source connector from a Mongo DB data source using <a href="https://www.mongodb.com/kafka-connector">this connector</a>.</p>
<p><img alt="Mongo source " src="../images/kconnect-mongo.png" /></p>
<p>When using as a source, the connector publishes data changes from MongoDB into Kafka topics for streaming to consuming apps. Data is captured via Change Streams within the MongoDB cluster and published into Kafka topics. The installation of a connector is done by adding the jars from the connector into the plugin path (<code>/opt/connectors</code>) as defined in the connector properties. In the case of mongodb kafka connector the manual installation instructions are in <a href="https://github.com/mongodb/mongo-kafka/blob/master/docs/install.md">this github</a>. The download page includes an uber jar.</p>
<p>As we run the kakfa connect as docker container, the approach is to build a new docker image based one of the Kafka image publicly available. </p>
<p>To define and start a connector, you do a POST to the REST API.</p>
<h2 id="verifying-the-connectors-via-the-rest-api">Verifying the connectors via the REST api</h2>
<p>The documentation about the REST APIs for the distributed connector is in <a href="https://docs.confluent.io/current/connect/references/restapi.html">this site</a>.</p>
<p>For example the http://localhost:8083/connectors is the base URL when running locally.</p>
<h2 id="deploy-the-kafka-connect-as-a-service-within-openshift-cluster">Deploy the Kafka connect as a service within Openshift cluster</h2>
<p>When you use IBM Event Streams on Openshift, you can deploy the IBM kafka connector environment as Docker containers, and define the needed <code>connect-*</code> topics as explained in previous section. The product documentation describes how to do that.</p>
<p>Another approach is to use <a href="https://strimzi.io/">Strimzi</a> operator.</p>
<p>To Be done! </p>
<h2 id="running-with-local-kafka-cluster">Running with local kafka cluster</h2>
<p>We are using a local kafka cluster started with docker-compose as defined in the compose file <a href="https://github.com/ibm-cloud-architecture/refarch-kc/blob/master/docker/backbone-compose.yml">here</a>.</p>
<ul>
<li>The docker network should be <code>kafkanet</code>, if not already created do the following</li>
</ul>
<div class="codehilite"><pre><span></span>docker network create kafkanet
</pre></div>

<ul>
<li>Start the kafka broker (bitnami distribution) and zookeeper node using the command below under the <code>refarch-kc/docker</code> folder:</li>
</ul>
<div class="codehilite"><pre><span></span>docker-compose -f backbone-compose.yml up -d
</pre></div>

<ul>
<li>Start a container with kafka code, to run a standalone connector: you need to use a worker configuration and a connector properties files. Those files will be mounted under the /home folder:</li>
</ul>
<div class="codehilite"><pre><span></span>docker run -ti  -rm --name kconnect -v <span class="k">$(</span><span class="nb">pwd</span><span class="k">)</span>:/home --network kafkanet -p <span class="m">8083</span>:8083 bitnami/kafka:2 bash
</pre></div>

<p>Need to map the port 8083, to access the REST APIs.</p>
<ul>
<li>Inside the container starts the standalone connector:</li>
</ul>
<div class="codehilite"><pre><span></span><span class="nb">cd</span> /opt/bitnami/kafka
./bin/connect-standalone.sh /home/kafka-connect/worker-standalone.properties /home/kafka-connect/file-source.properties
</pre></div>

<p>The above file configures a file reader to source the <code>access_log.txt</code> file to the <code>clickstream</code> topic:</p>
<div class="codehilite"><pre><span></span><span class="na">name</span><span class="o">=</span><span class="s">local-file-source</span>
<span class="na">connector.class</span><span class="o">=</span><span class="s">FileStreamSource</span>
<span class="na">tasks.max</span><span class="o">=</span><span class="s">1</span>
<span class="na">file</span><span class="o">=</span><span class="s">/home/kafka-connect/access_log.txt</span>
<span class="na">topic</span><span class="o">=</span><span class="s">clickstream</span>
</pre></div>

<p>The standalone connector worker configuration specifies where to connect, and what converters to use:</p>
<div class="codehilite"><pre><span></span><span class="na">bootstrap.servers</span><span class="o">=</span><span class="s">kafka1:9092</span>
<span class="na">key.converter</span><span class="o">=</span><span class="s">org.apache.kafka.connect.json.JsonConverter</span>
<span class="na">value.converter</span><span class="o">=</span><span class="s">org.apache.kafka.connect.json.JsonConverter</span>

<span class="c"># Local storage file for offset data</span>
<span class="na">offset.storage.file.filename</span><span class="o">=</span><span class="s">/tmp/connect.offsets</span>
</pre></div>

<p>The execution trace shows the producer id</p>
<div class="codehilite"><pre><span></span><span class="n">INFO</span> <span class="p">[</span><span class="n">Producer</span> <span class="n">clientId</span><span class="o">=</span><span class="n">connector</span><span class="o">-</span><span class="n">producer</span><span class="o">-</span><span class="k">local</span><span class="o">-</span><span class="n">file</span><span class="o">-</span><span class="k">source</span><span class="o">-</span><span class="mi">0</span><span class="p">]</span> <span class="k">Cluster</span> <span class="n">ID</span><span class="p">:</span> <span class="n">tj8y0hiZSYWHB9vLHGP1Ew</span> <span class="p">(</span><span class="n">org</span><span class="p">.</span><span class="n">apache</span><span class="p">.</span><span class="n">kafka</span><span class="p">.</span><span class="n">clients</span><span class="p">.</span><span class="n">Metadata</span><span class="p">:</span><span class="mi">261</span><span class="p">)</span>
</pre></div>

<p>To validate the data are well published run another container with the consumer console tool:</p>
<div class="codehilite"><pre><span></span>docker run -ti  --name sinktrace --rm  --network kafkanet bitnami/kafka:2 bash -c <span class="s2">&quot;</span>
<span class="s2">/opt/bitnami/kafka/bin/kafka-console-consumer.sh --bootstrap-server kafka1:9092 --topic clickstream --from-beginning&quot;</span>
</pre></div>

<p>As the Json converter was used the trace show the message was wrapped into a json document with schema and payload.</p>
<div class="codehilite"><pre><span></span><span class="p">{</span><span class="nt">&quot;schema&quot;</span><span class="p">:{</span><span class="nt">&quot;type&quot;</span><span class="p">:</span><span class="s2">&quot;string&quot;</span><span class="p">,</span><span class="nt">&quot;optional&quot;</span><span class="p">:</span><span class="kc">false</span><span class="p">},</span><span class="nt">&quot;payload&quot;</span><span class="p">:</span><span class="s2">&quot;46.166.139.20 - - [01/Dec/2015:23:22:09 +0000] \&quot;POST /xmlrpc.php HTTP/1.0\&quot; 200 370 \&quot;-\&quot; \&quot;Mozilla/4.0 (compatible: MSIE 7.0; Windows NT 6.0)\&quot;&quot;</span><span class="p">}</span>
</pre></div>

<h2 id="further-readings">Further Readings</h2>
<ul>
<li><a href="https://kafka.apache.org/documentation/#connect">Apache Kafka connect documentation</a></li>
<li><a href="https://docs.confluent.io/current/connect/index.html">Confluent Connector Documentation</a></li>
<li><a href="https://ibm.github.io/event-streams/connecting/connectors/">IBM Event Streams Connectors</a> or <a href="https://ibm.github.io/event-streams/connectors/">the list of supported connectors</a></li>
<li><a href="https://github.com/mongodb/mongo-kafka">MongoDB Connector for Apache Kafka</a></li>
</ul>
                
                  
                
              
              
                


              
            </article>
          </div>
        </div>
      </main>
      
        
<footer class="md-footer">
  
    <div class="md-footer-nav">
      <nav class="md-footer-nav__inner md-grid">
        
          <a href="../kafka-stream/" title="Kafka streaming processing" class="md-flex md-footer-nav__link md-footer-nav__link--prev" rel="prev">
            <div class="md-flex__cell md-flex__cell--shrink">
              <i class="md-icon md-icon--arrow-back md-footer-nav__button"></i>
            </div>
            <div class="md-flex__cell md-flex__cell--stretch md-footer-nav__title">
              <span class="md-flex__ellipsis">
                <span class="md-footer-nav__direction">
                  Previous
                </span>
                Kafka streaming processing
              </span>
            </div>
          </a>
        
        
          <a href="../FAQ/" title="Kafka FAQ" class="md-flex md-footer-nav__link md-footer-nav__link--next" rel="next">
            <div class="md-flex__cell md-flex__cell--stretch md-footer-nav__title">
              <span class="md-flex__ellipsis">
                <span class="md-footer-nav__direction">
                  Next
                </span>
                Kafka FAQ
              </span>
            </div>
            <div class="md-flex__cell md-flex__cell--shrink">
              <i class="md-icon md-icon--arrow-forward md-footer-nav__button"></i>
            </div>
          </a>
        
      </nav>
    </div>
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-footer-copyright">
        
        powered by
        <a href="https://www.mkdocs.org">MkDocs</a>
        and
        <a href="https://squidfunk.github.io/mkdocs-material/">
          Material for MkDocs</a>
      </div>
      
    </div>
  </div>
</footer>
      
    </div>
    
      <script src="../../assets/javascripts/application.c648116f.js"></script>
      
      <script>app.initialize({version:"1.0.4",url:{base:"../.."}})</script>
      
    
  </body>
</html>