{"componentChunkName":"component---src-pages-scenarios-monitoring-on-ocp-index-mdx","path":"/scenarios/monitoring-on-ocp/","result":{"pageContext":{"frontmatter":{"title":"Monitoring IBM Event Streams on OpenShift Cloud Platform","description":"Monitoring Kafka performance metrics and activity when deployed via the IBM Cloud Pak for Integration on Red Hat OpenShift Container Platform."},"relativePagePath":"/scenarios/monitoring-on-ocp/index.mdx","titleType":"append","MdxNode":{"id":"bfe87ffd-fac7-5cb0-bb36-c413ed39c0b5","children":[],"parent":"96645fa5-2b71-5bb0-bb1e-ade7e7a6077d","internal":{"content":"---\ntitle: Monitoring IBM Event Streams on OpenShift Cloud Platform\ndescription: Monitoring Kafka performance metrics and activity when deployed via the IBM Cloud Pak for Integration on Red Hat OpenShift Container Platform.\n---\n\n<AnchorLinks>\n  <AnchorLink>Overview</AnchorLink>\n  <AnchorLink>Scenario Prereqs</AnchorLink>\n  <AnchorLink>Generate Event Load</AnchorLink>\n  <AnchorLink>Explore the preconfigured Event Streams Dashboard</AnchorLink>\n  <AnchorLink>Import Grafana Dashboards</AnchorLink>\n  <AnchorLink>View Grafana Dashboards</AnchorLink>\n  <AnchorLink>External Monitoring Tools</AnchorLink>\n  <AnchorLink>Additional Reading</AnchorLink>\n</AnchorLinks>\n\n<!--<AnchorLink>Import Kibana Dashboards</AnchorLink>\n<AnchorLink>View Kibana Dashboards</AnchorLink>-->\n\n## Overview\n\nTBD Reference\n- https://ibm.github.io/event-streams/administering/deployment-health/\n- https://ibm.github.io/event-streams/administering/cluster-health/\n- https://ibm.github.io/event-streams/administering/topic-health/\n- https://ibm.github.io/event-streams/administering/consumer-lag/\n\n\n<!--\n### Advanced Scenarios\n\nJMX Exporter\n- https://ibm.github.io/event-streams/installing/configuring#configuring-the-jmx-exporter\n- Kafka Streams and jmx_exporter use case\n\nKafka Exporter\n- https://ibm.github.io/event-streams/administering/cluster-health/#kafka-exporter\n- https://ibm.github.io/event-streams/installing/configuring/#configuring-the-kafka-exporter\n\nJmxTrans\n- https://ibm.github.io/event-streams/security/secure-jmx-connections/#configuring-a-jmxtrans-deployment\n-->\n\n## Scenario Prereqs\n\n**OpenShift Container Platform**\n\n- This deployment scenario was developed for use on the OpenShift Container Platform, with a minimum version of `4.4`.\n\n**Cloud Pak for Integration**\n\n- This deployment scenario was developed for use with the 2020.2.x release of the Cloud Pak for Integration, installed on OpenShift 4.4.\n\n**IBM Event Streams**\n\n- This deployment scenario requires a working installation of [IBM Event Streams V10.0](https://ibm.github.io/event-streams/) or greater, deployed on the Cloud Pak for Integration environment mentioned above.\n- For Cloud Pak installation guidance, you can follow the [Cloud Pak Playbook](https://cloudpak8s.io/integration/cp4i-deploy-eventstreams/) installation instructions.\n\n**Git**\n\n- We will need to clone repositories.\n\n**Java**\n\n- Java Development Kit (JDK) v1.8+ (Java 8+)\n\n**Maven**\n\n- The scenario uses Maven v3.6.x\n\n## Generate Event Load\n\nThis section details walking through the generation of a starter application for usage with IBM Event Streams, as documented in the [official product documentation](https://ibm.github.io/event-streams/getting-started/generating-starter-app/).\n\n- Access the Event Streams Dashboard via `https://es-1-ibm-es-ui-integration.apps.[cluster-name]` and login.\n- Click the **Try the starter application** button from the _Getting Started_ page\n- Click **Download JAR from GitHub**. This will open a new window to `https://github.com/ibm-messaging/kafka-java-vertx-starter/releases`\n  - Click the link for `demo-all.jar` from the latest release available. At the time of this writing, the latest version was `1.0.0`.\n\n- Return to the Event Streams console and click **Generate properties**.\n- In dialog that pops up from the right-hand side of the screen, enter the following information:\n  - **Starter application name:** `monitoring-lab-[your-initials]`\n  - Leave **New topic** selected and enter a **Topic name** of `monitoring-lab-topic-[your-initials]`.\n  - Click **Generate and download .zip**\n\n- In a Terminal window, unzip the generated ZIP file from the previous window to the same directory with the `demo-all.jar` file.\n- Review the extracted `kafka.properties` to understand how Event Streams has generated credentials and configuration information for this sample application to connect.\n- Run the command `java -Dproperties_path=./kafka.properties -jar demo-all.jar`.\n\n- Wait until you see the string `Application started in X ms` in the output and then visit the application's user interface via `http://localhost:8080`.\n- Once in the User Interface, enter a message to be contained for the Kafka record value then click **Start producing**.\n- Wait a few moments until the UI updates to show some of the confirmed produced messages and offsets, then click on **Start consuming** on the right side of the application.\n- You can let the application continue running while you continue with the rest of this lab.\n  - If you would like to stop the application from producing, you can click **Stop producing**.\n  - If you would like to stop the application from consuming, you can click **Stop consuming**.\n  - If you would like to stop the application entirely, you can input `Control+C` in the Terminal session where the application is running.\n\nAn [alternative sample application](https://ibm.github.io/event-streams/getting-started/testing-loads/) can be leveraged from the official documentation to generate higher amounts of load.\n\n## Explore the preconfigured Event Streams Dashboard\n\nTBD https://ibm.github.io/event-streams/administering/cluster-health/#viewing-the-preconfigured-dashboard\n- Go to es-console/topics and click on your topic\n- Producers tab\n- Messages tab\n- Consumer groups tab\n\n- Go to https://es-1-ibm-es-ui-integration.apps.eda-solutions.gse-ocp.net/monitor\n- View Messages, Partitions, and Replicas information\n\n## Import Grafana Dashboards\n\nThis section will walk through the Grafana Dashboard capabilities documented in the [official IBM Event Streams documentation](https://ibm.github.io/event-streams/administering/cluster-health/#grafana).\n\n1. Apply the Grafana Dashboard for overall Kafka Health via a `MonitoringDashboard` custom resource:\n\n```bash\noc apply -f https://raw.githubusercontent.com/ibm-messaging/event-streams-operator-resources/master/grafana-dashboards/ibm-eventstreams-kafka-health-dashboard.yaml\n```\n\n## View Grafana Dashboards\n\nTo view the newly imported Event Streams Grafana dashboard for overall Kafka Health, follow these steps:\n\n- Navigate to the IBM Cloud Platform Common Services console homepage via `https://cp-console.apps.[cluster-name]`\n- Click the hamburger icon in the top left.\n- Expand **Monitor Health**.\n- Click the **Monitoring** in the expanded menu to open the Grafana homepage.\n- Click the user icon in the bottom left corner to open the user profile page.\n- In the **Organizations** table, find the namespace where you installed the Event Streams `monitoringdashboard` custom resource, and switch the user profile to that namespace.\n- Hover over the _Dashboards_ square on the left and click **Manage**.\n- Click on **IBM Event Streams Kafka** dashboard in the Dashboard table to view the newly imported resource.\n- Using the drop-down selectors at the top, select the following:\n  - **Namespace** which has the running instance of your Event Streams deployment,\n  - **Cluster Name** for the desired Event Streams cluster\n  - **Topic** that matches desired topics for viewing _(only topics that have been published to will appear in this list)_\n  - **Broker** to select individual or multiple brokers in the cluster.\n\n<InlineNotification kind=\"warning\"><strong>TODO</strong> - Create Alert of some signifigance</InlineNotification>\n\n<!--\n## Import Kibana Dashboards\n\n<InlineNotification kind=\"info\"><strong>PREREQ</strong> - https://docs.openshift.com/container-platform/4.4/logging/cluster-logging-deploying.html</InlineNotification>\n\nTBD https://ibm.github.io/event-streams/administering/cluster-health/#kibana\n\n## View Kibana Dashboards\n\nTBD\n-->\n\n## External Monitoring Tools\n\nTBD\n- https://ibm.github.io/event-streams/tutorials/\n- https://ibm.github.io/event-streams/administering/external-monitoring/\n\n## Additional Reading\n\n- [Monitoring Kafka performance metrics](https://www.datadoghq.com/blog/monitoring-kafka-performance-metrics/) via **Datadog**\n- [How to Monitor Kafka](https://blog.serverdensity.com/how-to-monitor-kafka/) via **Server Density**\n- [OpenShift Day 2 Monitoring](https://cloudpak8s.io/day2/Monitoring/) via **IBM Cloud Paks Playbook**\n- [Monitoring Kafka cluster health](https://ibm.github.io/event-streams/administering/cluster-health/) via **IBM Event Streams documentation**\n- [Configuring the monitoring stack](https://docs.openshift.com/container-platform/4.3/monitoring/cluster_monitoring/configuring-the-monitoring-stack.html) via **Red Hat OpenShift** documentation\n- [Examining cluster metrics](https://docs.openshift.com/container-platform/4.3/monitoring/cluster_monitoring/examining-cluster-metrics.html) via **Red Hat OpenShift** documentation\n","type":"Mdx","contentDigest":"e4a57a2da7bd79c38129e6144fa727a9","counter":447,"owner":"gatsby-plugin-mdx"},"frontmatter":{"title":"Monitoring IBM Event Streams on OpenShift Cloud Platform","description":"Monitoring Kafka performance metrics and activity when deployed via the IBM Cloud Pak for Integration on Red Hat OpenShift Container Platform."},"exports":{},"rawBody":"---\ntitle: Monitoring IBM Event Streams on OpenShift Cloud Platform\ndescription: Monitoring Kafka performance metrics and activity when deployed via the IBM Cloud Pak for Integration on Red Hat OpenShift Container Platform.\n---\n\n<AnchorLinks>\n  <AnchorLink>Overview</AnchorLink>\n  <AnchorLink>Scenario Prereqs</AnchorLink>\n  <AnchorLink>Generate Event Load</AnchorLink>\n  <AnchorLink>Explore the preconfigured Event Streams Dashboard</AnchorLink>\n  <AnchorLink>Import Grafana Dashboards</AnchorLink>\n  <AnchorLink>View Grafana Dashboards</AnchorLink>\n  <AnchorLink>External Monitoring Tools</AnchorLink>\n  <AnchorLink>Additional Reading</AnchorLink>\n</AnchorLinks>\n\n<!--<AnchorLink>Import Kibana Dashboards</AnchorLink>\n<AnchorLink>View Kibana Dashboards</AnchorLink>-->\n\n## Overview\n\nTBD Reference\n- https://ibm.github.io/event-streams/administering/deployment-health/\n- https://ibm.github.io/event-streams/administering/cluster-health/\n- https://ibm.github.io/event-streams/administering/topic-health/\n- https://ibm.github.io/event-streams/administering/consumer-lag/\n\n\n<!--\n### Advanced Scenarios\n\nJMX Exporter\n- https://ibm.github.io/event-streams/installing/configuring#configuring-the-jmx-exporter\n- Kafka Streams and jmx_exporter use case\n\nKafka Exporter\n- https://ibm.github.io/event-streams/administering/cluster-health/#kafka-exporter\n- https://ibm.github.io/event-streams/installing/configuring/#configuring-the-kafka-exporter\n\nJmxTrans\n- https://ibm.github.io/event-streams/security/secure-jmx-connections/#configuring-a-jmxtrans-deployment\n-->\n\n## Scenario Prereqs\n\n**OpenShift Container Platform**\n\n- This deployment scenario was developed for use on the OpenShift Container Platform, with a minimum version of `4.4`.\n\n**Cloud Pak for Integration**\n\n- This deployment scenario was developed for use with the 2020.2.x release of the Cloud Pak for Integration, installed on OpenShift 4.4.\n\n**IBM Event Streams**\n\n- This deployment scenario requires a working installation of [IBM Event Streams V10.0](https://ibm.github.io/event-streams/) or greater, deployed on the Cloud Pak for Integration environment mentioned above.\n- For Cloud Pak installation guidance, you can follow the [Cloud Pak Playbook](https://cloudpak8s.io/integration/cp4i-deploy-eventstreams/) installation instructions.\n\n**Git**\n\n- We will need to clone repositories.\n\n**Java**\n\n- Java Development Kit (JDK) v1.8+ (Java 8+)\n\n**Maven**\n\n- The scenario uses Maven v3.6.x\n\n## Generate Event Load\n\nThis section details walking through the generation of a starter application for usage with IBM Event Streams, as documented in the [official product documentation](https://ibm.github.io/event-streams/getting-started/generating-starter-app/).\n\n- Access the Event Streams Dashboard via `https://es-1-ibm-es-ui-integration.apps.[cluster-name]` and login.\n- Click the **Try the starter application** button from the _Getting Started_ page\n- Click **Download JAR from GitHub**. This will open a new window to `https://github.com/ibm-messaging/kafka-java-vertx-starter/releases`\n  - Click the link for `demo-all.jar` from the latest release available. At the time of this writing, the latest version was `1.0.0`.\n\n- Return to the Event Streams console and click **Generate properties**.\n- In dialog that pops up from the right-hand side of the screen, enter the following information:\n  - **Starter application name:** `monitoring-lab-[your-initials]`\n  - Leave **New topic** selected and enter a **Topic name** of `monitoring-lab-topic-[your-initials]`.\n  - Click **Generate and download .zip**\n\n- In a Terminal window, unzip the generated ZIP file from the previous window to the same directory with the `demo-all.jar` file.\n- Review the extracted `kafka.properties` to understand how Event Streams has generated credentials and configuration information for this sample application to connect.\n- Run the command `java -Dproperties_path=./kafka.properties -jar demo-all.jar`.\n\n- Wait until you see the string `Application started in X ms` in the output and then visit the application's user interface via `http://localhost:8080`.\n- Once in the User Interface, enter a message to be contained for the Kafka record value then click **Start producing**.\n- Wait a few moments until the UI updates to show some of the confirmed produced messages and offsets, then click on **Start consuming** on the right side of the application.\n- You can let the application continue running while you continue with the rest of this lab.\n  - If you would like to stop the application from producing, you can click **Stop producing**.\n  - If you would like to stop the application from consuming, you can click **Stop consuming**.\n  - If you would like to stop the application entirely, you can input `Control+C` in the Terminal session where the application is running.\n\nAn [alternative sample application](https://ibm.github.io/event-streams/getting-started/testing-loads/) can be leveraged from the official documentation to generate higher amounts of load.\n\n## Explore the preconfigured Event Streams Dashboard\n\nTBD https://ibm.github.io/event-streams/administering/cluster-health/#viewing-the-preconfigured-dashboard\n- Go to es-console/topics and click on your topic\n- Producers tab\n- Messages tab\n- Consumer groups tab\n\n- Go to https://es-1-ibm-es-ui-integration.apps.eda-solutions.gse-ocp.net/monitor\n- View Messages, Partitions, and Replicas information\n\n## Import Grafana Dashboards\n\nThis section will walk through the Grafana Dashboard capabilities documented in the [official IBM Event Streams documentation](https://ibm.github.io/event-streams/administering/cluster-health/#grafana).\n\n1. Apply the Grafana Dashboard for overall Kafka Health via a `MonitoringDashboard` custom resource:\n\n```bash\noc apply -f https://raw.githubusercontent.com/ibm-messaging/event-streams-operator-resources/master/grafana-dashboards/ibm-eventstreams-kafka-health-dashboard.yaml\n```\n\n## View Grafana Dashboards\n\nTo view the newly imported Event Streams Grafana dashboard for overall Kafka Health, follow these steps:\n\n- Navigate to the IBM Cloud Platform Common Services console homepage via `https://cp-console.apps.[cluster-name]`\n- Click the hamburger icon in the top left.\n- Expand **Monitor Health**.\n- Click the **Monitoring** in the expanded menu to open the Grafana homepage.\n- Click the user icon in the bottom left corner to open the user profile page.\n- In the **Organizations** table, find the namespace where you installed the Event Streams `monitoringdashboard` custom resource, and switch the user profile to that namespace.\n- Hover over the _Dashboards_ square on the left and click **Manage**.\n- Click on **IBM Event Streams Kafka** dashboard in the Dashboard table to view the newly imported resource.\n- Using the drop-down selectors at the top, select the following:\n  - **Namespace** which has the running instance of your Event Streams deployment,\n  - **Cluster Name** for the desired Event Streams cluster\n  - **Topic** that matches desired topics for viewing _(only topics that have been published to will appear in this list)_\n  - **Broker** to select individual or multiple brokers in the cluster.\n\n<InlineNotification kind=\"warning\"><strong>TODO</strong> - Create Alert of some signifigance</InlineNotification>\n\n<!--\n## Import Kibana Dashboards\n\n<InlineNotification kind=\"info\"><strong>PREREQ</strong> - https://docs.openshift.com/container-platform/4.4/logging/cluster-logging-deploying.html</InlineNotification>\n\nTBD https://ibm.github.io/event-streams/administering/cluster-health/#kibana\n\n## View Kibana Dashboards\n\nTBD\n-->\n\n## External Monitoring Tools\n\nTBD\n- https://ibm.github.io/event-streams/tutorials/\n- https://ibm.github.io/event-streams/administering/external-monitoring/\n\n## Additional Reading\n\n- [Monitoring Kafka performance metrics](https://www.datadoghq.com/blog/monitoring-kafka-performance-metrics/) via **Datadog**\n- [How to Monitor Kafka](https://blog.serverdensity.com/how-to-monitor-kafka/) via **Server Density**\n- [OpenShift Day 2 Monitoring](https://cloudpak8s.io/day2/Monitoring/) via **IBM Cloud Paks Playbook**\n- [Monitoring Kafka cluster health](https://ibm.github.io/event-streams/administering/cluster-health/) via **IBM Event Streams documentation**\n- [Configuring the monitoring stack](https://docs.openshift.com/container-platform/4.3/monitoring/cluster_monitoring/configuring-the-monitoring-stack.html) via **Red Hat OpenShift** documentation\n- [Examining cluster metrics](https://docs.openshift.com/container-platform/4.3/monitoring/cluster_monitoring/examining-cluster-metrics.html) via **Red Hat OpenShift** documentation\n","fileAbsolutePath":"/home/runner/work/refarch-eda/refarch-eda/docs/src/pages/scenarios/monitoring-on-ocp/index.mdx"}}}}