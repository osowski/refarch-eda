{"componentChunkName":"component---src-pages-evt-backbone-readme-mdx","path":"/evt-backbone/README/","result":{"pageContext":{"frontmatter":{"title":"Event Backbone","description":"Event Backbone"},"relativePagePath":"/evt-backbone/README.mdx","titleType":"append","MdxNode":{"id":"6dd7919a-12ae-5f0b-ba4a-bc0a9478454b","children":[],"parent":"c7755af0-b97b-5a07-a09c-82d9386013d7","internal":{"content":"---\ntitle: Event Backbone\ndescription: Event Backbone\n---\n\nThe event backbone is the communication layer in the event driven architecture.  It provides the connection between event driven capabilities and in the *Cloud Native*, it becomes the Pub/Sub communication layer for event driven microservices.\n\nAt this high level we would consider two types of relevant technologies for the event backbone, *Message Brokers* and *Event Logs*.  Both technology types could be used to achieve the event communication style, with the \"Publish and subscribe\" model however, it is also important to consider other capabilities which are frequently used within event driven solutions:\n\n* Keeping an **Event Log** as a time sequenced as it happened recording of events (Source of the truth).\n* Enabling direct **replay** of events.\n* Enabling **Event Sourcing** as a way of recording state changes in distributed systems.\n* Enabling **programmatic access** to the *continuous event stream*.\n\nWhen viewed across these wider event driven capabilities, an event log style technology can provide a central component which can support all of these capabilities, whereas a message broker would have to be extended with other components.\n\n## Defining the Event Backbone for the event driven reference architecture\n\n![](evt-backbone.png)\n\nFor the event driven architecture we defined the following characteristics to be essential for the *event backbone*\n\n* Publish-subscribe event communication between event producers and consumers\n* Facilitate many consumers with shared central “source of truth”.\n* Capability to store events for a given period of time (event log). This is the shared source of the truth for events.\n* Ability for consumers to subscribe to events.\n* Provide replay of events from history for evolving application instances.\n* Provide programmatic access to continuous stream of events, with minimum time lag.\n* Must be highly scalable and resilient to cloud deployment levels.\n\nLooking across these capabilities, the potential technologies, the amount of adoption and community activity around the technologies lead us to selecting *Kafka* as the Open Source technology base for the event backbone.\n\nYou can read more about Apache Kafka project here [https://kafka.apache.org](https://kafka.apache.org)\n\n## Event backbone considerations\n\nWhile choosing an event backbone for your event-driven app development, you need to consider below points,\n\n### Persistence\n\nWhen source systems generate events, the consumers of those are interested in those events may not be online or available at the same time. So you need a way to store these messages for a configurable period of time until they are consumed and acted upon. Event backbone should be able to provide such event persistence.\n\n### Observability\n\nAt times, you need an overall view of how events are ingested by source systems and getting processed by consumers. It could be a management console where events can be observed. Event backbone should provide such observability.\n\n### Fault tolerance\n\nEvent backbone could be made of several components. If one of them becomes unavailable, there should not be any impact on the event processors dependent on the backbone. Event backbone needs to provide this resiliency.\n\n### High availability\n\nEvent backbone provides persistence of messages/events. If one of the components of the backbone becomes unavailable, there should not be any impact on the availability of these messages/events. Event backbone should be highly available.\n\n### Performance\n\nEvent backbone should provide means of accelerating the event processing operations (e.g. parallelising event processing) thereby providing enhanced performance.\n\n### Delivery guarantees\n\nEvent backbone should support guaranteed delivery both for producer and consumer. It should support below delivery guarantees:\n\n* at least once\n* at most once\n* exactly once\n\n### Security\n\nThe data residing in the event backbone should be secured, at rest as well as in transit. Only authenticated and authorized users should be able to publish and consume messages from the backbone. Topic specific authorizations will also help blocking access by unauthorized consumers. Event backbone should provide these security measures.\n\n### Stateful operations for events streams\n\nSometimes, source systems generate a continuous flow of 'inter-related' events (e.g. IoT sensors sending data every second). In order to process such messages correctly, the event backbone needs to support for stateful operations like windowing, joins, aggregations. and any type of real time analytics.\n\n### Ease of development\n\nDeveloping a consumer or a stream application should be straight-forward with the programmatic features that the event backbone provides.\n\n### Ease of deployment\n\nThe installation of event backbone should be an easy to follow process.\n\n### Event routing options\n\nIn EDA, event consumers may not be online at all times. So, it should be easier for consumers to subscribe to a topic when it comes online.\n\n### On-failure hooks\n\nEvent backbone can support pre-configured actions/behaviors for certain messages. E.g. if a consumer fails to process a message more than a certain number of times, that message can be sent to another topic for re-trying the processing action.\n\nPredetermined for unprocessed events (retries, dead-letter queues etc)\n\n### Management plane\n\nEvent backbone can provide a management plane from which infrastrucutre level configurations can be managed.\n\n## Supporting products\n\nThe IBM Event Streams offering provides a *Kafka* service for the Event Backbone. The service is available as a fully managed service within Public cloud and as a supported build for IBM Cloud Private.\n\n* [IBM Event Streams Public Cloud](https://console.bluemix.net/catalog/services/event-streams)\n* [IBM Event Streams Private Cloud](https://www.ibm.com/cloud/event-streams)\n* [See also our own Kafka study article](../kafka/readme/) on how to support high availability and how to deploy to your local environment or to a kubernetes cluster like IBM Cloud Private.\n* [Active MQ Artemis](https://activemq.apache.org/components/artemis/) and our study [notes]()\n\n## Messaging versus event streaming\n\nWe recommend reading [this article](https://developer.ibm.com/messaging/2018/05/18/comparing-messaging-event-streaming-use-cases/) and [this one](https://developer.ibm.com/messaging/2019/02/05/comparing-messaging-pub-sub-and-event-streams/), to get insight between messaging (focusing on operations / actions to be performed by a system or service) versus event (focusing on the state / facts of a system with no knowledge of the downstream processing. To summarize messaging (like MQ) are to support:\n\n* Transient Data – data is only stored until a consumer has processed the message, or it expires\n* Request / reply most of the time\n* Targeted reliable delivery: targeted to the entity that will process the request or receive the response. Reliable with transaction support.\n\nFor events:\n\n* Stream history: consumers are interested by history and not just the most recent event\n* Scalable Consumption: A single event is consumed by many consumers with limited impact as the number of consumers grow.\n* Immutable Data.\n* Decoupling of Producers and consumers\n\n![](evt-msg.png)\n\n## Deployments\n\nIn term of event backbone deployment environment we propose different approaches:\n\n* **[IBM Cloud](https://cloud.ibm.com/)** with the [Event Streams service](https://cloud.ibm.com/catalog/services/event-streams).\n    * Deployment discussions for the KC solution are in [this note](https://ibm-cloud-architecture.github.io/refarch-kc/deployments/iks/)\n* **IBM Cloud Private**\n    * [Event Streams deployment](../deployments/eventstreams/README/).\n    * [Zookeeper deployment](../deployments/zookeeper/README/) and [Kafka deployment](../deployments/kafka/README/) for ICP.\n* Running locally with docker compose. See [this note](https://ibm-cloud-architecture.github.io/refarch-kc/deployments/local/) for details.\n","type":"Mdx","contentDigest":"649a5e197f6dbf4e61e9235bba6909a7","counter":245,"owner":"gatsby-plugin-mdx"},"frontmatter":{"title":"Event Backbone","description":"Event Backbone"},"exports":{},"rawBody":"---\ntitle: Event Backbone\ndescription: Event Backbone\n---\n\nThe event backbone is the communication layer in the event driven architecture.  It provides the connection between event driven capabilities and in the *Cloud Native*, it becomes the Pub/Sub communication layer for event driven microservices.\n\nAt this high level we would consider two types of relevant technologies for the event backbone, *Message Brokers* and *Event Logs*.  Both technology types could be used to achieve the event communication style, with the \"Publish and subscribe\" model however, it is also important to consider other capabilities which are frequently used within event driven solutions:\n\n* Keeping an **Event Log** as a time sequenced as it happened recording of events (Source of the truth).\n* Enabling direct **replay** of events.\n* Enabling **Event Sourcing** as a way of recording state changes in distributed systems.\n* Enabling **programmatic access** to the *continuous event stream*.\n\nWhen viewed across these wider event driven capabilities, an event log style technology can provide a central component which can support all of these capabilities, whereas a message broker would have to be extended with other components.\n\n## Defining the Event Backbone for the event driven reference architecture\n\n![](evt-backbone.png)\n\nFor the event driven architecture we defined the following characteristics to be essential for the *event backbone*\n\n* Publish-subscribe event communication between event producers and consumers\n* Facilitate many consumers with shared central “source of truth”.\n* Capability to store events for a given period of time (event log). This is the shared source of the truth for events.\n* Ability for consumers to subscribe to events.\n* Provide replay of events from history for evolving application instances.\n* Provide programmatic access to continuous stream of events, with minimum time lag.\n* Must be highly scalable and resilient to cloud deployment levels.\n\nLooking across these capabilities, the potential technologies, the amount of adoption and community activity around the technologies lead us to selecting *Kafka* as the Open Source technology base for the event backbone.\n\nYou can read more about Apache Kafka project here [https://kafka.apache.org](https://kafka.apache.org)\n\n## Event backbone considerations\n\nWhile choosing an event backbone for your event-driven app development, you need to consider below points,\n\n### Persistence\n\nWhen source systems generate events, the consumers of those are interested in those events may not be online or available at the same time. So you need a way to store these messages for a configurable period of time until they are consumed and acted upon. Event backbone should be able to provide such event persistence.\n\n### Observability\n\nAt times, you need an overall view of how events are ingested by source systems and getting processed by consumers. It could be a management console where events can be observed. Event backbone should provide such observability.\n\n### Fault tolerance\n\nEvent backbone could be made of several components. If one of them becomes unavailable, there should not be any impact on the event processors dependent on the backbone. Event backbone needs to provide this resiliency.\n\n### High availability\n\nEvent backbone provides persistence of messages/events. If one of the components of the backbone becomes unavailable, there should not be any impact on the availability of these messages/events. Event backbone should be highly available.\n\n### Performance\n\nEvent backbone should provide means of accelerating the event processing operations (e.g. parallelising event processing) thereby providing enhanced performance.\n\n### Delivery guarantees\n\nEvent backbone should support guaranteed delivery both for producer and consumer. It should support below delivery guarantees:\n\n* at least once\n* at most once\n* exactly once\n\n### Security\n\nThe data residing in the event backbone should be secured, at rest as well as in transit. Only authenticated and authorized users should be able to publish and consume messages from the backbone. Topic specific authorizations will also help blocking access by unauthorized consumers. Event backbone should provide these security measures.\n\n### Stateful operations for events streams\n\nSometimes, source systems generate a continuous flow of 'inter-related' events (e.g. IoT sensors sending data every second). In order to process such messages correctly, the event backbone needs to support for stateful operations like windowing, joins, aggregations. and any type of real time analytics.\n\n### Ease of development\n\nDeveloping a consumer or a stream application should be straight-forward with the programmatic features that the event backbone provides.\n\n### Ease of deployment\n\nThe installation of event backbone should be an easy to follow process.\n\n### Event routing options\n\nIn EDA, event consumers may not be online at all times. So, it should be easier for consumers to subscribe to a topic when it comes online.\n\n### On-failure hooks\n\nEvent backbone can support pre-configured actions/behaviors for certain messages. E.g. if a consumer fails to process a message more than a certain number of times, that message can be sent to another topic for re-trying the processing action.\n\nPredetermined for unprocessed events (retries, dead-letter queues etc)\n\n### Management plane\n\nEvent backbone can provide a management plane from which infrastrucutre level configurations can be managed.\n\n## Supporting products\n\nThe IBM Event Streams offering provides a *Kafka* service for the Event Backbone. The service is available as a fully managed service within Public cloud and as a supported build for IBM Cloud Private.\n\n* [IBM Event Streams Public Cloud](https://console.bluemix.net/catalog/services/event-streams)\n* [IBM Event Streams Private Cloud](https://www.ibm.com/cloud/event-streams)\n* [See also our own Kafka study article](../kafka/readme/) on how to support high availability and how to deploy to your local environment or to a kubernetes cluster like IBM Cloud Private.\n* [Active MQ Artemis](https://activemq.apache.org/components/artemis/) and our study [notes]()\n\n## Messaging versus event streaming\n\nWe recommend reading [this article](https://developer.ibm.com/messaging/2018/05/18/comparing-messaging-event-streaming-use-cases/) and [this one](https://developer.ibm.com/messaging/2019/02/05/comparing-messaging-pub-sub-and-event-streams/), to get insight between messaging (focusing on operations / actions to be performed by a system or service) versus event (focusing on the state / facts of a system with no knowledge of the downstream processing. To summarize messaging (like MQ) are to support:\n\n* Transient Data – data is only stored until a consumer has processed the message, or it expires\n* Request / reply most of the time\n* Targeted reliable delivery: targeted to the entity that will process the request or receive the response. Reliable with transaction support.\n\nFor events:\n\n* Stream history: consumers are interested by history and not just the most recent event\n* Scalable Consumption: A single event is consumed by many consumers with limited impact as the number of consumers grow.\n* Immutable Data.\n* Decoupling of Producers and consumers\n\n![](evt-msg.png)\n\n## Deployments\n\nIn term of event backbone deployment environment we propose different approaches:\n\n* **[IBM Cloud](https://cloud.ibm.com/)** with the [Event Streams service](https://cloud.ibm.com/catalog/services/event-streams).\n    * Deployment discussions for the KC solution are in [this note](https://ibm-cloud-architecture.github.io/refarch-kc/deployments/iks/)\n* **IBM Cloud Private**\n    * [Event Streams deployment](../deployments/eventstreams/README/).\n    * [Zookeeper deployment](../deployments/zookeeper/README/) and [Kafka deployment](../deployments/kafka/README/) for ICP.\n* Running locally with docker compose. See [this note](https://ibm-cloud-architecture.github.io/refarch-kc/deployments/local/) for details.\n","fileAbsolutePath":"/home/runner/work/refarch-eda/refarch-eda/docs-gatsby/src/pages/evt-backbone/README.mdx"}}}}