{"componentChunkName":"component---src-pages-methodology-governance-index-mdx","path":"/methodology/governance/","result":{"pageContext":{"frontmatter":{"title":"Event driven solution governance","description":"Event driven solution governance"},"relativePagePath":"/methodology/governance/index.mdx","titleType":"append","MdxNode":{"id":"d918b47c-629e-519e-8df0-b6a4c0a1d799","children":[],"parent":"8869d190-a715-5c18-aaec-77f4a6407934","internal":{"content":"---\ntitle: Event driven solution governance\ndescription: Event driven solution governance\n---\n\nDigital businesses are real-time, responsive, scalable and flexible while focussing on delivering\noutstanding customer experience. API and Microservices focus has achieved a lot in enabling\nthis transformation, supporting real-time interactions and increasing levels of agility through\ndecoupling applications. But digital business requires more, it needs to become more timesensitive,\ncontextual and event-driven in nature. Events is how the modern digital business operates, and eventdriven\narchitecture allows IT to align to this.\n\nGovernance involves a lot of different view points, so in this section we will cover what we think are important to govern the development, deployment and maintenance of event-driven solution. The first important question to address is do I need to use event-driven solution? This is what the fit for purpose is about.\n\nMost EDA adoption starts from the adoption of some new programming model based on the reactive manifesto, or by selecting a modern middleware to support loosely coupled microservice, like Kafka, all this in the context of one business application. \nFrom the first successful project, it is important to consider adopting a more strategic approach:\n\n* to select technologies\n* to apply common architecture and design patterns\n* to adopt data models governance and control data lineage\n* to apply common methodology to quickly onboard new business initiative, and be able to deploy new capability on top of the EDA in question of days or weeks. \n\n## Fit for Purpose\n\nIn EDA context the fit for purpose needs to help responding to the high level question on when to use event-driven solution for a new application, but also to address when to use modern pub/sub event backbone versus queuing products, what data stream processing to use, what are the different use cases and benefits.\n\nWe have developed the content in a [separate note](/concepts/fit-to-purpose) as the subject can become long to describe.\n\n## Architecture patterns\n\nWe have already describe in [this section](/introduction/reference-architecture/) as set of event-driven architecture patterns that can be leveraged while establishing EDA practices. \nYou can look at the [extended reference architecture](/introduction/reference-architecture/#extended-architecture) that includes how to integrate with data in topic for doing feature engineering. An example of Jupiter notebook can also be reused for this as described in [this data collection article](https://ibm-cloud-architecture.github.io/vaccine-solution-main/solution/cp4d/eventStream/).\n\nLegacy integration and coexistence between legacy applications or mainframe transactional application and microservices is presented in [this section](/introduction/reference-architecture/#legacy-integration).\n\nThe [modern data pipeline](/introduction/reference-architecture/#modern-data-lake) is also an important architecture pattern where data ingestion layer is the same as the microservice integration middleware and provide buffering capability as well as stateful data stream processing.\n\nFrom an implementation point of view the following design patterns are often part of the EDA adoption:\n\n* [Event sourcing](/patterns/event-sourcing/)\n* [Command Query Responsibility Segregation](/patterns/cqrs/)\n* [Saga pattern](/patterns/saga/)\n* [Transactional outbox](/patterns/intro/#transactional-outbox)\n* [Event reprocessing with dead letter](/patterns/dlq/)\n\nYou can also review the other [microservice patterns in this note](/patterns).\n\n## Getting developers on board\n\n## Data lineage\n\nData governance is a well established practices in most companies. Solutions need to address the following needs:\n\n* Which sources/producers are feeding data?\n* What is the data schema?\n* How to classify data\n* Which process reads the data and how is it transformed?\n* When was the data last updated?\n* Which apps/ users access private data?\n\nIn the context of event-driven architecture, one focus will be to ensure re-use of event topics, \ncontrol the schema definition, have a consistent and governed ways to manage topic as service, \ndomain and event data model definition, access control, encryption and traceability. \nAs this subject is very important, we have started to address it in a [separate 'data lineage' note](/methodology/data-lineage/).\n\n## Deployment Strategy\n\nHybrid cloud, Containerized\n\n\nsecurity and access control\nStrimzi - cruise control\nactive - active\ntopic as self service\n\n## Ongoing Maintenance\n\nProcedures performed regularly to keep a system healthy\nCluster rebalancing\n Add new broker - partition reassignment\n\nProduct migration\n\n\n## Operational Monitoring \n\nassess partition in heavy load\nassess broker in heavy load\nassess partition leadership assignment\n\nProblem identification\nSystem health confirmation\n\n## Error Handling\nProcedures, tools and tactics to resolve problems when they arise","type":"Mdx","contentDigest":"274b4d11100bd63839ad0d0c262a9f5f","owner":"gatsby-plugin-mdx","counter":706},"frontmatter":{"title":"Event driven solution governance","description":"Event driven solution governance"},"exports":{},"rawBody":"---\ntitle: Event driven solution governance\ndescription: Event driven solution governance\n---\n\nDigital businesses are real-time, responsive, scalable and flexible while focussing on delivering\noutstanding customer experience. API and Microservices focus has achieved a lot in enabling\nthis transformation, supporting real-time interactions and increasing levels of agility through\ndecoupling applications. But digital business requires more, it needs to become more timesensitive,\ncontextual and event-driven in nature. Events is how the modern digital business operates, and eventdriven\narchitecture allows IT to align to this.\n\nGovernance involves a lot of different view points, so in this section we will cover what we think are important to govern the development, deployment and maintenance of event-driven solution. The first important question to address is do I need to use event-driven solution? This is what the fit for purpose is about.\n\nMost EDA adoption starts from the adoption of some new programming model based on the reactive manifesto, or by selecting a modern middleware to support loosely coupled microservice, like Kafka, all this in the context of one business application. \nFrom the first successful project, it is important to consider adopting a more strategic approach:\n\n* to select technologies\n* to apply common architecture and design patterns\n* to adopt data models governance and control data lineage\n* to apply common methodology to quickly onboard new business initiative, and be able to deploy new capability on top of the EDA in question of days or weeks. \n\n## Fit for Purpose\n\nIn EDA context the fit for purpose needs to help responding to the high level question on when to use event-driven solution for a new application, but also to address when to use modern pub/sub event backbone versus queuing products, what data stream processing to use, what are the different use cases and benefits.\n\nWe have developed the content in a [separate note](/concepts/fit-to-purpose) as the subject can become long to describe.\n\n## Architecture patterns\n\nWe have already describe in [this section](/introduction/reference-architecture/) as set of event-driven architecture patterns that can be leveraged while establishing EDA practices. \nYou can look at the [extended reference architecture](/introduction/reference-architecture/#extended-architecture) that includes how to integrate with data in topic for doing feature engineering. An example of Jupiter notebook can also be reused for this as described in [this data collection article](https://ibm-cloud-architecture.github.io/vaccine-solution-main/solution/cp4d/eventStream/).\n\nLegacy integration and coexistence between legacy applications or mainframe transactional application and microservices is presented in [this section](/introduction/reference-architecture/#legacy-integration).\n\nThe [modern data pipeline](/introduction/reference-architecture/#modern-data-lake) is also an important architecture pattern where data ingestion layer is the same as the microservice integration middleware and provide buffering capability as well as stateful data stream processing.\n\nFrom an implementation point of view the following design patterns are often part of the EDA adoption:\n\n* [Event sourcing](/patterns/event-sourcing/)\n* [Command Query Responsibility Segregation](/patterns/cqrs/)\n* [Saga pattern](/patterns/saga/)\n* [Transactional outbox](/patterns/intro/#transactional-outbox)\n* [Event reprocessing with dead letter](/patterns/dlq/)\n\nYou can also review the other [microservice patterns in this note](/patterns).\n\n## Getting developers on board\n\n## Data lineage\n\nData governance is a well established practices in most companies. Solutions need to address the following needs:\n\n* Which sources/producers are feeding data?\n* What is the data schema?\n* How to classify data\n* Which process reads the data and how is it transformed?\n* When was the data last updated?\n* Which apps/ users access private data?\n\nIn the context of event-driven architecture, one focus will be to ensure re-use of event topics, \ncontrol the schema definition, have a consistent and governed ways to manage topic as service, \ndomain and event data model definition, access control, encryption and traceability. \nAs this subject is very important, we have started to address it in a [separate 'data lineage' note](/methodology/data-lineage/).\n\n## Deployment Strategy\n\nHybrid cloud, Containerized\n\n\nsecurity and access control\nStrimzi - cruise control\nactive - active\ntopic as self service\n\n## Ongoing Maintenance\n\nProcedures performed regularly to keep a system healthy\nCluster rebalancing\n Add new broker - partition reassignment\n\nProduct migration\n\n\n## Operational Monitoring \n\nassess partition in heavy load\nassess broker in heavy load\nassess partition leadership assignment\n\nProblem identification\nSystem health confirmation\n\n## Error Handling\nProcedures, tools and tactics to resolve problems when they arise","fileAbsolutePath":"/home/runner/work/refarch-eda/refarch-eda/docs/src/pages/methodology/governance/index.mdx"}}},"staticQueryHashes":["1054721580","1054721580","1364590287","2102389209","2102389209","2456312558","2746626797","2746626797","3018647132","3018647132","3037994772","3037994772","768070550"]}