{"componentChunkName":"component---src-pages-technology-event-streams-es-cloud-mdx","path":"/technology/event-streams/es-cloud/","result":{"pageContext":{"frontmatter":{"title":"Event Streams on Cloud hands on lab","description":"Hands on lab to configure Event Streams on Cloud"},"relativePagePath":"/technology/event-streams/es-cloud.mdx","titleType":"append","MdxNode":{"id":"6ea0b282-76a2-5f85-9f18-2f2ce26adb23","children":[],"parent":"3279e90c-6751-566f-985e-677825a222e4","internal":{"content":"---\ntitle: Event Streams on Cloud hands on lab\ndescription: Hands on lab to configure Event Streams on Cloud\n---\n\nThis documentation aims to be a introductory hands-on lab on IBM Event Streams on Cloud with topic creation.\n\n## Index\n\n<AnchorLinks>\n  <AnchorLink>Pre-requisites</AnchorLink>\n  <AnchorLink>Create a Event Streams service instance</AnchorLink>\n  <AnchorLink>Creating Event Streams instance with IBM Cloud CLI</AnchorLink>\n  <AnchorLink>Create topic</AnchorLink>\n  <AnchorLink>Create topic with CLI</AnchorLink>\n</AnchorLinks>\n\n## Pre-requisites\n\nThis lab requires the following components to work against:\n\n1. An IBM Cloud account. Get a IBM Cloud Account by using the register link in [https://cloud.ibm.com/login](https://cloud.ibm.com/login)\nCreate a new account is free of charge. \n\n![](./images/ic-login.png)\n\nOn your development workstation you will need:\n\n1. IBM Cloud CLI (<https://cloud.ibm.com/docs/cli?topic=cloud-cli-getting-started>)\n1. IBM CLoud CLI Event Streams plugin (`ibmcloud plugin install event-streams`)\n\n### Login CLI\n\n```\nibmcoud login\n```\n\n### Account and resource group concepts\n\nAs any other IBM Cloud services, Event Streams can be part of a resources group, is controlled by user roles, and is accessible via API keys. \nTo get familiar with those concepts, it is recommended to study [the concepts of IBM account](https://cloud.ibm.com/docs/account?topic=account-overview) \nand how it is related to resource group and services. The following diagram is a summary of the objects managed in IBM Cloud:\n\n![](https://cloud.ibm.com/docs/api/content/account/images/account_diagram.svg)\n\nTo summarize:\n\n* Account represents the billable entity, and can have multiple users.\n* Users are given access to resource groups.\n* Applications are identified with a service ID.\n* To restrict permissions for using specific services, you can assign specific access policies to the service ID and user ID\n* Resource groups are here to organize any type of resources (services, clusters, VMs...) that are managed by  Identity and Access Management (IAM).\n* Resource groups are not scoped by location\n* Access group are used to organize a set of users and service IDs into a single entity and easily assign permissions\n\n## Create a Event Streams service instance\n\nFrom the IBM Cloud Dashboard page, you can create a new resource, using the right top button `Create resource`. \n\n![D](./images/ic-dashboard.png)\n\nwhich leads to the service and feature catalog. From there in the `services` view, select the `integration` \ncategory and then the `Event Streams` tile:\n\n![C](./images/ic-catalog.png)\n\nYou can access this screen from this URL: [https://cloud.ibm.com/catalog/event-streams](https://cloud.ibm.com/catalog/event-streams).\n\n### Plan characteristics\n\nWithin the first page for the Event Streams creation, you need to select the region, the pricing plan, a service name and the resource group.\n\n![C2](./images/es-create-1.png)\n\nFor the region, it is important to note that the 'lite' plan is available only in Dallas, and it used to do some proof of concept. \nIt is recommended to select a region close to your on-premise data center. For the Plan description, \nthe [product documentation](https://cloud.ibm.com/docs/EventStreams?topic=eventstreams-plan_choose) goes over the different plans in details.\n\nThe 'multi-tenancy' means the Kafka cluster is shared with other people. The cluster topology is covering multi availability zones inside\nthe same data center. The following diagram illustrates a simple view of this topology with the different network zones and availability zones:\n\n![T](./images/es-topology.png)\n\nWe will address fine-grained access control in [the security lab](security).\n\nAs described in the [Kafka concept introduction](https://cloud.ibm.com/docs/EventStreams?topic=eventstreams-apache_kafka), topic may have partitions.\nPartitions are used to improve throughput as consumer can run in parallel, and producer can publish to multiple partitions.\n\nThe plan set a limit on the total number of partitions. \n\nEach partition records, are persisted in the file system and so the maximum time records are kept on disks is controlled by the maximum retention period and total size. Those Kafka configurations are described in the\n[topic and broker documentation](https://kafka.apache.org/documentation/#topicconfigs). \n\nFro the Standard plan, the first page has also a price estimator. The two important concepts used for pricing are the number of  partition instances and the number of GB consumed: each consumer reading from a topic/partition will increase the number of byte consumed. The cost is per month.\n\n### Creating Event Streams instance with IBM Cloud CLI\n\n1. Go to IBM Cloud and click on the user avatar on the top right corner. Then, click on _Log in to CLI and API_ option:\n\n   ![1](./images/1.png)\n\n1. Copy the `IBM Cloud CLI` login command\n\n   ![2](./images/2.png)\n\n1. Open a terminal window, paste and execute the command:\n\n\t```shell\n\t$ ibmcloud login -a https://cloud.ibm.com -u passcode -p XsgEKGb84Z\n\tAPI endpoint: https://cloud.ibm.com\n\tAuthenticating...\n\tOK\n\n\tTargeted account bill s Account (b63...) <-> 195...\n\tSelect a region (or press enter to skip):\n\t1. au-syd\n\t2. in-che\n\t3. jp-osa\n\t4. jp-tok\n\t5. kr-seo\n\t6. eu-de\n\t7. eu-gb\n\t8. us-south\n\t9. us-south-test\n\t10. us-east\n\tEnter a number> 6\n\tTargeted region eu-de\n\n\tAPI endpoint:      https://cloud.ibm.com\n\tRegion:            eu-de\n\tUser:              A<>\n\tAccount:           Bill s Account (b63...) <-> 195...\n\tResource group:    No resource group targeted, use ibmcloud target -g RESOURCE_GROUP\n\tCF API endpoint:\n\tOrg:\n\tSpace:\n\t```\n\n1. List your services with `ibmcloud resource service-instances` and make sure your IBM Event Streams instance is listed:\n\n\t```shell\n\t$ ibmcloud resource service-instances\n\tRetrieving instances with type service_instance in all resource groups in all locations under account Kedar Kulkarni's Account as ALMARAZJ@ie.ibm.com...\n\tOK\n\tName                                   Location   State    Type\n\tIBM Cloud Monitoring with Sysdig-rgd   us-south   active   service_instance\n\tapikey for simple toolchain            us-east    active   service_instance\n\taapoc-event-streams                    us-south   active   service_instance\n\tEvent Streams-wn                       eu-de      active   service_instance\n\t```\n\n\tWe can see our instance called: **Event Streams-wn**\n\n1. Create an Event Streams instance using CLI\n\n\t```shell\n\tibmcloud resource service-instance-create EventStreamsEDA2 messagehub standard us-south\n\t```\n\n1. List your IBM Event Streams instance details with `ibmcloud resource service-instance <instance_name>`:\n\n\t```shell\n\t$ ibmcloud resource service-instance Event\\ Streams-wn \n\tRetrieving service instance Event Streams-wn in all resource groups under account Kedar Kulkarni's Account as ALMARAZJ@ie.ibm.com...\n\tOK\n\n\tName:                  Event Streams-wn\n\tID:                    crn:v1:bluemix:public:messagehub:eu-de:a/b636d1d8...cfa:b05be9...2e687a::\n\tGUID:                  b05be932...e687a\n\tLocation:              eu-de\n\tService Name:          messagehub\n\tService Plan Name:     enterprise-3nodes-2tb\n\tResource Group Name:\n\tState:                 active\n\tType:                  service_instance\n\tSub Type:\n\tCreated at:            2020-05-11T15:54:48Z\n\tCreated by:            bob.the.builder@someemail.com\n\tUpdated at:            2020-05-11T16:49:18Z\n\tLast Operation:\n\t\t\t\t\t\tStatus    sync succeeded\n\t\t\t\t\t\tMessage   Synchronized the instance\n\t```\n\tMind the `\\` character in your IBM Event Streams instance.\n\n1. Initialize your IBM Event Streams plugin for the IBM Cloud CLI with `ibmcloud es init`:\n\n\t```shell\n\t$ ibmcloud es init\n\n\tSelect an Event Streams instance:\n\t1. Event Streams-2t\n\t2. Event Streams-wn\n\t3. aapoc-event-streams\n\t4. tutorial\n\tEnter a number> 2\n\tAPI Endpoint: \thttps://mh-tcqsppdpzlrkdmkb.....175-0000.eu-de.containers.appdomain.cloud\n\tOK\n\t```\n\n1. Check all the CLI commands available to you to manage and interact with your IBM Event Streams instance with `$ ibmcloud es`:\n\n\t```shell\n\t$ ibmcloud es\n\tNAME:\n\tibmcloud es - Plugin for IBM Event Streams (build 1908221834)\n\n\tUSAGE:\n\tibmcloud es command [arguments...] [command options]\n\n\tCOMMANDS:\n\tbroker                 Display details of a broker.\n\tbroker-config          Display broker configuration.\n\tcluster                Display details of the cluster.\n\tgroup                  Display details of a consumer group.\n\tgroup-delete           Delete a consumer group.\n\tgroup-reset            Reset the offsets for a consumer group.\n\tgroups                 List the consumer groups.\n\tinit                   Initialize the IBM Event Streams plugin.\n\ttopic                  Display details of a topic.\n\ttopic-create           Create a new topic.\n\ttopic-delete           Delete a topic.\n\ttopic-delete-records   Delete records from a topic before a given offset.\n\ttopic-partitions-set   Set the partitions for a topic.\n\ttopic-update           Update the configuration for a topic.\n\ttopics                 List the topics.\n\thelp, h                Show help\n\n\tEnter 'ibmcloud es help [command]' for more information about a command.\n\t```\n\n1. List your cluster configuration with `$ ibmcloud es cluster`:\n\n\t```shell\n\t$ ibmcloud es cluster\n\tDetails for cluster\n\tCluster ID                                                      Controller\n\tmh-tcqsppdpzlrkdmkbgmgl-4c20...361c6f175-0000   0\n\n\tDetails for brokers\n\tID   Host                                                                                                     Port   Rack\n\t0    kafka-0.mh-tcqsppdpzlrkdmkbgmgl-4c201a12d......22e361c6f175-0000.eu-de.containers.appdomain.cloud   9093   fra05\n\t1    kafka-1.mh-tcqsppdpzlrkdmkbgmgl-4c201a12d......22e361c6f175-0000.eu-de.containers.appdomain.cloud   9093   fra02\n\t2    kafka-2.mh-tcqsppdpzlrkdmkbgmgl-4c201a12d......22e361c6f175-0000.eu-de.containers.appdomain.cloud   9093   fra04\n\tNo cluster-wide dynamic configurations found.\n\t```\n1. Looking at broker details: `ibmcloud es broker  0`:\n\n\t```shell\n\tibmcloud es broker  0\n\t\tDetails for broker\n\t\tID   Host                                                                        Port   Rack   \n\t\t0    broker-0-t19zgvnykgdqy1zl.kafka.svc02.us-south.eventstreams.cloud.ibm.com   9093   dal10   \n\n\t\tDetails for broker configuration\n\t\tName                   Value                                                                                            Sensitive?   \n\t\tbroker.id              0                                                                                                false   \n\t\tbroker.rack            dal10                                                                                            false   \n\t\tadvertised.listeners   SASL_EXTERNAL://broker-0-t19zgvnykgdqy1zl.kafka.svc02.us-south.eventstreams.cloud.ibm.com:9093   false   \n\t\tOK\n\n\t```\n\n1. Get detail view of a broker configuration: `ibmcloud es broker-config  0`\n\nWe will see other CLI commands in future labs.\n\n### Coming back another time\n\nWhen coming back to the IBM Cloud dashboard the simplest way to find the Event Streams service is to go \nto the `Services`:\n\n![3](./images/3.png)\n\n* Click on your IBM Event Streams instance:\n\n![4](./images/4.png)\n\n* Click on _Launch Dashboard_ button to open the IBM Event Streams dashboard\n\n![5](./images/5.png)\n\n### Main Event Streams Dashboard page\n\nOnce the instance is created, or when you come back to the service, you reach the `manage`panel, as illustrated in previous figure.\n\nFrom the Dashboard we can access the _Topics_ and _Consumer groups_ panels.\n\n![](./images/es-manage.png)\n\n## Create topic\n\nIn this section we are going to see how to create, list and delete topics both using the User Interface and then the IBM Event Streams CLI.\n\n1. Open the IBM Event Streams user interface (go into your IBM Event Streams service within your IBM Cloud portal and click on the launch dashboard button). Once there, click on the _Topics_ tab from the top menu:\n\n\t![12-0](images/7.png)\n\nLet create a `demo-topic-ui` topic. If you need to revisit the topic concepts, you can read [this note](http://localhost:8000/technology/kafka-overview/#topics). When you go to the topics view you get the list of existing topics.\n\n![](./images/es-topics.png)\n\nFrom this list an administrator can delete an existing topic or create new one. \n\n1. The 'create topic' button leads to the step by step process. \n1. Switch to the _Advanced_ mode to get access to the complete set of parameters. The first panel is here to define the core configuration\n\n![](./images/es-create-topic-1.png)\n\nSome parameters to understand:\n\n* **Number of partitions**: the default value should be 1. If the data can be partitioned without loosing semantic, you can increase the number of partitions.\n* **Retention time**: This is how long messages are retained before they are deleted to free up space. If your messages are not read \nby a consumer within this time, they will be missed. It is mapped to the [retention.ms](https://kafka.apache.org/documentation/#retention.ms) kafka topic configuration.\n\nThe bottom part of the configuration page, includes _logs, cleanup_ and _indexing_.\n\n![](./images/es-create-topic-2.png)\n\n* The partition's log parameter section includes a [cleanup policy](https://kafka.apache.org/documentation/#cleanup.policy) that could be:\n    * delete: discard old segments when their retention time or size limit has been reached\n    * compact: retain at least the last known value for each message key within the log of data for a single topic partition. The topic looks like a table in DB.\n    * compact, delete: compact the log and remove old records\n\n* [retention bytes](https://kafka.apache.org/documentation/#retention.bytes): represents the maximum size a partition (which consists of log segments) can grow to, before old log segments will be discarded to free up space.\n* [log segment size](https://kafka.apache.org/documentation/#segment.bytes) is the maximum size in bytes of a single log file. \n* [Cleanup segment time - segment.ms](https://kafka.apache.org/documentation/#segment.ms) controls the period of time after which Kafka will force the log to roll, even if the segment file isn't full, this is to ensure that retention can delete or compact old data.\n* [Index - segment.index.bytes](https://kafka.apache.org/documentation.html#segment.index.bytes)controls the size of the index that maps offsets to file positions.\n\nThe log cleaner policy is supported by a log cleaner, which are threads that recopy log segment files, removing records whose key appears in the head of the log.\n\nThe number of replications is set to three with a `min-in-sync` replicas of two.\n\n<InlineNotification kind=\"info\">A message is considered committed when all in sync replicas for that partition have applied it to their log. The leader maintains a set of in-sync-replicas: all the nodes which are up-to-date with the leader’s log, and actively acknowledging new writes. Every write goes through the leader and is propagated to every node in the In Sync Replica set, or ISR. \n</InlineNotification>\n\n![142](./images/isr.png)\n\n1. We can now see our new topic:\n\n\t![15](./images/15.png)\n\n1. To delete a topic, click on the topic options button at the right end of a topic, click on _Delete this topic_ and then on the _Delete_ button in the confirmation pop-up window:\n\n\t![16](./images/16.png)\n\n1. The topic should now be deleted:\n\n\t![16-1](./images/7.png)\n\n### Create topic with CLI\n\n1. List your topics with `$ ibmcloud es topics`:\n\n\t```shell\n\t$ ibmcloud es topics\n\tOK\n\tNo topics found.\n\t```\n1. Create a topic: (Default 1 partition - 3 replicas)\n\n\t```shell\n\t$ ibmcloud es topic-create --name demo-topic\n\tCreated topic demo-topic\n\tOK\n\t```\n\t\\* Execute `$ ibmcloud es topic-create --help` for more further configuration of your topic creation\n\n1. List topics:\n\n\t```shell\n\t$ ibmcloud es topics\n\tTopic name\n\tdemo-topic\n\tOK\n\t```\n\n1. Display details of a topic:\n\n\t```shell\n\t$ ibmcloud es topic demo-topic\n\tDetails for topic demo-topic\n\tTopic name   Internal?   Partition count   Replication factor\n\tdemo-topic   false       1                 3\n\n\tPartition details for topic demo-topic\n\tPartition ID   Leader   Replicas   In-sync\n\t0              2        [2 1 0]    [2 1 0]\n\n\tConfiguration parameters for topic demo-topic\n\tName                  Value\n\tcleanup.policy        delete\n\tmin.insync.replicas   2\n\tsegment.bytes         536870912\n\tretention.ms          86400000\n\tretention.bytes       1073741824\n\tOK\n\t```\n\n1. Delete records in a topic (in the command below, we want to delete record on a partition 0 offset 5 and partition 1 from offset 0):\n\n\t```shell\n\t$ ibmcloud es topic-delete-records --name demo-topic --partition-offset 1:0;0:5 --force\n\t```\n\n1. Add partitions to an existing topic, by setting the new target number of partition: \n\n\t```shell\n\t$ ibmcloud es topic-partition-set --name demo-topic --partitions 30\n\t```\n\n1. Delete a topic:\n\n\t```shell\n\t$ ibmcloud es topic-delete demo-topic\n\tReally delete topic 'demo-topic'? [y/N]> y\n\tTopic demo-topic deleted successfully\n\tOK\n\t```\n\n1. List topics:\n\n\t```shell\n\t$ ibmcloud es topics\n\tOK\n\tNo topics found.\n\t```\n\nFor the last list of commands see the [CLI Reference manual](https://cloud.ibm.com/docs/EventStreams?topic=eventstreams-cli_reference#cli_reference).\n\n## Getting started applications\n\nFrom the manage dashboard we can download a getting started application that has two processes: one consumer and one producer, or we can use a second application that we have in [this repository](https://github.com/ibm-cloud-architecture/refarch-eda-tools)\n\n### Using the Event Streams on cloud getting started app\n\nTo be able to build the code you need to get [gradle](https://gradle.org/install) installed or use the docker image:\n\n```\ndocker run --rm -u gradle -v \"$PWD\":/home/gradle/project -w /home/gradle/project gradle gradle <gradle-task>\n```\n\nThe instructions are in [this documentation](https://cloud.ibm.com/docs/EventStreams?topic=EventStreams-getting_started#eventstreams) and can be summarized as:\n\n* Clone the github repository:\n\n```shell\ngit clone https://github.com/ibm-messaging/event-streams-samples.git\n```\n\n* Build the code:\n\nUsing the gradle CLI\n```shell\ncd kafka-java-console-sample\ngradle clean && gradle build\n```\n\nor the gradle docker image\n\n```shell\ndocker run --rm -u gradle -v \"$PWD\":/home/gradle/project -w /home/gradle/project gradle gradle build\n```\n\n* Start consumer\n\n```shell\njava -jar ./build/libs/kafka-java-console-sample-2.0.jar broker-0-qnprtqnp7hnkssdz.kafka.svc01.us-east.eventstreams.cloud.ibm.com:9093,broker-1-qnprtqnp7hnkssdz.kafka.svc01.us-east.eventstreams.cloud.ibm.com:9093,broker-2-qnprtqnp7hnkssdz.kafka.svc01.us-east.eventstreams.cloud.ibm.com:9093 am_rbb9e794mMwhE-KGPYo0hhW3h91e28OhT8IlruFe5 -consumer\n```\n\n* Start producer\n\n```shell\njava -jar ./build/libs/kafka-java-console-sample-2.0.jar broker-0-qnprtqnp7hnkssdz.kafka.svc01.us-east.eventstreams.cloud.ibm.com:9093,broker-1-qnprtqnp7hnkssdz.kafka.svc01.us-east.eventstreams.cloud.ibm.com:9093,broker-2-qnprtqnp7hnkssdz.kafka.svc01.us-east.eventstreams.cloud.ibm.com:9093 am_rbb9e794mMwhE-KGPYo0hhW3h91e28OhT8IlruFe5 -producer\n```","type":"Mdx","contentDigest":"b024e4588d306afda34068b0239853d4","counter":422,"owner":"gatsby-plugin-mdx"},"frontmatter":{"title":"Event Streams on Cloud hands on lab","description":"Hands on lab to configure Event Streams on Cloud"},"exports":{},"rawBody":"---\ntitle: Event Streams on Cloud hands on lab\ndescription: Hands on lab to configure Event Streams on Cloud\n---\n\nThis documentation aims to be a introductory hands-on lab on IBM Event Streams on Cloud with topic creation.\n\n## Index\n\n<AnchorLinks>\n  <AnchorLink>Pre-requisites</AnchorLink>\n  <AnchorLink>Create a Event Streams service instance</AnchorLink>\n  <AnchorLink>Creating Event Streams instance with IBM Cloud CLI</AnchorLink>\n  <AnchorLink>Create topic</AnchorLink>\n  <AnchorLink>Create topic with CLI</AnchorLink>\n</AnchorLinks>\n\n## Pre-requisites\n\nThis lab requires the following components to work against:\n\n1. An IBM Cloud account. Get a IBM Cloud Account by using the register link in [https://cloud.ibm.com/login](https://cloud.ibm.com/login)\nCreate a new account is free of charge. \n\n![](./images/ic-login.png)\n\nOn your development workstation you will need:\n\n1. IBM Cloud CLI (<https://cloud.ibm.com/docs/cli?topic=cloud-cli-getting-started>)\n1. IBM CLoud CLI Event Streams plugin (`ibmcloud plugin install event-streams`)\n\n### Login CLI\n\n```\nibmcoud login\n```\n\n### Account and resource group concepts\n\nAs any other IBM Cloud services, Event Streams can be part of a resources group, is controlled by user roles, and is accessible via API keys. \nTo get familiar with those concepts, it is recommended to study [the concepts of IBM account](https://cloud.ibm.com/docs/account?topic=account-overview) \nand how it is related to resource group and services. The following diagram is a summary of the objects managed in IBM Cloud:\n\n![](https://cloud.ibm.com/docs/api/content/account/images/account_diagram.svg)\n\nTo summarize:\n\n* Account represents the billable entity, and can have multiple users.\n* Users are given access to resource groups.\n* Applications are identified with a service ID.\n* To restrict permissions for using specific services, you can assign specific access policies to the service ID and user ID\n* Resource groups are here to organize any type of resources (services, clusters, VMs...) that are managed by  Identity and Access Management (IAM).\n* Resource groups are not scoped by location\n* Access group are used to organize a set of users and service IDs into a single entity and easily assign permissions\n\n## Create a Event Streams service instance\n\nFrom the IBM Cloud Dashboard page, you can create a new resource, using the right top button `Create resource`. \n\n![D](./images/ic-dashboard.png)\n\nwhich leads to the service and feature catalog. From there in the `services` view, select the `integration` \ncategory and then the `Event Streams` tile:\n\n![C](./images/ic-catalog.png)\n\nYou can access this screen from this URL: [https://cloud.ibm.com/catalog/event-streams](https://cloud.ibm.com/catalog/event-streams).\n\n### Plan characteristics\n\nWithin the first page for the Event Streams creation, you need to select the region, the pricing plan, a service name and the resource group.\n\n![C2](./images/es-create-1.png)\n\nFor the region, it is important to note that the 'lite' plan is available only in Dallas, and it used to do some proof of concept. \nIt is recommended to select a region close to your on-premise data center. For the Plan description, \nthe [product documentation](https://cloud.ibm.com/docs/EventStreams?topic=eventstreams-plan_choose) goes over the different plans in details.\n\nThe 'multi-tenancy' means the Kafka cluster is shared with other people. The cluster topology is covering multi availability zones inside\nthe same data center. The following diagram illustrates a simple view of this topology with the different network zones and availability zones:\n\n![T](./images/es-topology.png)\n\nWe will address fine-grained access control in [the security lab](security).\n\nAs described in the [Kafka concept introduction](https://cloud.ibm.com/docs/EventStreams?topic=eventstreams-apache_kafka), topic may have partitions.\nPartitions are used to improve throughput as consumer can run in parallel, and producer can publish to multiple partitions.\n\nThe plan set a limit on the total number of partitions. \n\nEach partition records, are persisted in the file system and so the maximum time records are kept on disks is controlled by the maximum retention period and total size. Those Kafka configurations are described in the\n[topic and broker documentation](https://kafka.apache.org/documentation/#topicconfigs). \n\nFro the Standard plan, the first page has also a price estimator. The two important concepts used for pricing are the number of  partition instances and the number of GB consumed: each consumer reading from a topic/partition will increase the number of byte consumed. The cost is per month.\n\n### Creating Event Streams instance with IBM Cloud CLI\n\n1. Go to IBM Cloud and click on the user avatar on the top right corner. Then, click on _Log in to CLI and API_ option:\n\n   ![1](./images/1.png)\n\n1. Copy the `IBM Cloud CLI` login command\n\n   ![2](./images/2.png)\n\n1. Open a terminal window, paste and execute the command:\n\n\t```shell\n\t$ ibmcloud login -a https://cloud.ibm.com -u passcode -p XsgEKGb84Z\n\tAPI endpoint: https://cloud.ibm.com\n\tAuthenticating...\n\tOK\n\n\tTargeted account bill s Account (b63...) <-> 195...\n\tSelect a region (or press enter to skip):\n\t1. au-syd\n\t2. in-che\n\t3. jp-osa\n\t4. jp-tok\n\t5. kr-seo\n\t6. eu-de\n\t7. eu-gb\n\t8. us-south\n\t9. us-south-test\n\t10. us-east\n\tEnter a number> 6\n\tTargeted region eu-de\n\n\tAPI endpoint:      https://cloud.ibm.com\n\tRegion:            eu-de\n\tUser:              A<>\n\tAccount:           Bill s Account (b63...) <-> 195...\n\tResource group:    No resource group targeted, use ibmcloud target -g RESOURCE_GROUP\n\tCF API endpoint:\n\tOrg:\n\tSpace:\n\t```\n\n1. List your services with `ibmcloud resource service-instances` and make sure your IBM Event Streams instance is listed:\n\n\t```shell\n\t$ ibmcloud resource service-instances\n\tRetrieving instances with type service_instance in all resource groups in all locations under account Kedar Kulkarni's Account as ALMARAZJ@ie.ibm.com...\n\tOK\n\tName                                   Location   State    Type\n\tIBM Cloud Monitoring with Sysdig-rgd   us-south   active   service_instance\n\tapikey for simple toolchain            us-east    active   service_instance\n\taapoc-event-streams                    us-south   active   service_instance\n\tEvent Streams-wn                       eu-de      active   service_instance\n\t```\n\n\tWe can see our instance called: **Event Streams-wn**\n\n1. Create an Event Streams instance using CLI\n\n\t```shell\n\tibmcloud resource service-instance-create EventStreamsEDA2 messagehub standard us-south\n\t```\n\n1. List your IBM Event Streams instance details with `ibmcloud resource service-instance <instance_name>`:\n\n\t```shell\n\t$ ibmcloud resource service-instance Event\\ Streams-wn \n\tRetrieving service instance Event Streams-wn in all resource groups under account Kedar Kulkarni's Account as ALMARAZJ@ie.ibm.com...\n\tOK\n\n\tName:                  Event Streams-wn\n\tID:                    crn:v1:bluemix:public:messagehub:eu-de:a/b636d1d8...cfa:b05be9...2e687a::\n\tGUID:                  b05be932...e687a\n\tLocation:              eu-de\n\tService Name:          messagehub\n\tService Plan Name:     enterprise-3nodes-2tb\n\tResource Group Name:\n\tState:                 active\n\tType:                  service_instance\n\tSub Type:\n\tCreated at:            2020-05-11T15:54:48Z\n\tCreated by:            bob.the.builder@someemail.com\n\tUpdated at:            2020-05-11T16:49:18Z\n\tLast Operation:\n\t\t\t\t\t\tStatus    sync succeeded\n\t\t\t\t\t\tMessage   Synchronized the instance\n\t```\n\tMind the `\\` character in your IBM Event Streams instance.\n\n1. Initialize your IBM Event Streams plugin for the IBM Cloud CLI with `ibmcloud es init`:\n\n\t```shell\n\t$ ibmcloud es init\n\n\tSelect an Event Streams instance:\n\t1. Event Streams-2t\n\t2. Event Streams-wn\n\t3. aapoc-event-streams\n\t4. tutorial\n\tEnter a number> 2\n\tAPI Endpoint: \thttps://mh-tcqsppdpzlrkdmkb.....175-0000.eu-de.containers.appdomain.cloud\n\tOK\n\t```\n\n1. Check all the CLI commands available to you to manage and interact with your IBM Event Streams instance with `$ ibmcloud es`:\n\n\t```shell\n\t$ ibmcloud es\n\tNAME:\n\tibmcloud es - Plugin for IBM Event Streams (build 1908221834)\n\n\tUSAGE:\n\tibmcloud es command [arguments...] [command options]\n\n\tCOMMANDS:\n\tbroker                 Display details of a broker.\n\tbroker-config          Display broker configuration.\n\tcluster                Display details of the cluster.\n\tgroup                  Display details of a consumer group.\n\tgroup-delete           Delete a consumer group.\n\tgroup-reset            Reset the offsets for a consumer group.\n\tgroups                 List the consumer groups.\n\tinit                   Initialize the IBM Event Streams plugin.\n\ttopic                  Display details of a topic.\n\ttopic-create           Create a new topic.\n\ttopic-delete           Delete a topic.\n\ttopic-delete-records   Delete records from a topic before a given offset.\n\ttopic-partitions-set   Set the partitions for a topic.\n\ttopic-update           Update the configuration for a topic.\n\ttopics                 List the topics.\n\thelp, h                Show help\n\n\tEnter 'ibmcloud es help [command]' for more information about a command.\n\t```\n\n1. List your cluster configuration with `$ ibmcloud es cluster`:\n\n\t```shell\n\t$ ibmcloud es cluster\n\tDetails for cluster\n\tCluster ID                                                      Controller\n\tmh-tcqsppdpzlrkdmkbgmgl-4c20...361c6f175-0000   0\n\n\tDetails for brokers\n\tID   Host                                                                                                     Port   Rack\n\t0    kafka-0.mh-tcqsppdpzlrkdmkbgmgl-4c201a12d......22e361c6f175-0000.eu-de.containers.appdomain.cloud   9093   fra05\n\t1    kafka-1.mh-tcqsppdpzlrkdmkbgmgl-4c201a12d......22e361c6f175-0000.eu-de.containers.appdomain.cloud   9093   fra02\n\t2    kafka-2.mh-tcqsppdpzlrkdmkbgmgl-4c201a12d......22e361c6f175-0000.eu-de.containers.appdomain.cloud   9093   fra04\n\tNo cluster-wide dynamic configurations found.\n\t```\n1. Looking at broker details: `ibmcloud es broker  0`:\n\n\t```shell\n\tibmcloud es broker  0\n\t\tDetails for broker\n\t\tID   Host                                                                        Port   Rack   \n\t\t0    broker-0-t19zgvnykgdqy1zl.kafka.svc02.us-south.eventstreams.cloud.ibm.com   9093   dal10   \n\n\t\tDetails for broker configuration\n\t\tName                   Value                                                                                            Sensitive?   \n\t\tbroker.id              0                                                                                                false   \n\t\tbroker.rack            dal10                                                                                            false   \n\t\tadvertised.listeners   SASL_EXTERNAL://broker-0-t19zgvnykgdqy1zl.kafka.svc02.us-south.eventstreams.cloud.ibm.com:9093   false   \n\t\tOK\n\n\t```\n\n1. Get detail view of a broker configuration: `ibmcloud es broker-config  0`\n\nWe will see other CLI commands in future labs.\n\n### Coming back another time\n\nWhen coming back to the IBM Cloud dashboard the simplest way to find the Event Streams service is to go \nto the `Services`:\n\n![3](./images/3.png)\n\n* Click on your IBM Event Streams instance:\n\n![4](./images/4.png)\n\n* Click on _Launch Dashboard_ button to open the IBM Event Streams dashboard\n\n![5](./images/5.png)\n\n### Main Event Streams Dashboard page\n\nOnce the instance is created, or when you come back to the service, you reach the `manage`panel, as illustrated in previous figure.\n\nFrom the Dashboard we can access the _Topics_ and _Consumer groups_ panels.\n\n![](./images/es-manage.png)\n\n## Create topic\n\nIn this section we are going to see how to create, list and delete topics both using the User Interface and then the IBM Event Streams CLI.\n\n1. Open the IBM Event Streams user interface (go into your IBM Event Streams service within your IBM Cloud portal and click on the launch dashboard button). Once there, click on the _Topics_ tab from the top menu:\n\n\t![12-0](images/7.png)\n\nLet create a `demo-topic-ui` topic. If you need to revisit the topic concepts, you can read [this note](http://localhost:8000/technology/kafka-overview/#topics). When you go to the topics view you get the list of existing topics.\n\n![](./images/es-topics.png)\n\nFrom this list an administrator can delete an existing topic or create new one. \n\n1. The 'create topic' button leads to the step by step process. \n1. Switch to the _Advanced_ mode to get access to the complete set of parameters. The first panel is here to define the core configuration\n\n![](./images/es-create-topic-1.png)\n\nSome parameters to understand:\n\n* **Number of partitions**: the default value should be 1. If the data can be partitioned without loosing semantic, you can increase the number of partitions.\n* **Retention time**: This is how long messages are retained before they are deleted to free up space. If your messages are not read \nby a consumer within this time, they will be missed. It is mapped to the [retention.ms](https://kafka.apache.org/documentation/#retention.ms) kafka topic configuration.\n\nThe bottom part of the configuration page, includes _logs, cleanup_ and _indexing_.\n\n![](./images/es-create-topic-2.png)\n\n* The partition's log parameter section includes a [cleanup policy](https://kafka.apache.org/documentation/#cleanup.policy) that could be:\n    * delete: discard old segments when their retention time or size limit has been reached\n    * compact: retain at least the last known value for each message key within the log of data for a single topic partition. The topic looks like a table in DB.\n    * compact, delete: compact the log and remove old records\n\n* [retention bytes](https://kafka.apache.org/documentation/#retention.bytes): represents the maximum size a partition (which consists of log segments) can grow to, before old log segments will be discarded to free up space.\n* [log segment size](https://kafka.apache.org/documentation/#segment.bytes) is the maximum size in bytes of a single log file. \n* [Cleanup segment time - segment.ms](https://kafka.apache.org/documentation/#segment.ms) controls the period of time after which Kafka will force the log to roll, even if the segment file isn't full, this is to ensure that retention can delete or compact old data.\n* [Index - segment.index.bytes](https://kafka.apache.org/documentation.html#segment.index.bytes)controls the size of the index that maps offsets to file positions.\n\nThe log cleaner policy is supported by a log cleaner, which are threads that recopy log segment files, removing records whose key appears in the head of the log.\n\nThe number of replications is set to three with a `min-in-sync` replicas of two.\n\n<InlineNotification kind=\"info\">A message is considered committed when all in sync replicas for that partition have applied it to their log. The leader maintains a set of in-sync-replicas: all the nodes which are up-to-date with the leader’s log, and actively acknowledging new writes. Every write goes through the leader and is propagated to every node in the In Sync Replica set, or ISR. \n</InlineNotification>\n\n![142](./images/isr.png)\n\n1. We can now see our new topic:\n\n\t![15](./images/15.png)\n\n1. To delete a topic, click on the topic options button at the right end of a topic, click on _Delete this topic_ and then on the _Delete_ button in the confirmation pop-up window:\n\n\t![16](./images/16.png)\n\n1. The topic should now be deleted:\n\n\t![16-1](./images/7.png)\n\n### Create topic with CLI\n\n1. List your topics with `$ ibmcloud es topics`:\n\n\t```shell\n\t$ ibmcloud es topics\n\tOK\n\tNo topics found.\n\t```\n1. Create a topic: (Default 1 partition - 3 replicas)\n\n\t```shell\n\t$ ibmcloud es topic-create --name demo-topic\n\tCreated topic demo-topic\n\tOK\n\t```\n\t\\* Execute `$ ibmcloud es topic-create --help` for more further configuration of your topic creation\n\n1. List topics:\n\n\t```shell\n\t$ ibmcloud es topics\n\tTopic name\n\tdemo-topic\n\tOK\n\t```\n\n1. Display details of a topic:\n\n\t```shell\n\t$ ibmcloud es topic demo-topic\n\tDetails for topic demo-topic\n\tTopic name   Internal?   Partition count   Replication factor\n\tdemo-topic   false       1                 3\n\n\tPartition details for topic demo-topic\n\tPartition ID   Leader   Replicas   In-sync\n\t0              2        [2 1 0]    [2 1 0]\n\n\tConfiguration parameters for topic demo-topic\n\tName                  Value\n\tcleanup.policy        delete\n\tmin.insync.replicas   2\n\tsegment.bytes         536870912\n\tretention.ms          86400000\n\tretention.bytes       1073741824\n\tOK\n\t```\n\n1. Delete records in a topic (in the command below, we want to delete record on a partition 0 offset 5 and partition 1 from offset 0):\n\n\t```shell\n\t$ ibmcloud es topic-delete-records --name demo-topic --partition-offset 1:0;0:5 --force\n\t```\n\n1. Add partitions to an existing topic, by setting the new target number of partition: \n\n\t```shell\n\t$ ibmcloud es topic-partition-set --name demo-topic --partitions 30\n\t```\n\n1. Delete a topic:\n\n\t```shell\n\t$ ibmcloud es topic-delete demo-topic\n\tReally delete topic 'demo-topic'? [y/N]> y\n\tTopic demo-topic deleted successfully\n\tOK\n\t```\n\n1. List topics:\n\n\t```shell\n\t$ ibmcloud es topics\n\tOK\n\tNo topics found.\n\t```\n\nFor the last list of commands see the [CLI Reference manual](https://cloud.ibm.com/docs/EventStreams?topic=eventstreams-cli_reference#cli_reference).\n\n## Getting started applications\n\nFrom the manage dashboard we can download a getting started application that has two processes: one consumer and one producer, or we can use a second application that we have in [this repository](https://github.com/ibm-cloud-architecture/refarch-eda-tools)\n\n### Using the Event Streams on cloud getting started app\n\nTo be able to build the code you need to get [gradle](https://gradle.org/install) installed or use the docker image:\n\n```\ndocker run --rm -u gradle -v \"$PWD\":/home/gradle/project -w /home/gradle/project gradle gradle <gradle-task>\n```\n\nThe instructions are in [this documentation](https://cloud.ibm.com/docs/EventStreams?topic=EventStreams-getting_started#eventstreams) and can be summarized as:\n\n* Clone the github repository:\n\n```shell\ngit clone https://github.com/ibm-messaging/event-streams-samples.git\n```\n\n* Build the code:\n\nUsing the gradle CLI\n```shell\ncd kafka-java-console-sample\ngradle clean && gradle build\n```\n\nor the gradle docker image\n\n```shell\ndocker run --rm -u gradle -v \"$PWD\":/home/gradle/project -w /home/gradle/project gradle gradle build\n```\n\n* Start consumer\n\n```shell\njava -jar ./build/libs/kafka-java-console-sample-2.0.jar broker-0-qnprtqnp7hnkssdz.kafka.svc01.us-east.eventstreams.cloud.ibm.com:9093,broker-1-qnprtqnp7hnkssdz.kafka.svc01.us-east.eventstreams.cloud.ibm.com:9093,broker-2-qnprtqnp7hnkssdz.kafka.svc01.us-east.eventstreams.cloud.ibm.com:9093 am_rbb9e794mMwhE-KGPYo0hhW3h91e28OhT8IlruFe5 -consumer\n```\n\n* Start producer\n\n```shell\njava -jar ./build/libs/kafka-java-console-sample-2.0.jar broker-0-qnprtqnp7hnkssdz.kafka.svc01.us-east.eventstreams.cloud.ibm.com:9093,broker-1-qnprtqnp7hnkssdz.kafka.svc01.us-east.eventstreams.cloud.ibm.com:9093,broker-2-qnprtqnp7hnkssdz.kafka.svc01.us-east.eventstreams.cloud.ibm.com:9093 am_rbb9e794mMwhE-KGPYo0hhW3h91e28OhT8IlruFe5 -producer\n```","fileAbsolutePath":"/home/runner/work/refarch-eda/refarch-eda/docs/src/pages/technology/event-streams/es-cloud.mdx"}}}}