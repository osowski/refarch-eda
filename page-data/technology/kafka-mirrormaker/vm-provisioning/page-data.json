{"componentChunkName":"component---src-pages-technology-kafka-mirrormaker-vm-provisioning-mdx","path":"/technology/kafka-mirrormaker/vm-provisioning/","result":{"pageContext":{"frontmatter":{"title":"Standalone VM Based Installation of Mirror Maker 2","description":"Install Mirror Maker 2 on Virtual Machine"},"relativePagePath":"/technology/kafka-mirrormaker/vm-provisioning.mdx","titleType":"append","MdxNode":{"id":"6bf18d75-d54a-5a47-ba5d-49da0d3a6b59","children":[],"parent":"cd728dfe-1a7a-5084-b798-2ff5af65848e","internal":{"content":"---\ntitle: Standalone VM Based Installation of Mirror Maker 2\ndescription: Install Mirror Maker 2 on Virtual Machine\n---\n\nHere we are showing how to install and configure Kafka Mirror Maker 2 in a cluster on VMs.  We will also show how to test the Mirror Maker 2 cluster for resiliency, and finally how to perform a rolling upgrade of the Mirror Maker 2 nodes.\n\n\n## Environment\n\nThe environment we’re using is as follows:\n\n* A remote IBM Event Streams cluster on IBM Cloud as the source cluster\n* A local Kafka 2.4 cluster deployed on OpenShift using the Strimzi v0.17 Operator\n* 2x dedicated Linux VMs for running a clustered pair of Mirror Maker 2 nodes\n* A dedicated Linux VM to act as a data stream producer\n* A dedicated Linux VM to act as a data stream consumer\n* Java VMs are already installed on all VMs\n* On the Producer VM, we use a simple producer sample provided by IBM for use with Event Streams:  [https://github.com/ibm-messaging/event-streams-samples](https://github.com/ibm-messaging/event-streams-samples)\n* On the Consumer VM and Mirror Maker VMs, we use the Client and Cluster Certificates from the Kafka cluster merged into a PKCS 12 format certificate file.  \n\n\nFirst, start the producer to start sending data to the remote Event Streams cluster.  On the Producer VM, start streaming data to Event Streams:\n\n![1](./images/vm-1.png)\n\nNote the specific brokers and the authentication token used have been blacked-out.  We’ll let this producer run in the background producing one message per second.\n\nNext we’ll set up the first Mirror Maker 2 node.  To install Mirror Maker, we’re just downloading the Kafka 2.4 distribution from Apache directly:  [https://www.apache.org/dyn/closer.cgi?path=/kafka/2.4.1/kafka_2.12-2.4.1.tgz](https://www.apache.org/dyn/closer.cgi?path=/kafka/2.4.1/kafka_2.12-2.4.1.tgz)\n\nWe’ll untar the archive into /opt and create a symlink.  Also, set the PATH to include the new Kafka package.\n\n![2](./images/vm-2.png)\n\nNow we will create a Mirror Maker 2 configuration file based on the sample provided in /opt/kafka/config/connect-mirror-maker.properties and add some options.  The full configuration is below:\n\n```properties \n# Run with ./bin/connect-mirror-maker.sh connect-mirror-maker.properties \n\n# specify any number of cluster aliases\nclusters = kp-remote,kp-local\n\n# connection information for each cluster\n# This is a comma separated host:port pairs for each cluster\n# for e.g. \"A_host1:9092, A_host2:9092, A_host3:9092\"\n\n#\n# KP Remote Cluster\n# IES on IBM Cloud\n#\n\nkp-remote.bootstrap.servers = broker-3 ... eventstreams.cloud.ibm.com:9093\nkp-remote.ssl.enabled.protocols=TLSv1.2\nkp-remote.ssl.protocol=TLS\nkp-remote.security.protocol=SASL_SSL\nkp-remote.sasl.mechanism=PLAIN\nkp-remote.sasl.jaas.config=org.apache.kafka.common.security.plain.PlainLoginModule  required \\\n  username=\"token\" \\\n  password=\"hCJ ... KtS\";\n\n#\n# KP Local Cluster\n# Kafka 2.4 on OpenShift using Strimzi 0.17 Operator\n#\n\nkp-local.bootstrap.servers = kp-local-kafka-bootstrap-kp-local-kafka.apps. ... :443\nkp-local.ssl.enabled.protocols=TLSv1.2\nkp-local.ssl.protocol=TLS\nkp-local.security.protocol=SSL\nkp-local.ssl.truststore.location = truststore.p12\nkp-local.ssl.truststore.password = cz ... Hi\nkp-remote->kp-local.tasks.max = 3\nkp-remote->kp-local.group.id=mirrormaker2-cluster\n\n# enable and configure individual replication flows\nkp-remote->kp-local.enabled = true\n# regex which defines which topics gets replicated. For eg \"foo-.*\"\nkp-remote->kp-local.topics = .*\n# Setting replication factor of newly created remote topics\nreplication.factor=3\n############################# Internal Topic Settings  #############################\n# The replication factor for mm2 internal topics \"heartbeats\", \"B.checkpoints.internal\" and\n# \"mm2-offset-syncs.B.internal\"\n# For anything other than development testing, a value greater than 1 is recommended to ensure availability such as 3.\ncheckpoints.topic.replication.factor=3\nheartbeats.topic.replication.factor=3\noffset-syncs.topic.replication.factor=3\n\n# The replication factor for connect internal topics \"mm2-configs.B.internal\", \"mm2-offsets.B.internal\" and\n# \"mm2-status.B.internal\"\n# For anything other than development testing, a value greater than 1 is recommended to ensure availability such as 3.\noffset.storage.replication.factor=3\nstatus.storage.replication.factor=3\nconfig.storage.replication.factor=3\n\n# customize as needed\n# replication.policy.separator = _\nsync.topic.acls.enabled = false\n# emit.heartbeats.interval.seconds = 5\n```\n\nNote that passwords and API keys have been obscured as well as hostnames.  This configuration file, along with the trust store for connecting to our local Kafka cluster, is all that is needed to replicate topics from the remote EventStreams cluster to the local Kafka cluster.  We start the Mirror Maker 2 cluster and wait for it to finish initializing:\n\n```shell\n./bin/connect-mirror-maker.sh mm2.properties\n```\n\nOnce it finishes initializing, we should see messages like the following:\n\n![3](./images/vm-3.png)\n\nTo show that replication is occurring, we will create a consumer on the Consumer VM.  Install Kafka as shown above and use the built-in console consumer to view the replicated messages from the local Kafka cluster.   To run the consumer, we use the same PKCS 12 certificate file to authenticate to the local cluster, and a local-consumer.properties file that is shown below:\n\n```properties\nclient.id=test-consumer-1\nssl.enabled.protocols=TLSv1.2\nsecurity.protocol=SSL\nssl.protocol=TLS\nssl.truststore.location=truststore.p12\nssl.truststore.password=cz...\n```\nRun the consumer command:\n\n![4](./images/vm-4.png)\n\nNotice that the topic name in this case is `kp-remote.kp-topic-1` instead of just `kp-topic-1`.  This is because we’re monitoring the replicated version of `kp-topic-1` from the remote EventStreams cluster.  Mirror Maker 2 automatically prepends the alias of the remote cluster as it is labeled in the Mirror Maker 2 configuration file.  In this case, the alias was `kp-remote`, so the replicated topic `kp-topic-1` is named `kp-remote.kp-topic-1`.\n\nWe can see the test messages from the producer that is writing to EventStreams are being replicated successfully to our local Kafka cluster.\n\n\n```shell\n./bin/connect-mirror-maker.sh mm2.properties\n```\n\n## Restarting Mirror Maker 2\n\nNow that replication is running successfully and we have both a producer and consumer running to view the traffic in real time, we can set up a second Mirror Maker 2 node.  The process is exactly the same as the first Mirror Maker 2 node, and the configuration file is also exactly the same.\n\nNow that both instances of Mirror Maker 2 are running, we can verify that both instances are able to assume the load by stopping the first Mirror Maker 2 instance we created, verifying that replication is still occurring, restarting it, and finally stopping the second instance.  This will show that as long as at least one instance of Mirror Maker 2 is running we have successful replication.\n\nFrom the Consumer:\n\n![5](./images/vm-5.png)\n\nNow we stop the first Mirror Maker 2, and verify that replication is still occurring via the Consumer VM: \n\n![6](./images/vm-6.png)\n\nReplication continued as expected.  Now we restart Mirror Maker 2 on Node 1, and stop it on Node 2, and check the consumer is still getting records.\n","type":"Mdx","contentDigest":"08ad405dd2dcfee4e170ffbb3c1a8269","owner":"gatsby-plugin-mdx","counter":737},"frontmatter":{"title":"Standalone VM Based Installation of Mirror Maker 2","description":"Install Mirror Maker 2 on Virtual Machine"},"exports":{},"rawBody":"---\ntitle: Standalone VM Based Installation of Mirror Maker 2\ndescription: Install Mirror Maker 2 on Virtual Machine\n---\n\nHere we are showing how to install and configure Kafka Mirror Maker 2 in a cluster on VMs.  We will also show how to test the Mirror Maker 2 cluster for resiliency, and finally how to perform a rolling upgrade of the Mirror Maker 2 nodes.\n\n\n## Environment\n\nThe environment we’re using is as follows:\n\n* A remote IBM Event Streams cluster on IBM Cloud as the source cluster\n* A local Kafka 2.4 cluster deployed on OpenShift using the Strimzi v0.17 Operator\n* 2x dedicated Linux VMs for running a clustered pair of Mirror Maker 2 nodes\n* A dedicated Linux VM to act as a data stream producer\n* A dedicated Linux VM to act as a data stream consumer\n* Java VMs are already installed on all VMs\n* On the Producer VM, we use a simple producer sample provided by IBM for use with Event Streams:  [https://github.com/ibm-messaging/event-streams-samples](https://github.com/ibm-messaging/event-streams-samples)\n* On the Consumer VM and Mirror Maker VMs, we use the Client and Cluster Certificates from the Kafka cluster merged into a PKCS 12 format certificate file.  \n\n\nFirst, start the producer to start sending data to the remote Event Streams cluster.  On the Producer VM, start streaming data to Event Streams:\n\n![1](./images/vm-1.png)\n\nNote the specific brokers and the authentication token used have been blacked-out.  We’ll let this producer run in the background producing one message per second.\n\nNext we’ll set up the first Mirror Maker 2 node.  To install Mirror Maker, we’re just downloading the Kafka 2.4 distribution from Apache directly:  [https://www.apache.org/dyn/closer.cgi?path=/kafka/2.4.1/kafka_2.12-2.4.1.tgz](https://www.apache.org/dyn/closer.cgi?path=/kafka/2.4.1/kafka_2.12-2.4.1.tgz)\n\nWe’ll untar the archive into /opt and create a symlink.  Also, set the PATH to include the new Kafka package.\n\n![2](./images/vm-2.png)\n\nNow we will create a Mirror Maker 2 configuration file based on the sample provided in /opt/kafka/config/connect-mirror-maker.properties and add some options.  The full configuration is below:\n\n```properties \n# Run with ./bin/connect-mirror-maker.sh connect-mirror-maker.properties \n\n# specify any number of cluster aliases\nclusters = kp-remote,kp-local\n\n# connection information for each cluster\n# This is a comma separated host:port pairs for each cluster\n# for e.g. \"A_host1:9092, A_host2:9092, A_host3:9092\"\n\n#\n# KP Remote Cluster\n# IES on IBM Cloud\n#\n\nkp-remote.bootstrap.servers = broker-3 ... eventstreams.cloud.ibm.com:9093\nkp-remote.ssl.enabled.protocols=TLSv1.2\nkp-remote.ssl.protocol=TLS\nkp-remote.security.protocol=SASL_SSL\nkp-remote.sasl.mechanism=PLAIN\nkp-remote.sasl.jaas.config=org.apache.kafka.common.security.plain.PlainLoginModule  required \\\n  username=\"token\" \\\n  password=\"hCJ ... KtS\";\n\n#\n# KP Local Cluster\n# Kafka 2.4 on OpenShift using Strimzi 0.17 Operator\n#\n\nkp-local.bootstrap.servers = kp-local-kafka-bootstrap-kp-local-kafka.apps. ... :443\nkp-local.ssl.enabled.protocols=TLSv1.2\nkp-local.ssl.protocol=TLS\nkp-local.security.protocol=SSL\nkp-local.ssl.truststore.location = truststore.p12\nkp-local.ssl.truststore.password = cz ... Hi\nkp-remote->kp-local.tasks.max = 3\nkp-remote->kp-local.group.id=mirrormaker2-cluster\n\n# enable and configure individual replication flows\nkp-remote->kp-local.enabled = true\n# regex which defines which topics gets replicated. For eg \"foo-.*\"\nkp-remote->kp-local.topics = .*\n# Setting replication factor of newly created remote topics\nreplication.factor=3\n############################# Internal Topic Settings  #############################\n# The replication factor for mm2 internal topics \"heartbeats\", \"B.checkpoints.internal\" and\n# \"mm2-offset-syncs.B.internal\"\n# For anything other than development testing, a value greater than 1 is recommended to ensure availability such as 3.\ncheckpoints.topic.replication.factor=3\nheartbeats.topic.replication.factor=3\noffset-syncs.topic.replication.factor=3\n\n# The replication factor for connect internal topics \"mm2-configs.B.internal\", \"mm2-offsets.B.internal\" and\n# \"mm2-status.B.internal\"\n# For anything other than development testing, a value greater than 1 is recommended to ensure availability such as 3.\noffset.storage.replication.factor=3\nstatus.storage.replication.factor=3\nconfig.storage.replication.factor=3\n\n# customize as needed\n# replication.policy.separator = _\nsync.topic.acls.enabled = false\n# emit.heartbeats.interval.seconds = 5\n```\n\nNote that passwords and API keys have been obscured as well as hostnames.  This configuration file, along with the trust store for connecting to our local Kafka cluster, is all that is needed to replicate topics from the remote EventStreams cluster to the local Kafka cluster.  We start the Mirror Maker 2 cluster and wait for it to finish initializing:\n\n```shell\n./bin/connect-mirror-maker.sh mm2.properties\n```\n\nOnce it finishes initializing, we should see messages like the following:\n\n![3](./images/vm-3.png)\n\nTo show that replication is occurring, we will create a consumer on the Consumer VM.  Install Kafka as shown above and use the built-in console consumer to view the replicated messages from the local Kafka cluster.   To run the consumer, we use the same PKCS 12 certificate file to authenticate to the local cluster, and a local-consumer.properties file that is shown below:\n\n```properties\nclient.id=test-consumer-1\nssl.enabled.protocols=TLSv1.2\nsecurity.protocol=SSL\nssl.protocol=TLS\nssl.truststore.location=truststore.p12\nssl.truststore.password=cz...\n```\nRun the consumer command:\n\n![4](./images/vm-4.png)\n\nNotice that the topic name in this case is `kp-remote.kp-topic-1` instead of just `kp-topic-1`.  This is because we’re monitoring the replicated version of `kp-topic-1` from the remote EventStreams cluster.  Mirror Maker 2 automatically prepends the alias of the remote cluster as it is labeled in the Mirror Maker 2 configuration file.  In this case, the alias was `kp-remote`, so the replicated topic `kp-topic-1` is named `kp-remote.kp-topic-1`.\n\nWe can see the test messages from the producer that is writing to EventStreams are being replicated successfully to our local Kafka cluster.\n\n\n```shell\n./bin/connect-mirror-maker.sh mm2.properties\n```\n\n## Restarting Mirror Maker 2\n\nNow that replication is running successfully and we have both a producer and consumer running to view the traffic in real time, we can set up a second Mirror Maker 2 node.  The process is exactly the same as the first Mirror Maker 2 node, and the configuration file is also exactly the same.\n\nNow that both instances of Mirror Maker 2 are running, we can verify that both instances are able to assume the load by stopping the first Mirror Maker 2 instance we created, verifying that replication is still occurring, restarting it, and finally stopping the second instance.  This will show that as long as at least one instance of Mirror Maker 2 is running we have successful replication.\n\nFrom the Consumer:\n\n![5](./images/vm-5.png)\n\nNow we stop the first Mirror Maker 2, and verify that replication is still occurring via the Consumer VM: \n\n![6](./images/vm-6.png)\n\nReplication continued as expected.  Now we restart Mirror Maker 2 on Node 1, and stop it on Node 2, and check the consumer is still getting records.\n","fileAbsolutePath":"/home/runner/work/refarch-eda/refarch-eda/docs/src/pages/technology/kafka-mirrormaker/vm-provisioning.mdx"}}},"staticQueryHashes":["1054721580","1054721580","1364590287","2102389209","2102389209","2456312558","2746626797","2746626797","3018647132","3018647132","3037994772","3037994772","768070550"]}