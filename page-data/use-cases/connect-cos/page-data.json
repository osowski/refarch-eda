{"componentChunkName":"component---src-pages-use-cases-connect-cos-index-mdx","path":"/use-cases/connect-cos/","result":{"pageContext":{"frontmatter":{"title":"Kafka Connect to IBM COS","description":"Apache Kafka to IBM Cloud Object Storage Source Connector usecase"},"relativePagePath":"/use-cases/connect-cos/index.mdx","titleType":"append","MdxNode":{"id":"59a7d688-86ad-5326-a261-a86bcbd504a8","children":[],"parent":"ad3d5018-6410-5bb0-ac3c-ce3730f16020","internal":{"content":"---\ntitle: Kafka Connect to IBM COS \ndescription: Apache Kafka to IBM Cloud Object Storage Source Connector usecase\n---\n\n<AnchorLinks>\n  <AnchorLink>Overview</AnchorLink>\n  <AnchorLink>Scenario Prerequisites</AnchorLink>\n  <AnchorLink>Creating Event Streams Topics</AnchorLink>\n  <AnchorLink>Event Streams Security: API Key, Credentials and Certificates</AnchorLink>\n  <AnchorLink>Creating the Quarkus with MicroProfile Reactive Messaging Application</AnchorLink>\n  <AnchorLink>Setting up the Kafka Strimzi Operator</AnchorLink>\n  <AnchorLink>Setting up the Kafka Connect Cluster</AnchorLink>\n  <AnchorLink>Building and Applying IBM COS Sink Connector</AnchorLink>\n  <AnchorLink>Event Streams v10 Addendum</AnchorLink>\n  <AnchorLink>Test the Entire Flow</AnchorLink>\n</AnchorLinks>\n\n## Overview\n- Now that you have an Event Streams instance installed on Cloud Pak for Integration on top of OpenShift Container Platform the goal of this story is to show a possible use case that we can use with this technology.\n- With IBM Event Streams we have access to the powerful capabilities of Kafka in addition to all the monitoring and logging capabilities that IBM provides on top of that with Event Streams.\n- We will create a simple Quarkus (a super sonic and sub-atomic Kubernetes native framework for Java) application that utilizes MicroProfile Reactive Messaging in order for us to send a stream of data to our Event Streams/Kafka topic.\n- We will then create a Kafka Connect cluster using the Strimzi Operator.\n- Lastly we'll send messages to an Event Streams topic from our Quarkus application which then triggers the IBM COS Connector to grab messages and place into an IBM COS Bucket.\n\n![Architecture Diagram](./images/quarkus-to-event-streams-to-cos.png)\n\n\n## Scenario Prerequisites\n**OpenShift Container Platform Cluster** \n  - This scenario will assume you have a 4.x Cluster as we will make use of Operators, though this one is 4.3 specifically.\n  \n**Cloud Pak for Integration**\n  - This will assume you have probably at least a 2019.4.1 or 2020.x.x release of the Cloud Pak for Integration installed on OpenShift. This story will also assume you have followed the installation instructions for Event Streams outlined in [the 2020-2 product documentation](https://ibm.github.io/event-streams/installing/installing/) or from the [Cloud Pak Playbook](https://cloudpak8s.io/integration/cp4i-deploy-eventstreams/) and have a working Event Streams instance.\n  \n**Java**\n  - Java Development Kit (JDK) v1.8+ (Java 8+)\n\n**Maven**\n  - The scenario uses Maven v3.6.3\n\n**Gradle**\n  - Ideally v4.0+ (Note - the gradle shadowJar command might not work on Java 13)\n\n**An IDE of your choice**\n  - Visual Studio Code is used in this scenario.\n\n**Git**\n  - We will need to clone repositories.\n\n**An IBM Cloud Account (free)**\n  - A free (Lite) IBM Cloud Object Storage trial Service account [IBM Cloud Object Storage](https://cloud.ibm.com/catalog/services/cloud-object-storage)\n\n\n## Creating Event Streams Topics\n\nSee instructions in [the common pre-requisite section](../overview/pre-requisites/#creating-event-streams-topics)\n\n## Event Streams Security: API Key, Credentials and Certificates\n\n- To connect to our Event Streams Instance we will need to follow a few steps to properly connect to it.\n\n- While viewing our Event Streams Instance, navigate to the Topics menu from the left. Click Connect to this Cluster - \n\n![Connect to this Cluster](./images/esv10-connect-to-cluster.png)\n\n- Make sure that you're on **External Connection** as we will need to test/connect from an application on a local machine. Keep note of your **Bootstrap Server Address**. Save this somewhere as we will need this later to configure our Quarkus Application's connection to the Event Streams instance.\n\n\n- Generate your **SCRAM Credentials**. Click the `Generate SCRAM Credentials` button.\n\n![Generate SCRAM1 ](./images/esv10-generate-scram.png)\n\n- Select a name for your secret and make sure you rmeember/take note of it as we will need this later. Also choose the Produce, Consume, Create Topics and Schema Option.\n\n![Generate SCRAM 2](./images/esv10-scram-1.png)\n\n- Select `All Topics` and then click Next.\n\n![Generate SCRAM 3](./images/esv10-scram-2.png)\n\n- Leave it with `All Consumer Groups` and click Next.\n\n- Generate your **API Key**. Click the Generate API Key button.\n\n![Generate SCRAM 5](./images/esv10-scram-4.png)\n\n- Select a name for your application. It doesn't really matter too much what you name it. Also choose the Produce, Consume, Create Topics and Schema Option.\n\n- If this error occurs, log into your OpenShift cluster and go to the project/namespace that your Event Streams v10 instance is installed in. If you run these commands you will see your secret.\n\n`oc get kafkauser`\n\n\n`oc get secrets`\n\n- Your `SCRAM Username` that we will need for later is the name of your secret. The `SCRAM Password` can be either obtained by going to your OpenShift Console Web UI and revealing the password through the secrets menu or through the CLI. Run the following commands to see the value of the password.\n\n`oc get secret your-secret -o yaml | grep password`\n\n- This will return you a base64 encoded value. Decode this like so\n\n`echo \"dWpPN3ZSSEF1clRK\" | base64 -d`\n\n![SCRAM Secret](./images/esv10-scram-secret.png)\n\n\n- Lastly download the PKCS12 truststore .pkcs12 certificate. Once you hit the Download button the password to the truststore will be revealed. **Copy this down** as we will need it.\n\n![PKCS12 Truststore](./images/esv10-pkcs12.png)\n\n\n\n**Summary** \n- We now have the bootstrap server address, SCRAM Username (also the name of the KafkaUser/Secret CRs) and Password, .pcks12 truststore certificate, and the truststore password associated with that certificate to allow us the ability to connect to our Event Streams instance.\n\n\n\n## Creating the Quarkus with MicroProfile Reactive Messaging Application \n- Create the Quarkus project. You can replace {} and the contents inside of {} with whatever you would like.\n\n```bash\nmvn io.quarkus:quarkus-maven-plugin:1.6.0.Final:create \\\n    -DprojectGroupId={org.acme} \\\n    -DprojectArtifactId={quarkus-kafka} \\\n    -Dextensions=\"kafka\"\n```\n\n- Open the project in your IDE of choice. \n\n- Create the following folder structure and then create the Producer.java file.\n\n```bash\nsrc/main/java/org/acme/kafka/producer/Producer.java\n```\n\n![Quarkus Project Folder Structure](./images/quarkus-folder-structure.png)\n\n\n- Within your Producer.java file add the following code - \n\n```java\npackage org.acme.kafka.producer;\n\nimport io.reactivex.Flowable;\nimport io.smallrye.reactive.messaging.kafka.KafkaRecord;\n\nimport org.eclipse.microprofile.reactive.messaging.Outgoing;\n\nimport javax.enterprise.context.ApplicationScoped;\nimport java.util.Random;\nimport java.util.concurrent.TimeUnit;\n\n/**\n * This class produces a message every 5 seconds.\n * The Kafka configuration is specified in the application.properties file.\n*/\n@ApplicationScoped\npublic class Producer {\n\n    private Random random = new Random();\n\n    @Outgoing(\"{TOPIC-NAME}\")      \n    public Flowable<KafkaRecord<Integer, String>> generate() {\n        return Flowable.interval(5, TimeUnit.SECONDS)    \n                .onBackpressureDrop()\n                .map(tick -> {      \n                    return KafkaRecord.of(random.nextInt(100), String.valueOf(random.nextInt(100)));\n                });\n    }                  \n}\n\n```\n\nTake note on the line that says @Outgoing(\"{TOPIC-NAME}\"). For the purposes of this story we will use the INBOUND topic name that we created in the Event Streams Topic step earlier. Replace whatever is inside the quotation marks.\n\n```java\n@Outgoing(\"INBOUND\")\n```\n\nThe @Outgoing annotation is for specifying the name of the Channel, but it will default to that Channel's name if a topic name is not provided in the application.properties file. We will address that a little bit later.\n\n\n* What does this Producer.java code do? \n   - The @Outgoing annotation indicates that we're sending to a Channel (or Topic) and we're not expecting any data.\n   - The generate() function returns an [RX Java 2 Flowable Object](https://www.baeldung.com/rxjava-2-flowable) emmitted every 5 seconds. \n   - The Flowable object returns a KafkaRecord of type key type Integer and value type String.\n   \n   \n- We will now need to update our applications.properties file that was automatically generated when the Quarkus project was created located here - \n\n```bash\nsrc/main/resources/application.properties\n```\n\n![application properties structure](./images/application-properties-structure.png)\n\n- Copy and paste the following into your application.properties file - \n\n```properties\n# Event Streams Connection details\nmp.messaging.connector.smallrye-kafka.bootstrap.servers=${BOOTSTRAP_SERVERS}\nmp.messaging.connector.smallrye-kafka.security.protocol=SASL_SSL\nmp.messaging.connector.smallrye-kafka.ssl.protocol=TLSv1.2\nmp.messaging.connector.smallrye-kafka.sasl.mechanism=PLAIN\nmp.messaging.connector.smallrye-kafka.sasl.jaas.config=org.apache.kafka.common.security.scram.PlainLoginModule required \\\n                username=\"token\" \\\n                password=${APIKey};\nmp.messaging.connector.smallrye-kafka.ssl.truststore.location=${CERT_LOCATION}\nmp.messaging.connector.smallrye-kafka.ssl.truststore.password=password\n\n\n# Initial mock JSON message producer configuration\nmp.messaging.outgoing.INBOUND.connector=smallrye-kafka\nmp.messaging.outgoing.INBOUND.topic=${TOPIC_NAME}\nmp.messaging.outgoing.INBOUND.value.serializer=io.quarkus.kafka.client.serialization.JsonbSerializer\n```\n\n*Note* - These values that we are configuring can be used with environmental variables. We will export them, or you can choose to hardcode them.\n   \n```shell\nexport BOOTSTRAP_SERVERS={your-bootstrap-server-address} \\\nexport TOPIC_NAME=INBOUND \\ \nexport CERT_LOCATION={your-path-to-es-cert}/es-cert.jks \\\nexport APIKey={your-api-key}\n```\n\n- Replace the values and export the following environment variables. Note that while `TOPIC_NAME` is INBOUND in this case, if we omit this configuration property `mp.messaging.outgoing.INBOUND.topic=${TOPIC_NAME}`, it will default to the channel name as the topic. In this case it will default to `INBOUND`. You can choose to specify a different topic name from the `INBOUND` topic if you so choose. \n\n- Great! We now have our simple Quarkus Kafka Producer with our Event Streams credentials. We can now test the connection.\n\n- Run the producer code by running the following command \n\n```bash\n./mvnw quarkus:dev\n```\n\n- Since the code sends a message every 5 seconds, you can leave it on for a bit or you can change it to send it more frequently. Check out the Event Streams instance in the browser UI topic for messages. You can click the message under \"Indexed Timestamp\" to see the contents and details of the message.\n\n![ES Topic Messages](./images/event-streams-topic-messages.png)\n\n\n\n## Creating an IBM COS Service and COS Bucket for your IBM Cloud Account\n\nThis story assumes that you already have an IBM Cloud account already, and if not you can sign up for one here at [IBM Cloud](https://cloud.ibm.com).\n\n- Once inside your IBM Cloud account, traverse to the `Catalog` section.\n\n- In the search type in `IBM Cloud Object Storage`\n\n![IBM COS Catalog Search](./images/ibm-cloud-create-cos-service.png)\n\n- Name your IBM COS Service with something unique. Since this is a free account we can stick with the Lite Plan.\n\n![IBM COS Create COS Service](./images/ibm-cloud-create-cos-service-2.png)\n\n- Now that the IBM Cloud Object Storage Service is created, traverse to it and let's create a new bucket. \n\n\n- On the `Create Bucket` screen pick `Custom Bucket`.\n\n![IBM COS Custom Bucket](./images/ibm-cos-create-bucket.png)\n\n- When selecting options for the bucket, name your bucket something unique. For `Resiliency` let's select `Regional`. For location select an area from the drop-down that you want. (IMPORTANT) For `Storage Class` select `Standard`. The IBM COS Sink connector seems to not play well with buckets that are created with the `Smart Tier` Storage Class. Leave everything else as-is and hit `Create Bucket`.\n\n![IBM COS Custom Bucket Settings](./images/ibm-cos-bucket-settings.png)\n\n\n\n\n## Creating IBM Cloud Service Credentials\n\nNow that we have created our IBM Cloud Object Storage Service and bucket we now need to create the Service Credential so that we can connect to it.\n\n- Inside your IBM COS Service, select `Service Credentials` and then click the `New Credential` button.\n\n![IBM COS Service Credential](./images/ibm-cos-create-service-cred.png)\n\n- Name your credential and select `Manager` from the `Role:` drop-down menu and click `Add`.\n\n![IBM COS SC Settings](./images/ibm-cos-service-credentials.png)\n\n- Expand your newly created Service Credential and write down the values for `\"apikey\"` and `\"resource_instance_id\"`.\n\n![Expanded Service Cred](./images/ibm-service-credential-keys.png)\n\n\n### Summary\n\nWe've created the IBM COS Service, created a COS Bucket, and created our Service Credentials. Here are the following items we need to configure our IBM COS connector.\n\n\n- IBM COS Bucket name\n- IBM COS Bucket location\n- IBM COS Resiliency (regional)\n- IBM COS Service CRN (resource_instance_id)\n- IBM COS API Key\n\n\n\n## Setting up the Kafka Strimzi Operator\n\n*Note* - This scenario uses an OCP 4.3 cluster, CP4I2020.1.1 and Event Streams v2019.4.2 so this Strimzi installation step\nmay not be necessary if you are on OCP 4.4, CP4I2020.2.1 as well as Event Streams v10 (which is operator based and built on top of Strimzi)\n\n- As part of the pre-requisites this assumes that you have a 4.x OpenShift Container Platform cluster we will use the Strimzi Operator to deploy our Kafka cluster. \n\n- In your OpenShift Web Console, in the \"ADMINISTRATOR\" view. This is in the top left most portion of the menu. Go to \"Operators\" > \"OperatorHub\".\n\n![OperatorHub](./images/operator-hub.png)\n\n- Type \"Strimzi\" into the Search Bar.\n\n![Strimzi](./images/strimzi.png)\n\n- Click on the Strimzi Operator and then click \"Install\".\n\n![Operator Install](./images/operator-install.png)\n\n- Make sure that the option to have \"All namespaces on the cluster (default)\" is checked.\n\n![Operator Subscription](./images/operator-subscription.png)\n\n- Tail the status of your Strimzi operator install either through the web console or doing while logged in through OpenShift through your terminal. \n\n```bash\noc get pods -n openshift-operators\n```\n\n![Operator Installing](./images/strimzi-operator-installing.png)\n\n\n\n7. When the Strimzi Operator finally says Succeeded in the \"Installed Operators\" section in the Web console or 1/1 Running in the Pod status we may proceed.\n\n\n\n![Operator Success](./images/strimzi-operator-success.png)\n\n![Operator Console](./images/strimzi-operator-console.png)\n\n\n\n\n## Setting up the Kafka Connect Cluster\n\n*Note* - As stated in the pre-requisites section we will be mirroring the steps followed here at [Kafka Connect to S3 Sink & Source](https://ibm-cloud-architecture.github.io/refarch-eda/scenarios/connect-s3/) for more granular information and reading.\n\n- Now that we have our Strimzi Kafka Operator installed we need the secrets and appropriate credentials set up.\n\n- You will need to be logged into your OpenShift Cluster through the terminal. You can do this by going to the OpenShift Web UI and going to the top right and hitting the User (likely kube:admin in this case) and then \"Copy Login command\" and then \"Display Token\". Copy and paste the \"Log in with this token\" command into your terminal.\n\n- I would advise you to create a new Project/Namespace to separate secrets and logic but that's up to you.\n\n```bash\noc new-project es-cos-test\n```\n\n- We now need to create a secret for our Event Streams API Key that we gathered from the \"Event Streams Security: API Key, Credentials and Certificates\" Section earlier. This secret will be injected into the KafkaConnect cluster at run time as well. Replace {eventstreams_api_key} with your API key. This should also be in the `es-api-key.json` file earlier if you chose the \"Download as JSON\" option.\n\n```bash\noc create secret generic eventstreams-apikey --from-literal=password={eventstreams_api_key}\n```\n\n- We will now create/generate the proper certificate for use with the Kafka Connect cluster. By default our Event Streams certificate is a .jks file but we need to convert this to a .crt file. Run the following commands. These commands convert the .jks file to a new es-cert.crt file and then creates a Kubernetes/OpenShift secret for use with the KafkaConnect cluster.\n\n```bash\nkeytool -importkeystore -srckeystore es-cert.jks -destkeystore es-cert.p12 -deststoretype PKCS12\nopenssl pkcs12 -in es-cert.p12 -nokeys -out es-cert.crt\noc create secret generic eventstreams-truststore-cert --from-file=es-cert.crt\n```\n\n\n```bash\nvi log4j.properties\n```\n\n```properties\n# Do not change this generated file. Logging can be configured in the corresponding kubernetes/openshift resource.\nlog4j.appender.CONSOLE=org.apache.log4j.ConsoleAppender\nlog4j.appender.CONSOLE.layout=org.apache.log4j.PatternLayout\nlog4j.appender.CONSOLE.layout.ConversionPattern=%d{ISO8601} %p %m (%c) [%t]%n\nconnect.root.logger.level=INFO\nlog4j.rootLogger=${connect.root.logger.level}, CONSOLE\nlog4j.logger.org.apache.zookeeper=ERROR\nlog4j.logger.org.I0Itec.zkclient=ERROR\nlog4j.logger.org.reflections=ERROR\n\n```\n\n- (OPTIONAL) We can now create the ConfigMap from the newly created properties file.\n\n```bash\noc create configmap custom-connect-log4j --from-file=log4j.properties\n```\n\n- We will now deploy the base KafkaConnect Cluster using KafkaConnectS2I (Source to Image) custom resource. Create a new `kafka-connect.yaml` file and paste the following. \n\n```bash\nvi kafka-connect.yaml\n```\n\n```yaml\napiVersion: kafka.strimzi.io/v1alpha1\nkind: KafkaConnectS2I\nmetadata:\n  name: connect-cluster-101\n  annotations:\n    strimzi.io/use-connector-resources: \"true\"\nspec:\n  #logging:\n  #  type: external\n  #  name: custom-connect-log4j\n  replicas: 1\n  bootstrapServers: {your-bootstrap-server-address:443}\n  tls:\n    trustedCertificates:\n      - certificate: es-cert.crt\n        secretName: eventstreams-truststore-cert\n  authentication:\n    passwordSecret:\n      secretName: eventstreams-apikey\n      password: password\n    username: token\n    type: plain\n  config:\n    group.id: connect-cluster-101\n    config.providers: file\n    config.providers.file.class: org.apache.kafka.common.config.provider.FileConfigProvider\n    key.converter: org.apache.kafka.connect.json.JsonConverter\n    value.converter: org.apache.kafka.connect.json.JsonConverter\n    key.converter.schemas.enable: false\n    value.converter.schemas.enable: false\n    offset.storage.topic: connect-cluster-101-offsets\n    config.storage.topic: connect-cluster-101-configs\n    status.storage.topic: connect-cluster-101-status\n ```\n \n NOTE - The following options are things we need to take note of/configure. \n \n - (OPTIONAL)`spec.logging.name`: The name of the previously configured log4j ConfigMap. You can uncomment those previous three lines if you opted to create the ConfigMap.\n - `spec.bootstrapServers`: Replace `{your-bootstrap-server-address:443}` with your Event Streams instance bootstrap server address.\n - `spec.tls.trustedCertificates[0].secretName`: The name of the OpenShift secret created for your Event Streams certificate\n - `spec.authentication.passwordSecret.secretName`: The name of the OpenShift secret created from the Event Streams API Key\n - `spec.config['group.id']`: This should be a unique ID for connecting to the same set of Kafka brokers. If we do not specify a name, multiple KafkaConnect instances will end up using the default id and end up in a race condition as they all try to vie for access.\n - `spec.config['*.storage.topic']`: As noted in the .yaml file we have `offset.storage.topic`, `config.storage.topic`, and `status.storage.topic`. The name of these topics will need to be created in your Event Streams instance to store the metadata. See the \"Creating Event Streams Topics\" section for a refresher on creating Event Streams topics. \n \n \n - Make sure the `kafka-connect.yaml` files values are correctly configured and save it. From the terminal run the following\n\n```bash\noc apply -f kafka-connect.yaml\n``` \n \n- You can check the status of the pods by running `oc get pods`. When they're all Running we can proceed.\n \n \n\n## Building and Applying IBM COS Sink Connector\n\nThe IBM COS Source Connector source code is availabe at this repository [here](https://github.com/ibm-messaging/kafka-connect-ibmcos-sink). \n\n(IMPORTANT) The Strimzi Kafka Connect Cluster uses a Java 8 runtime so make sure you're actively using the Java 8 JRE.\n\n- Clone the Kafka Connect IBM COS Source Connector repository and then change your folder.\n```shell\ngit clone https://github.com/ibm-messaging/kafka-connect-ibmcos-sink.git\ncd kafka-connect-ibmcos-sink/\n```\n\n- We now need to build the connector binaries for use with our Kafka Connect cluster. Like stated earlier, make sure that you're using Java 8 to build the connector.\n\n```shell\ngradle shadowJar\n```\n\n- The newly built connector binaries are in the `build/libs/` folder. Let's move it into another folder for ease of use.\n\n```shell\ncp build/libs/kafka-connect-ibmcos-sink-*-all.jar connectors/\n```\n\n- Now that we have the connector in the `connectors/` folder let's start a new `oc start-build` command. What this command does is build a new image with your provided connectors/plugins and triggers a new deployment for your Kafka Connect clusters. \n\n```shell\noc start-build connect-cluster-101-connect --from-dir ./connectors/ --follow\n```\n\n- Since this creates a new deployment this will kick off a new Kafka Connect pod. Previously we'd have a pod with a name similar to `connect-101-cluster-connect-1-{random-suffix}`. This will create something similar to `connect-101-cluster-connect-2-{random-suffix}. Trail the output and wait for the pod to be `Running 1/1`\n\n```shell\noc get pods -w\n```\n\n- Once the new pod is up and running we can proceed. Create a new file named kafka-cos-sink-connector.yaml\n\n```shell\nvi kafka-cos-sink-connector.yaml\n```\n\n- Paste the following contents into the newly created yaml file.\n\n```yaml\napiVersion: kafka.strimzi.io/v1alpha1\nkind: KafkaConnector\nmetadata:\n  name: cos-sink-connector\n  labels:\n    strimzi.io/cluster: connect-cluster-101\nspec:\n  class: com.ibm.eventstreams.connect.cossink.COSSinkConnector\n  tasksMax: 1\n  config:\n    key.converter: org.apache.kafka.connect.storage.StringConverter\n    value.converter: org.apache.kafka.connect.storage.StringConverter\n    topics: {topic-name}\n    cos.api.key: {ibm-cos-api-key}\n    cos.bucket.location:{<ibm-cos-bucket-location}\n    cos.bucket.name: {your-ibm-cos-bucket-name}\n    cos.bucket.resiliency: {your-resiliency}\n    cos.service.crn: \"{your-ibm-cos-service-crn}\"\n    cos.object.records: 5\n    cos.object.deadline.seconds: 5\n    cos.object.interval.seconds: 5\n```\n\nIn the yaml there are a few things we need to configure.\n\n- `spec.config.topics`: Replace `{topic-name}` with the name of your created Event Streams topic. For the purposes of this story we'll assume the `INBOUND` topic for instance.\n- `spec.config.cos.api.key`: Replace `{ibm-cos-api-key}` with your `apikey` that we received/took down when we created our `Service Credential` earlier. \n- `spec.config.cos.bucket.location`: Replace `{ibm-cos-bucket-location}` with your created IBM COS bucket's location. It's usually in the form of something like `us-east` or `eu-gb` for example.\n- `spec.config.cos.bucket.resiliency`: Replace `{your-resiliency}` with your chosen Bucket resiliency selection. For the purposes of this scenario we assumed `regional`.\n- `spec.config.cos.service.crn`: Replace `{your-ibm-cos-service-crn}` with the CRN of your IBM COS Service. This usually ends with a double `::` at the end of it. *Note* - you might need to retain the double quotation marks here as the crn has colons in it. This ends up looking like something this - `cos.service.crn: \"crn:v1:bluemix:public:cloud-object-storage:global:a/123151fhtr324fd13:h6a12345f-ba23-1ab1-ab1f-12345678::\"`\n- The last three options can be configured to your liking. You can read more about configuring that [here](https://github.com/ibm-messaging/kafka-connect-ibmcos-sink#combining-multiple-kafka-records-into-an-object)\n\n- Save the yaml and apply this yaml to initiate the KafkaConnnector Custom Resource. \n```shell\noc apply -f kafka-cos-sink-connector.yaml\n```\n\n- The initialization of the connector can take a minute or two. You can check the logs of the connector to see if everything connected succesfully.\n```shell\noc describe kafkaconnector cos-sink-connector\n```\n\n- When the IBM COS Sink connector is successfully up and running you should see something similar to the below.\n\n![IBM COS Sink Connector success](./images/ibm-cos-sink-connector-success.png)\n\n\n## Event Streams v10 Addendum\n\n*A couple of things of note*\n- Most of these steps are the same as the last two (Setting up the Kafka Connect Cluster and IBM COS Sink Connector) besides a change to the YAML files.\n- Event Streams v10 is still rather new so these are subject to change. \n- Like previously mentioned in the Strimzi setup section, Event Streams v10 is built ontop of the Strimzi operator so we don't need to install those.\n\n\n*Quarkus Application application.properties*\n- Due to the changes to security with Event Streams v10, it has moved from plain text SASL to SCRAM credentials.\n- By default the certificate you download from the ESv10 is now a PKCS12 file and not a JKS. Also it now has an actual password associated now instead of just \"password\" previously.\n- As such we need to change our `application.properties` file for our Quarkus application to reflect that.\n\n```properties\nquarkus.http.port=8080\nquarkus.log.console.enable=true\nquarkus.log.console.level=INFO\n\n# Base ES Connection Details\nmp.messaging.connector.smallrye-kafka.bootstrap.servers=${BOOTSTRAP_SERVERS}\nmp.messaging.connector.smallrye-kafka.security.protocol=SASL_SSL\nmp.messaging.connector.smallrye-kafka.ssl.protocol=TLSv1.2\nmp.messaging.connector.smallrye-kafka.sasl.mechanism=SCRAM-SHA-512\nmp.messaging.connector.smallrye-kafka.sasl.jaas.config=org.apache.kafka.common.security.scram.ScramLoginModule required \\\n                username=${SCRAM_USERNAME} \\\n                password=${SCRAM_PASSWORD};\nmp.messaging.connector.smallrye-kafka.ssl.truststore.location=${CERT_LOCATION}\nmp.messaging.connector.smallrye-kafka.ssl.truststore.password=${CERT_PASSWORD}\nmp.messaging.connector.smallrye-kafka.ssl.truststore.type=PKCS12\n\n\n# Initial mock JSON message producer configuration\nmp.messaging.outgoing.INBOUND.connector=smallrye-kafka\nmp.messaging.outgoing.INBOUND.topic=${TOPIC_NAME}\nmp.messaging.outgoing.INBOUND.value.serializer=io.quarkus.kafka.client.serialization.JsonbSerializer\n```\n\nAs you can see there are a few more extra environment variables that we need to setup compared to when we connected to the previous version. This no longer uses an API Key.\n\n```shell\nexport BOOTSTRAP_SERVERS=your-bootstrap-server-address:443 \\\nexport TOPIC_NAME=name-of-topic-to-produce-to \\\nexport CERT_LOCATION=/path-to-pkcs12-cert/es-cert.p12 \\\nexport CERT_PASSWORD=certificate-password \\\nexport SCRAM_USERNAME=your-scram-username \\\nexport SCRAM_PASSWORD=your-scram-password \\\n```\n\n\n*KafkaConnectS2I Yaml*\n\n```yaml\napiVersion: eventstreams.ibm.com/v1beta1\nkind: KafkaConnectS2I\nmetadata:\n  name: connect-cluster-101\n  annotations:\n    eventstreams.ibm.com/use-connector-resources: \"true\"\nspec:\n  logging:\n    type: external\n    name: custom-connect-log4j\n  version: 2.5.0\n  replicas: 1\n  bootstrapServers: {your-internal-bootstrap-server-address}\n  template:\n    pod:\n      imagePullSecrets: []\n      metadata:\n        annotations:\n          eventstreams.production.type: CloudPakForIntegrationNonProduction\n          productID: xxxx\n          productName: IBM Event Streams for Non Production\n          productVersion: 10.0.0\n          productMetric: VIRTUAL_PROCESSOR_CORE\n          productChargedContainers: jng-connect\n          cloudpakId: xxxx\n          cloudpakName: IBM Cloud Pak for Integration\n          cloudpakVersion: 2020.2.1\n          productCloudpakRatio: \"2:1\"\n  tls:\n      trustedCertificates:\n        - secretName: {your-es-isntance-name}-ca-cert\n          certificate: ca.crt\n  authentication:\n    type: tls\n    certificateAndKey:\n      certificate: user.crt\n      key: user.key\n      secretName: {your-secret-name}\n  config:\n    group.id: connect-cluster-101\n    config.providers: file\n    config.providers.file.class: org.apache.kafka.common.config.provider.FileConfigProvider\n    key.converter: org.apache.kafka.connect.json.JsonConverter\n    value.converter: org.apache.kafka.connect.json.JsonConverter\n    key.converter.schemas.enable: false\n    value.converter.schemas.enable: false\n    offset.storage.topic: connect-cluster-101-offsets\n    config.storage.topic: connect-cluster-101-configs\n    status.storage.topic: connect-cluster-101-status\n    config.storage.replication.factor: 1\n    offset.storage.replication.factor: 1\n    status.storage.replication.factor: 1\n\n```\n\nThings of note that were changed.\n\n- `spec.bootstrapservers`: This bootstrap server address is found under the `Internal Connection` option rather than `External` in the ESv10 UI when choosing to `Connect to this Cluster`.\n- `spec.tls.trustedCertificates.secretName`: This will be the autogenerated certificate. It should be prefix'd with your Event Streams instance name. If your ES instance name is ES10 then this secret should be named `ES10-ca-cert`. Ideally this secret will be in the project/namespace of where you installed ESv10. \n- `spec.authentication.secretName`: This secretname will be the name you enter of your secret when you select `Generate TLS Credentials` with internal connection. ESv10 will automatically create a secret within the same OpenShift namespace/project. That generated secret will have various details in it like `user.cert` and `user.key`. \n\n\n*IBM COS Sink Connector YAML*\n\n```yaml\napiVersion: eventstreams.ibm.com/v1alpha1\nkind: KafkaConnector\nmetadata:\n  name: cos-sink-connector\n  labels:\n     eventstreams.ibm.com/cluster: jng-connect-cluster-101\nspec:\n  class: com.ibm.eventstreams.connect.cossink.COSSinkConnector\n  tasksMax: 1\n  config:\n    key.converter: org.apache.kafka.connect.storage.StringConverter\n    value.converter: org.apache.kafka.connect.storage.StringConverter\n    topics: {topic-name}\n    cos.api.key: {ibm-cos-api-key}\n    cos.bucket.location: {ibm-cos-bucket-location}\n    cos.bucket.name: {your-ibm-cos-bucket-name}\n    cos.bucket.resiliency: {your-resiliency}\n    cos.service.crn: \"{your-ibm-cos-service-crn}\"\n    cos.object.records: 5\n    cos.object.deadline.seconds: 5\n    cos.object.interval.seconds: 5\n```\n\n- Not too many differences from the Strimzi/ESv2019.4.2 version. \n  - Mainly the changing of `apiVersion: eventstreams.ibm.com/v1alpha1`. Not sure why the KafkaConnectS2I is beta and this is alpha. \n  - `metadata.labels.eventstreams.ibm.com/cluster:` instead of `strimzi.io/cluster`\n  \n- Besides these few changes to the YAMLs this should behave as it did previously.\n\n\n## Test the Entire Flow\n\n- Now that we have all the previous steps setup we can now test the entire flow.\n\n- Start our Quarkus Kafka Producer application to send messages to the Event Streams INBOUND topic.\n\n```bash\n./mvnw quarkus:dev\n```\n\n![Quarkus Run Success](./images/quarkus-run-success.png)\n\n- Go to your Event Streams instance on Cloud Pak for Integration. Traverse to the Topics menu and select your `INBOUND` topic and then go to \"Messages\". Choose the \"Live\" option to see an up-to-date stream of your incoming messages.\n\n- Your messages should be propagating the your created IBM COS Bucket automatically.\n\n![Event Streams Topic Success](./images/event-streams-topic-success.png)\n\n- The name of the file inside the bucket has starting offset and ending offset. You can download one of these object files to make sure that the value inside matches the value inside your `INBOUND` topic.\n\n\n![End to End Success](./images/ibm-cos-bucket-success.png)\n","type":"Mdx","contentDigest":"d92b23d247f781b79c3e28f2bfda2326","counter":621,"owner":"gatsby-plugin-mdx"},"exports":[],"rawBody":"---\ntitle: Kafka Connect to IBM COS \ndescription: Apache Kafka to IBM Cloud Object Storage Source Connector usecase\n---\n\n<AnchorLinks>\n  <AnchorLink>Overview</AnchorLink>\n  <AnchorLink>Scenario Prerequisites</AnchorLink>\n  <AnchorLink>Creating Event Streams Topics</AnchorLink>\n  <AnchorLink>Event Streams Security: API Key, Credentials and Certificates</AnchorLink>\n  <AnchorLink>Creating the Quarkus with MicroProfile Reactive Messaging Application</AnchorLink>\n  <AnchorLink>Setting up the Kafka Strimzi Operator</AnchorLink>\n  <AnchorLink>Setting up the Kafka Connect Cluster</AnchorLink>\n  <AnchorLink>Building and Applying IBM COS Sink Connector</AnchorLink>\n  <AnchorLink>Event Streams v10 Addendum</AnchorLink>\n  <AnchorLink>Test the Entire Flow</AnchorLink>\n</AnchorLinks>\n\n## Overview\n- Now that you have an Event Streams instance installed on Cloud Pak for Integration on top of OpenShift Container Platform the goal of this story is to show a possible use case that we can use with this technology.\n- With IBM Event Streams we have access to the powerful capabilities of Kafka in addition to all the monitoring and logging capabilities that IBM provides on top of that with Event Streams.\n- We will create a simple Quarkus (a super sonic and sub-atomic Kubernetes native framework for Java) application that utilizes MicroProfile Reactive Messaging in order for us to send a stream of data to our Event Streams/Kafka topic.\n- We will then create a Kafka Connect cluster using the Strimzi Operator.\n- Lastly we'll send messages to an Event Streams topic from our Quarkus application which then triggers the IBM COS Connector to grab messages and place into an IBM COS Bucket.\n\n![Architecture Diagram](./images/quarkus-to-event-streams-to-cos.png)\n\n\n## Scenario Prerequisites\n**OpenShift Container Platform Cluster** \n  - This scenario will assume you have a 4.x Cluster as we will make use of Operators, though this one is 4.3 specifically.\n  \n**Cloud Pak for Integration**\n  - This will assume you have probably at least a 2019.4.1 or 2020.x.x release of the Cloud Pak for Integration installed on OpenShift. This story will also assume you have followed the installation instructions for Event Streams outlined in [the 2020-2 product documentation](https://ibm.github.io/event-streams/installing/installing/) or from the [Cloud Pak Playbook](https://cloudpak8s.io/integration/cp4i-deploy-eventstreams/) and have a working Event Streams instance.\n  \n**Java**\n  - Java Development Kit (JDK) v1.8+ (Java 8+)\n\n**Maven**\n  - The scenario uses Maven v3.6.3\n\n**Gradle**\n  - Ideally v4.0+ (Note - the gradle shadowJar command might not work on Java 13)\n\n**An IDE of your choice**\n  - Visual Studio Code is used in this scenario.\n\n**Git**\n  - We will need to clone repositories.\n\n**An IBM Cloud Account (free)**\n  - A free (Lite) IBM Cloud Object Storage trial Service account [IBM Cloud Object Storage](https://cloud.ibm.com/catalog/services/cloud-object-storage)\n\n\n## Creating Event Streams Topics\n\nSee instructions in [the common pre-requisite section](../overview/pre-requisites/#creating-event-streams-topics)\n\n## Event Streams Security: API Key, Credentials and Certificates\n\n- To connect to our Event Streams Instance we will need to follow a few steps to properly connect to it.\n\n- While viewing our Event Streams Instance, navigate to the Topics menu from the left. Click Connect to this Cluster - \n\n![Connect to this Cluster](./images/esv10-connect-to-cluster.png)\n\n- Make sure that you're on **External Connection** as we will need to test/connect from an application on a local machine. Keep note of your **Bootstrap Server Address**. Save this somewhere as we will need this later to configure our Quarkus Application's connection to the Event Streams instance.\n\n\n- Generate your **SCRAM Credentials**. Click the `Generate SCRAM Credentials` button.\n\n![Generate SCRAM1 ](./images/esv10-generate-scram.png)\n\n- Select a name for your secret and make sure you rmeember/take note of it as we will need this later. Also choose the Produce, Consume, Create Topics and Schema Option.\n\n![Generate SCRAM 2](./images/esv10-scram-1.png)\n\n- Select `All Topics` and then click Next.\n\n![Generate SCRAM 3](./images/esv10-scram-2.png)\n\n- Leave it with `All Consumer Groups` and click Next.\n\n- Generate your **API Key**. Click the Generate API Key button.\n\n![Generate SCRAM 5](./images/esv10-scram-4.png)\n\n- Select a name for your application. It doesn't really matter too much what you name it. Also choose the Produce, Consume, Create Topics and Schema Option.\n\n- If this error occurs, log into your OpenShift cluster and go to the project/namespace that your Event Streams v10 instance is installed in. If you run these commands you will see your secret.\n\n`oc get kafkauser`\n\n\n`oc get secrets`\n\n- Your `SCRAM Username` that we will need for later is the name of your secret. The `SCRAM Password` can be either obtained by going to your OpenShift Console Web UI and revealing the password through the secrets menu or through the CLI. Run the following commands to see the value of the password.\n\n`oc get secret your-secret -o yaml | grep password`\n\n- This will return you a base64 encoded value. Decode this like so\n\n`echo \"dWpPN3ZSSEF1clRK\" | base64 -d`\n\n![SCRAM Secret](./images/esv10-scram-secret.png)\n\n\n- Lastly download the PKCS12 truststore .pkcs12 certificate. Once you hit the Download button the password to the truststore will be revealed. **Copy this down** as we will need it.\n\n![PKCS12 Truststore](./images/esv10-pkcs12.png)\n\n\n\n**Summary** \n- We now have the bootstrap server address, SCRAM Username (also the name of the KafkaUser/Secret CRs) and Password, .pcks12 truststore certificate, and the truststore password associated with that certificate to allow us the ability to connect to our Event Streams instance.\n\n\n\n## Creating the Quarkus with MicroProfile Reactive Messaging Application \n- Create the Quarkus project. You can replace {} and the contents inside of {} with whatever you would like.\n\n```bash\nmvn io.quarkus:quarkus-maven-plugin:1.6.0.Final:create \\\n    -DprojectGroupId={org.acme} \\\n    -DprojectArtifactId={quarkus-kafka} \\\n    -Dextensions=\"kafka\"\n```\n\n- Open the project in your IDE of choice. \n\n- Create the following folder structure and then create the Producer.java file.\n\n```bash\nsrc/main/java/org/acme/kafka/producer/Producer.java\n```\n\n![Quarkus Project Folder Structure](./images/quarkus-folder-structure.png)\n\n\n- Within your Producer.java file add the following code - \n\n```java\npackage org.acme.kafka.producer;\n\nimport io.reactivex.Flowable;\nimport io.smallrye.reactive.messaging.kafka.KafkaRecord;\n\nimport org.eclipse.microprofile.reactive.messaging.Outgoing;\n\nimport javax.enterprise.context.ApplicationScoped;\nimport java.util.Random;\nimport java.util.concurrent.TimeUnit;\n\n/**\n * This class produces a message every 5 seconds.\n * The Kafka configuration is specified in the application.properties file.\n*/\n@ApplicationScoped\npublic class Producer {\n\n    private Random random = new Random();\n\n    @Outgoing(\"{TOPIC-NAME}\")      \n    public Flowable<KafkaRecord<Integer, String>> generate() {\n        return Flowable.interval(5, TimeUnit.SECONDS)    \n                .onBackpressureDrop()\n                .map(tick -> {      \n                    return KafkaRecord.of(random.nextInt(100), String.valueOf(random.nextInt(100)));\n                });\n    }                  \n}\n\n```\n\nTake note on the line that says @Outgoing(\"{TOPIC-NAME}\"). For the purposes of this story we will use the INBOUND topic name that we created in the Event Streams Topic step earlier. Replace whatever is inside the quotation marks.\n\n```java\n@Outgoing(\"INBOUND\")\n```\n\nThe @Outgoing annotation is for specifying the name of the Channel, but it will default to that Channel's name if a topic name is not provided in the application.properties file. We will address that a little bit later.\n\n\n* What does this Producer.java code do? \n   - The @Outgoing annotation indicates that we're sending to a Channel (or Topic) and we're not expecting any data.\n   - The generate() function returns an [RX Java 2 Flowable Object](https://www.baeldung.com/rxjava-2-flowable) emmitted every 5 seconds. \n   - The Flowable object returns a KafkaRecord of type key type Integer and value type String.\n   \n   \n- We will now need to update our applications.properties file that was automatically generated when the Quarkus project was created located here - \n\n```bash\nsrc/main/resources/application.properties\n```\n\n![application properties structure](./images/application-properties-structure.png)\n\n- Copy and paste the following into your application.properties file - \n\n```properties\n# Event Streams Connection details\nmp.messaging.connector.smallrye-kafka.bootstrap.servers=${BOOTSTRAP_SERVERS}\nmp.messaging.connector.smallrye-kafka.security.protocol=SASL_SSL\nmp.messaging.connector.smallrye-kafka.ssl.protocol=TLSv1.2\nmp.messaging.connector.smallrye-kafka.sasl.mechanism=PLAIN\nmp.messaging.connector.smallrye-kafka.sasl.jaas.config=org.apache.kafka.common.security.scram.PlainLoginModule required \\\n                username=\"token\" \\\n                password=${APIKey};\nmp.messaging.connector.smallrye-kafka.ssl.truststore.location=${CERT_LOCATION}\nmp.messaging.connector.smallrye-kafka.ssl.truststore.password=password\n\n\n# Initial mock JSON message producer configuration\nmp.messaging.outgoing.INBOUND.connector=smallrye-kafka\nmp.messaging.outgoing.INBOUND.topic=${TOPIC_NAME}\nmp.messaging.outgoing.INBOUND.value.serializer=io.quarkus.kafka.client.serialization.JsonbSerializer\n```\n\n*Note* - These values that we are configuring can be used with environmental variables. We will export them, or you can choose to hardcode them.\n   \n```shell\nexport BOOTSTRAP_SERVERS={your-bootstrap-server-address} \\\nexport TOPIC_NAME=INBOUND \\ \nexport CERT_LOCATION={your-path-to-es-cert}/es-cert.jks \\\nexport APIKey={your-api-key}\n```\n\n- Replace the values and export the following environment variables. Note that while `TOPIC_NAME` is INBOUND in this case, if we omit this configuration property `mp.messaging.outgoing.INBOUND.topic=${TOPIC_NAME}`, it will default to the channel name as the topic. In this case it will default to `INBOUND`. You can choose to specify a different topic name from the `INBOUND` topic if you so choose. \n\n- Great! We now have our simple Quarkus Kafka Producer with our Event Streams credentials. We can now test the connection.\n\n- Run the producer code by running the following command \n\n```bash\n./mvnw quarkus:dev\n```\n\n- Since the code sends a message every 5 seconds, you can leave it on for a bit or you can change it to send it more frequently. Check out the Event Streams instance in the browser UI topic for messages. You can click the message under \"Indexed Timestamp\" to see the contents and details of the message.\n\n![ES Topic Messages](./images/event-streams-topic-messages.png)\n\n\n\n## Creating an IBM COS Service and COS Bucket for your IBM Cloud Account\n\nThis story assumes that you already have an IBM Cloud account already, and if not you can sign up for one here at [IBM Cloud](https://cloud.ibm.com).\n\n- Once inside your IBM Cloud account, traverse to the `Catalog` section.\n\n- In the search type in `IBM Cloud Object Storage`\n\n![IBM COS Catalog Search](./images/ibm-cloud-create-cos-service.png)\n\n- Name your IBM COS Service with something unique. Since this is a free account we can stick with the Lite Plan.\n\n![IBM COS Create COS Service](./images/ibm-cloud-create-cos-service-2.png)\n\n- Now that the IBM Cloud Object Storage Service is created, traverse to it and let's create a new bucket. \n\n\n- On the `Create Bucket` screen pick `Custom Bucket`.\n\n![IBM COS Custom Bucket](./images/ibm-cos-create-bucket.png)\n\n- When selecting options for the bucket, name your bucket something unique. For `Resiliency` let's select `Regional`. For location select an area from the drop-down that you want. (IMPORTANT) For `Storage Class` select `Standard`. The IBM COS Sink connector seems to not play well with buckets that are created with the `Smart Tier` Storage Class. Leave everything else as-is and hit `Create Bucket`.\n\n![IBM COS Custom Bucket Settings](./images/ibm-cos-bucket-settings.png)\n\n\n\n\n## Creating IBM Cloud Service Credentials\n\nNow that we have created our IBM Cloud Object Storage Service and bucket we now need to create the Service Credential so that we can connect to it.\n\n- Inside your IBM COS Service, select `Service Credentials` and then click the `New Credential` button.\n\n![IBM COS Service Credential](./images/ibm-cos-create-service-cred.png)\n\n- Name your credential and select `Manager` from the `Role:` drop-down menu and click `Add`.\n\n![IBM COS SC Settings](./images/ibm-cos-service-credentials.png)\n\n- Expand your newly created Service Credential and write down the values for `\"apikey\"` and `\"resource_instance_id\"`.\n\n![Expanded Service Cred](./images/ibm-service-credential-keys.png)\n\n\n### Summary\n\nWe've created the IBM COS Service, created a COS Bucket, and created our Service Credentials. Here are the following items we need to configure our IBM COS connector.\n\n\n- IBM COS Bucket name\n- IBM COS Bucket location\n- IBM COS Resiliency (regional)\n- IBM COS Service CRN (resource_instance_id)\n- IBM COS API Key\n\n\n\n## Setting up the Kafka Strimzi Operator\n\n*Note* - This scenario uses an OCP 4.3 cluster, CP4I2020.1.1 and Event Streams v2019.4.2 so this Strimzi installation step\nmay not be necessary if you are on OCP 4.4, CP4I2020.2.1 as well as Event Streams v10 (which is operator based and built on top of Strimzi)\n\n- As part of the pre-requisites this assumes that you have a 4.x OpenShift Container Platform cluster we will use the Strimzi Operator to deploy our Kafka cluster. \n\n- In your OpenShift Web Console, in the \"ADMINISTRATOR\" view. This is in the top left most portion of the menu. Go to \"Operators\" > \"OperatorHub\".\n\n![OperatorHub](./images/operator-hub.png)\n\n- Type \"Strimzi\" into the Search Bar.\n\n![Strimzi](./images/strimzi.png)\n\n- Click on the Strimzi Operator and then click \"Install\".\n\n![Operator Install](./images/operator-install.png)\n\n- Make sure that the option to have \"All namespaces on the cluster (default)\" is checked.\n\n![Operator Subscription](./images/operator-subscription.png)\n\n- Tail the status of your Strimzi operator install either through the web console or doing while logged in through OpenShift through your terminal. \n\n```bash\noc get pods -n openshift-operators\n```\n\n![Operator Installing](./images/strimzi-operator-installing.png)\n\n\n\n7. When the Strimzi Operator finally says Succeeded in the \"Installed Operators\" section in the Web console or 1/1 Running in the Pod status we may proceed.\n\n\n\n![Operator Success](./images/strimzi-operator-success.png)\n\n![Operator Console](./images/strimzi-operator-console.png)\n\n\n\n\n## Setting up the Kafka Connect Cluster\n\n*Note* - As stated in the pre-requisites section we will be mirroring the steps followed here at [Kafka Connect to S3 Sink & Source](https://ibm-cloud-architecture.github.io/refarch-eda/scenarios/connect-s3/) for more granular information and reading.\n\n- Now that we have our Strimzi Kafka Operator installed we need the secrets and appropriate credentials set up.\n\n- You will need to be logged into your OpenShift Cluster through the terminal. You can do this by going to the OpenShift Web UI and going to the top right and hitting the User (likely kube:admin in this case) and then \"Copy Login command\" and then \"Display Token\". Copy and paste the \"Log in with this token\" command into your terminal.\n\n- I would advise you to create a new Project/Namespace to separate secrets and logic but that's up to you.\n\n```bash\noc new-project es-cos-test\n```\n\n- We now need to create a secret for our Event Streams API Key that we gathered from the \"Event Streams Security: API Key, Credentials and Certificates\" Section earlier. This secret will be injected into the KafkaConnect cluster at run time as well. Replace {eventstreams_api_key} with your API key. This should also be in the `es-api-key.json` file earlier if you chose the \"Download as JSON\" option.\n\n```bash\noc create secret generic eventstreams-apikey --from-literal=password={eventstreams_api_key}\n```\n\n- We will now create/generate the proper certificate for use with the Kafka Connect cluster. By default our Event Streams certificate is a .jks file but we need to convert this to a .crt file. Run the following commands. These commands convert the .jks file to a new es-cert.crt file and then creates a Kubernetes/OpenShift secret for use with the KafkaConnect cluster.\n\n```bash\nkeytool -importkeystore -srckeystore es-cert.jks -destkeystore es-cert.p12 -deststoretype PKCS12\nopenssl pkcs12 -in es-cert.p12 -nokeys -out es-cert.crt\noc create secret generic eventstreams-truststore-cert --from-file=es-cert.crt\n```\n\n\n```bash\nvi log4j.properties\n```\n\n```properties\n# Do not change this generated file. Logging can be configured in the corresponding kubernetes/openshift resource.\nlog4j.appender.CONSOLE=org.apache.log4j.ConsoleAppender\nlog4j.appender.CONSOLE.layout=org.apache.log4j.PatternLayout\nlog4j.appender.CONSOLE.layout.ConversionPattern=%d{ISO8601} %p %m (%c) [%t]%n\nconnect.root.logger.level=INFO\nlog4j.rootLogger=${connect.root.logger.level}, CONSOLE\nlog4j.logger.org.apache.zookeeper=ERROR\nlog4j.logger.org.I0Itec.zkclient=ERROR\nlog4j.logger.org.reflections=ERROR\n\n```\n\n- (OPTIONAL) We can now create the ConfigMap from the newly created properties file.\n\n```bash\noc create configmap custom-connect-log4j --from-file=log4j.properties\n```\n\n- We will now deploy the base KafkaConnect Cluster using KafkaConnectS2I (Source to Image) custom resource. Create a new `kafka-connect.yaml` file and paste the following. \n\n```bash\nvi kafka-connect.yaml\n```\n\n```yaml\napiVersion: kafka.strimzi.io/v1alpha1\nkind: KafkaConnectS2I\nmetadata:\n  name: connect-cluster-101\n  annotations:\n    strimzi.io/use-connector-resources: \"true\"\nspec:\n  #logging:\n  #  type: external\n  #  name: custom-connect-log4j\n  replicas: 1\n  bootstrapServers: {your-bootstrap-server-address:443}\n  tls:\n    trustedCertificates:\n      - certificate: es-cert.crt\n        secretName: eventstreams-truststore-cert\n  authentication:\n    passwordSecret:\n      secretName: eventstreams-apikey\n      password: password\n    username: token\n    type: plain\n  config:\n    group.id: connect-cluster-101\n    config.providers: file\n    config.providers.file.class: org.apache.kafka.common.config.provider.FileConfigProvider\n    key.converter: org.apache.kafka.connect.json.JsonConverter\n    value.converter: org.apache.kafka.connect.json.JsonConverter\n    key.converter.schemas.enable: false\n    value.converter.schemas.enable: false\n    offset.storage.topic: connect-cluster-101-offsets\n    config.storage.topic: connect-cluster-101-configs\n    status.storage.topic: connect-cluster-101-status\n ```\n \n NOTE - The following options are things we need to take note of/configure. \n \n - (OPTIONAL)`spec.logging.name`: The name of the previously configured log4j ConfigMap. You can uncomment those previous three lines if you opted to create the ConfigMap.\n - `spec.bootstrapServers`: Replace `{your-bootstrap-server-address:443}` with your Event Streams instance bootstrap server address.\n - `spec.tls.trustedCertificates[0].secretName`: The name of the OpenShift secret created for your Event Streams certificate\n - `spec.authentication.passwordSecret.secretName`: The name of the OpenShift secret created from the Event Streams API Key\n - `spec.config['group.id']`: This should be a unique ID for connecting to the same set of Kafka brokers. If we do not specify a name, multiple KafkaConnect instances will end up using the default id and end up in a race condition as they all try to vie for access.\n - `spec.config['*.storage.topic']`: As noted in the .yaml file we have `offset.storage.topic`, `config.storage.topic`, and `status.storage.topic`. The name of these topics will need to be created in your Event Streams instance to store the metadata. See the \"Creating Event Streams Topics\" section for a refresher on creating Event Streams topics. \n \n \n - Make sure the `kafka-connect.yaml` files values are correctly configured and save it. From the terminal run the following\n\n```bash\noc apply -f kafka-connect.yaml\n``` \n \n- You can check the status of the pods by running `oc get pods`. When they're all Running we can proceed.\n \n \n\n## Building and Applying IBM COS Sink Connector\n\nThe IBM COS Source Connector source code is availabe at this repository [here](https://github.com/ibm-messaging/kafka-connect-ibmcos-sink). \n\n(IMPORTANT) The Strimzi Kafka Connect Cluster uses a Java 8 runtime so make sure you're actively using the Java 8 JRE.\n\n- Clone the Kafka Connect IBM COS Source Connector repository and then change your folder.\n```shell\ngit clone https://github.com/ibm-messaging/kafka-connect-ibmcos-sink.git\ncd kafka-connect-ibmcos-sink/\n```\n\n- We now need to build the connector binaries for use with our Kafka Connect cluster. Like stated earlier, make sure that you're using Java 8 to build the connector.\n\n```shell\ngradle shadowJar\n```\n\n- The newly built connector binaries are in the `build/libs/` folder. Let's move it into another folder for ease of use.\n\n```shell\ncp build/libs/kafka-connect-ibmcos-sink-*-all.jar connectors/\n```\n\n- Now that we have the connector in the `connectors/` folder let's start a new `oc start-build` command. What this command does is build a new image with your provided connectors/plugins and triggers a new deployment for your Kafka Connect clusters. \n\n```shell\noc start-build connect-cluster-101-connect --from-dir ./connectors/ --follow\n```\n\n- Since this creates a new deployment this will kick off a new Kafka Connect pod. Previously we'd have a pod with a name similar to `connect-101-cluster-connect-1-{random-suffix}`. This will create something similar to `connect-101-cluster-connect-2-{random-suffix}. Trail the output and wait for the pod to be `Running 1/1`\n\n```shell\noc get pods -w\n```\n\n- Once the new pod is up and running we can proceed. Create a new file named kafka-cos-sink-connector.yaml\n\n```shell\nvi kafka-cos-sink-connector.yaml\n```\n\n- Paste the following contents into the newly created yaml file.\n\n```yaml\napiVersion: kafka.strimzi.io/v1alpha1\nkind: KafkaConnector\nmetadata:\n  name: cos-sink-connector\n  labels:\n    strimzi.io/cluster: connect-cluster-101\nspec:\n  class: com.ibm.eventstreams.connect.cossink.COSSinkConnector\n  tasksMax: 1\n  config:\n    key.converter: org.apache.kafka.connect.storage.StringConverter\n    value.converter: org.apache.kafka.connect.storage.StringConverter\n    topics: {topic-name}\n    cos.api.key: {ibm-cos-api-key}\n    cos.bucket.location:{<ibm-cos-bucket-location}\n    cos.bucket.name: {your-ibm-cos-bucket-name}\n    cos.bucket.resiliency: {your-resiliency}\n    cos.service.crn: \"{your-ibm-cos-service-crn}\"\n    cos.object.records: 5\n    cos.object.deadline.seconds: 5\n    cos.object.interval.seconds: 5\n```\n\nIn the yaml there are a few things we need to configure.\n\n- `spec.config.topics`: Replace `{topic-name}` with the name of your created Event Streams topic. For the purposes of this story we'll assume the `INBOUND` topic for instance.\n- `spec.config.cos.api.key`: Replace `{ibm-cos-api-key}` with your `apikey` that we received/took down when we created our `Service Credential` earlier. \n- `spec.config.cos.bucket.location`: Replace `{ibm-cos-bucket-location}` with your created IBM COS bucket's location. It's usually in the form of something like `us-east` or `eu-gb` for example.\n- `spec.config.cos.bucket.resiliency`: Replace `{your-resiliency}` with your chosen Bucket resiliency selection. For the purposes of this scenario we assumed `regional`.\n- `spec.config.cos.service.crn`: Replace `{your-ibm-cos-service-crn}` with the CRN of your IBM COS Service. This usually ends with a double `::` at the end of it. *Note* - you might need to retain the double quotation marks here as the crn has colons in it. This ends up looking like something this - `cos.service.crn: \"crn:v1:bluemix:public:cloud-object-storage:global:a/123151fhtr324fd13:h6a12345f-ba23-1ab1-ab1f-12345678::\"`\n- The last three options can be configured to your liking. You can read more about configuring that [here](https://github.com/ibm-messaging/kafka-connect-ibmcos-sink#combining-multiple-kafka-records-into-an-object)\n\n- Save the yaml and apply this yaml to initiate the KafkaConnnector Custom Resource. \n```shell\noc apply -f kafka-cos-sink-connector.yaml\n```\n\n- The initialization of the connector can take a minute or two. You can check the logs of the connector to see if everything connected succesfully.\n```shell\noc describe kafkaconnector cos-sink-connector\n```\n\n- When the IBM COS Sink connector is successfully up and running you should see something similar to the below.\n\n![IBM COS Sink Connector success](./images/ibm-cos-sink-connector-success.png)\n\n\n## Event Streams v10 Addendum\n\n*A couple of things of note*\n- Most of these steps are the same as the last two (Setting up the Kafka Connect Cluster and IBM COS Sink Connector) besides a change to the YAML files.\n- Event Streams v10 is still rather new so these are subject to change. \n- Like previously mentioned in the Strimzi setup section, Event Streams v10 is built ontop of the Strimzi operator so we don't need to install those.\n\n\n*Quarkus Application application.properties*\n- Due to the changes to security with Event Streams v10, it has moved from plain text SASL to SCRAM credentials.\n- By default the certificate you download from the ESv10 is now a PKCS12 file and not a JKS. Also it now has an actual password associated now instead of just \"password\" previously.\n- As such we need to change our `application.properties` file for our Quarkus application to reflect that.\n\n```properties\nquarkus.http.port=8080\nquarkus.log.console.enable=true\nquarkus.log.console.level=INFO\n\n# Base ES Connection Details\nmp.messaging.connector.smallrye-kafka.bootstrap.servers=${BOOTSTRAP_SERVERS}\nmp.messaging.connector.smallrye-kafka.security.protocol=SASL_SSL\nmp.messaging.connector.smallrye-kafka.ssl.protocol=TLSv1.2\nmp.messaging.connector.smallrye-kafka.sasl.mechanism=SCRAM-SHA-512\nmp.messaging.connector.smallrye-kafka.sasl.jaas.config=org.apache.kafka.common.security.scram.ScramLoginModule required \\\n                username=${SCRAM_USERNAME} \\\n                password=${SCRAM_PASSWORD};\nmp.messaging.connector.smallrye-kafka.ssl.truststore.location=${CERT_LOCATION}\nmp.messaging.connector.smallrye-kafka.ssl.truststore.password=${CERT_PASSWORD}\nmp.messaging.connector.smallrye-kafka.ssl.truststore.type=PKCS12\n\n\n# Initial mock JSON message producer configuration\nmp.messaging.outgoing.INBOUND.connector=smallrye-kafka\nmp.messaging.outgoing.INBOUND.topic=${TOPIC_NAME}\nmp.messaging.outgoing.INBOUND.value.serializer=io.quarkus.kafka.client.serialization.JsonbSerializer\n```\n\nAs you can see there are a few more extra environment variables that we need to setup compared to when we connected to the previous version. This no longer uses an API Key.\n\n```shell\nexport BOOTSTRAP_SERVERS=your-bootstrap-server-address:443 \\\nexport TOPIC_NAME=name-of-topic-to-produce-to \\\nexport CERT_LOCATION=/path-to-pkcs12-cert/es-cert.p12 \\\nexport CERT_PASSWORD=certificate-password \\\nexport SCRAM_USERNAME=your-scram-username \\\nexport SCRAM_PASSWORD=your-scram-password \\\n```\n\n\n*KafkaConnectS2I Yaml*\n\n```yaml\napiVersion: eventstreams.ibm.com/v1beta1\nkind: KafkaConnectS2I\nmetadata:\n  name: connect-cluster-101\n  annotations:\n    eventstreams.ibm.com/use-connector-resources: \"true\"\nspec:\n  logging:\n    type: external\n    name: custom-connect-log4j\n  version: 2.5.0\n  replicas: 1\n  bootstrapServers: {your-internal-bootstrap-server-address}\n  template:\n    pod:\n      imagePullSecrets: []\n      metadata:\n        annotations:\n          eventstreams.production.type: CloudPakForIntegrationNonProduction\n          productID: xxxx\n          productName: IBM Event Streams for Non Production\n          productVersion: 10.0.0\n          productMetric: VIRTUAL_PROCESSOR_CORE\n          productChargedContainers: jng-connect\n          cloudpakId: xxxx\n          cloudpakName: IBM Cloud Pak for Integration\n          cloudpakVersion: 2020.2.1\n          productCloudpakRatio: \"2:1\"\n  tls:\n      trustedCertificates:\n        - secretName: {your-es-isntance-name}-ca-cert\n          certificate: ca.crt\n  authentication:\n    type: tls\n    certificateAndKey:\n      certificate: user.crt\n      key: user.key\n      secretName: {your-secret-name}\n  config:\n    group.id: connect-cluster-101\n    config.providers: file\n    config.providers.file.class: org.apache.kafka.common.config.provider.FileConfigProvider\n    key.converter: org.apache.kafka.connect.json.JsonConverter\n    value.converter: org.apache.kafka.connect.json.JsonConverter\n    key.converter.schemas.enable: false\n    value.converter.schemas.enable: false\n    offset.storage.topic: connect-cluster-101-offsets\n    config.storage.topic: connect-cluster-101-configs\n    status.storage.topic: connect-cluster-101-status\n    config.storage.replication.factor: 1\n    offset.storage.replication.factor: 1\n    status.storage.replication.factor: 1\n\n```\n\nThings of note that were changed.\n\n- `spec.bootstrapservers`: This bootstrap server address is found under the `Internal Connection` option rather than `External` in the ESv10 UI when choosing to `Connect to this Cluster`.\n- `spec.tls.trustedCertificates.secretName`: This will be the autogenerated certificate. It should be prefix'd with your Event Streams instance name. If your ES instance name is ES10 then this secret should be named `ES10-ca-cert`. Ideally this secret will be in the project/namespace of where you installed ESv10. \n- `spec.authentication.secretName`: This secretname will be the name you enter of your secret when you select `Generate TLS Credentials` with internal connection. ESv10 will automatically create a secret within the same OpenShift namespace/project. That generated secret will have various details in it like `user.cert` and `user.key`. \n\n\n*IBM COS Sink Connector YAML*\n\n```yaml\napiVersion: eventstreams.ibm.com/v1alpha1\nkind: KafkaConnector\nmetadata:\n  name: cos-sink-connector\n  labels:\n     eventstreams.ibm.com/cluster: jng-connect-cluster-101\nspec:\n  class: com.ibm.eventstreams.connect.cossink.COSSinkConnector\n  tasksMax: 1\n  config:\n    key.converter: org.apache.kafka.connect.storage.StringConverter\n    value.converter: org.apache.kafka.connect.storage.StringConverter\n    topics: {topic-name}\n    cos.api.key: {ibm-cos-api-key}\n    cos.bucket.location: {ibm-cos-bucket-location}\n    cos.bucket.name: {your-ibm-cos-bucket-name}\n    cos.bucket.resiliency: {your-resiliency}\n    cos.service.crn: \"{your-ibm-cos-service-crn}\"\n    cos.object.records: 5\n    cos.object.deadline.seconds: 5\n    cos.object.interval.seconds: 5\n```\n\n- Not too many differences from the Strimzi/ESv2019.4.2 version. \n  - Mainly the changing of `apiVersion: eventstreams.ibm.com/v1alpha1`. Not sure why the KafkaConnectS2I is beta and this is alpha. \n  - `metadata.labels.eventstreams.ibm.com/cluster:` instead of `strimzi.io/cluster`\n  \n- Besides these few changes to the YAMLs this should behave as it did previously.\n\n\n## Test the Entire Flow\n\n- Now that we have all the previous steps setup we can now test the entire flow.\n\n- Start our Quarkus Kafka Producer application to send messages to the Event Streams INBOUND topic.\n\n```bash\n./mvnw quarkus:dev\n```\n\n![Quarkus Run Success](./images/quarkus-run-success.png)\n\n- Go to your Event Streams instance on Cloud Pak for Integration. Traverse to the Topics menu and select your `INBOUND` topic and then go to \"Messages\". Choose the \"Live\" option to see an up-to-date stream of your incoming messages.\n\n- Your messages should be propagating the your created IBM COS Bucket automatically.\n\n![Event Streams Topic Success](./images/event-streams-topic-success.png)\n\n- The name of the file inside the bucket has starting offset and ending offset. You can download one of these object files to make sure that the value inside matches the value inside your `INBOUND` topic.\n\n\n![End to End Success](./images/ibm-cos-bucket-success.png)\n","frontmatter":{"title":"Kafka Connect to IBM COS","description":"Apache Kafka to IBM Cloud Object Storage Source Connector usecase"},"fileAbsolutePath":"/home/runner/work/refarch-eda/refarch-eda/docs/src/pages/use-cases/connect-cos/index.mdx"}}},"staticQueryHashes":["1364590287","2102389209","2102389209","2456312558","2746626797","2746626797","3018647132","3018647132","3037994772","3037994772","63531786","63531786","768070550"]}