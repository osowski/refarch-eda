{"componentChunkName":"component---src-pages-use-cases-db-2-debezium-index-mdx","path":"/use-cases/db2-debezium/","result":{"pageContext":{"frontmatter":{"title":"DB2 Change Data Capture with Debezium","description":"DB2 Change Data Capture with Debezium"},"relativePagePath":"/use-cases/db2-debezium/index.mdx","titleType":"append","MdxNode":{"id":"91d8d013-e50a-506d-a465-8d970398264a","children":[],"parent":"3791aa56-fe0b-51c8-bbc0-6fd67b01c274","internal":{"content":"--- \ntitle: DB2 Change Data Capture with Debezium\ndescription: DB2 Change Data Capture with Debezium\n---\n\nThis lab goes over how to implement a change data capture on order events table created using the [outbox pattern](/patterns/intro/#transactional-outbox) with the [Debezium open source](https://debezium.io/) project.\n\nWhat you will learn is:\n\n* DB2 settings for change data capture\n* Configuring Debezium DB2 connector to publish OrderEvents to Kafka topic\n* Validate the Kafka topic content.\n\nWe expect existing knowledge of Kafka, and Kafka connector.\n\n<InlineNotification kind=\"warning\">\n<strong>Updated 11/13/2020</strong> Ready for validation when running local. Need to be completed for OpenShift Deployment.\n</InlineNotification>\n\n\n<AnchorLinks>\n  <AnchorLink>Quick summary of Debezium</AnchorLink>\n  <AnchorLink>Use Case overview</AnchorLink>\n  <AnchorLink>Run locally</AnchorLink>\n  <AnchorLink>Verify starting states</AnchorLink>\n  <AnchorLink>Define the CDC connector</AnchorLink>\n  <AnchorLink>Start consumer</AnchorLink>\n  <AnchorLink>Create an order</AnchorLink>\n  <AnchorLink>References</AnchorLink>\n</AnchorLinks>\n\n## Quick summary of Debezium\n\n[Debezium](https://debezium.io/) is an open source project, led by Red Hat, to support capturing changes to a database and generate those changes to Kafka. It runs in Kafka Connect so support High availability and horizontal scaling. \n\nTo get started we recommend going into [the tutorial](https://debezium.io/documentation/reference/tutorial.html), review the [product documentation](https://debezium.io/documentation/reference/index.html) and for deeper dive you can leverage the [Debezium examples](https://github.com/debezium/debezium-examples). \n\n\nIn an data pipeline architecture, Change Data Capture, helps to inject existing data from existing Database to Kafka and the event-driven microservice. It is important to note that the data generated will be close to what is in the data base, it is possible to do some data transformation to generate some 'business event' from the database updates. Or use raw data and add a Kafka Streams processing to do the data transformation. \n\nDebezium supports DB2 as data source as [introduced by this project](https://github.com/debezium/debezium-connector-db2). As part of the Debezium tutorial in the [Debezium examples](https://github.com/debezium/debezium-examples), you can find a docker compose to start DB2 and Debezium.\n\nFor most of development effort, we are using Docker Compose to run a basic infrastructure with Kafka and Kafka Connect. \n\nOnce DB server and Kafka Connect are started, the approach is to register the DB connector using a json file like below. CDC uses a specific schema to keep source table update. We will detail that in next section.\n\n ```json\n  {\n    \"name\": \"order-connector\",\n    \"config\": {\n        \"connector.class\" : \"io.debezium.connector.db2.Db2Connector\",\n        \"tasks.max\" : \"1\",\n        \"database.server.name\" : \"vaccine_lot_db\",\n        \"database.hostname\" : \"db2\",\n        \"database.port\" : \"50000\",\n        \"database.user\" : \"db2inst1\",\n        \"database.password\" : \"db2inst1\",\n        \"database.dbname\" : \"TESTDB\",\n        \"database.cdcschema\": \"ASNCDC\",\n        \"database.history.kafka.bootstrap.servers\" : \"kafka:9092\",\n        \"database.history.kafka.topic\": \"db_history_vaccine_orders\",\n        \"topic.creation.default.replication.factor\": 1,  \n        \"topic.creation.default.partitions\": 1,  \n        \"topic.creation.default.cleanup.policy\": \"compact\", \n        \"table.include.list\" : \"DB2INST1.ORDEREVENTS\",\n        \"tombstones.on.delete\" : \"false\"\n    }\n  }\n ```\n\n### DB2 connector\n\nThe  [project documentation](https://debezium.io/documentation/reference/connectors/db2.html) presents in detail this connector, but below is a quick summary of the features:\n\n* Tables to monitor are in capture mode, so they have associated chage data table. \n* The Db2 connector reads change events from change-data tables and emits the events to Kafka topics.\n* The Debezium Db2 connector is based on the [ASN Capture/Apply](https://www.ibm.com/support/pages/q-replication-and-sql-replication-product-documentation-pdf-format-version-101-linux-unix-and-windows) agents. A capture agent:\n  * Generates change-data tables for tables that are in capture mode.\n  * Monitors tables in capture mode and stores change events for updates to those tables in their corresponding change-data tables.\n* A user defined function is needed to start or stop the ADN agent, put expected tables in capture mode, create the ASN schema abd change data tables. \n* The connector emits a change event for each row-level insert, update, and delete operation to a Kafka topic that has the same name as the changed table.\n* When the Db2 connector first connects to a particular Db2 database, it starts by performing a consistent snapshot of each table that is in capture mode\n* The connector keeps the log sequence number (LSN) of the change data table entry.\n* Database schema is also replicated so it supports schema updates\n* Each event contains the structure of its key and the payload. Or a reference for a schema registry entry.\n\n\n## Use Case overview\n\nThe use case is part of a larger scenario about order vaccines management. Vaccine orders are managed by an order microservice and using the outbox pattern order created and order updated events are produced to a specific table which is captured by the Debezium connector.\n\n ![0](./images/component-view.png)\n\nThe implementation of the outbox is done using Quarkus Debezium outbox extension and explained in [this separate note](https://ibm-cloud-architecture.github.io/vaccine-solution-main/solution/orderms/).\n\nIn this lab, you will get the component running on you computer or on OpenShift.\n\n## Run locally\n\nClone the order management service:\n\n ```shell\n git clone https://github.com/ibm-cloud-architecture/vaccine-order-mgr\n ```\n\nAnd then start the five processes (one Kafka broker, one ZooKeeper, one DB2 container for the persistence, one Kafka Connect with the Debezium code and DB2 JDBC driver and one vaccine-order-service) with Docker Compose.\n\n ```shell\n cd environment\n # with the option to build the db2, and debezium cdc container images\n docker-compose -f strimzi-docker-compose.yaml up -d --build\n # or with pre-existing images coming from dockerhub\n docker-compose -f strimzi-docker-compose.yaml  up -d\n ```\n\n* Create the needed topics\n\n```shell\n  # Under environment folder\n  ./createTopic.sh\n  # validate topics created\n  ./listTopics.sh\n\n  __consumer_offsets\n  db_history_vaccine_orders\n  src_connect_configs\n  src_connect_offsets\n  src_connect_statuses\n  vaccine_shipmentplan\n```\n\nThe `db_history_vaccine_orders` is the topic used to include database schema change on the vaccine orders table. \n\n## Verify starting states \n\nTo validate the DB2 settings, you can do one of the following troubleshooting commands:\n\n```shell\n# connect to DB2 server\ndocker exec -ti db2 bash\n# Access the database \ndb2 connect to TESTDB USER DB2INST1\n# use db2inst1 as password\n# list existing schemas\n db2 \"select * from syscat.schemata\"\n# list tables\ndb2 list tables\n# this is the outcomes if the order services was started\nTable/View                      Schema          Type  Creation time             \n------------------------------- --------------- ----- --------------------------\nORDERCREATEDEVENT               DB2INST1        T     2020-11-12-01.50.10.400490\nORDEREVENTS                     DB2INST1        T     2020-11-12-01.50.10.650172\nORDERUPDATEDEVENT               DB2INST1        T     2020-11-12-01.50.10.796566\nVACCINEORDERENTITY              DB2INST1        T     2020-11-12-01.50.10.874172\n# Verify the content of the current orders\ndb2 \"select * from vaccineorderentity\"\n# List the table for the change data capture\ndb2 list tables for schema asncdc\n```\n\nThe DB2 container was built to define ASNCDC schema to support table capture. The setup is described in [this note](https://debezium.io/documentation/reference/connectors/db2.html#setting-up-db2) and supported by [this script](https://github.com/ibm-cloud-architecture/vaccine-order-mgr/blob/master/environment/db2image/dbsetup.sh).\n\nWhen reusing this asset, the only thing you need to configure is the [startup-cdc.sql](https://github.com/ibm-cloud-architecture/vaccine-order-mgr/blob/master/environment/db2image/startup-cdc.sql) to specify the table(s) you want to capture.\n\n```shell\nVALUES ASNCDC.ASNCDCSERVICES('status','asncdc');\nCALL ASNCDC.ADDTABLE('DB2INST1', 'ORDEREVENTS' ); \nVALUES ASNCDC.ASNCDCSERVICES('reinit','asncdc');\n```\n\nand tune the content of the `register-db2.json` file to configure the Kafka Connector (see next section). \n\nThe application may have some issue to start as DB2 may take some time to configure, so it is important to verify the containers running (if you know how to add healthcheck on DB2 container... open a PR):\n\n```shell\ndocker ps \nCONTAINER ID         IMAGES                             NAMES\n5ddd45b5856e        ibmcase/vaccineorderms             vaccineorderms\n5bce18c820fc        ibmcase/cdc-connector              cdc-connector\n7fd6951972df        strimzi/kafka:latest-kafka-2.6.0   kafka\nb0f9127c874e        strimzi/kafka:latest-kafka-2.6.0   zookeeper\n7f356633ea2f        ibmcase/db2orders                  db2\n# Get come logs using the container name\ndocker logs vaccineorderms\n```\n\nIf for any reason the `vaccineorderms`, doing a `docker-compose up -d` will restart the container.\n\nYou can use the User interface to get the current order loaded. At the starting time there should be only one record. [http://localhost:8080/#/Orders](http://localhost:8080/#/Orders).\n\n ![2](./images/order-ui.png)\n\n## Define the CDC connector\n\nDeploy and start the Debezium DB2 connector. The connector definition is in [register-db2.json](https://github.com/ibm-cloud-architecture/vaccine-order-mgr/blob/master/environment/cdc/register-db2.json). The important elements of this file are below:\n\n```json\n# the namespace for the server that will be used in the topic created\n\"database.server.name\" : \"vaccine_lot_db\",\n# database credentials\n# The list of table to capture\n  \"table.include.list\" : \"DB2INST1.ORDEREVENTS\",\n# name for the topic to keep track of the database schema changes.\n \"database.history.kafka.topic\": \"db_history_vaccine_orders\",  \n```\n\nTo deploy to the Kafka Connector instance, perform a POST with the previous configuration as:\n\n ```shell\n # under environment/cdc\n curl -i -X POST -H \"Accept:application/json\" -H  \"Content-Type:application/json\" http://localhost:8083/connectors/ -d @cdc/register-db2.json\n ```\n\n* Get the status of the Kafka connector at:  [http://localhost:8083/connectors/orderdb-connector/](http://localhost:8083/connectors/orderdb-connector/)\n\n* Verify the newly created topics:\n\n```shell\n  ./listTopics.sh \n  vaccine_lot_db\n  vaccine_lot_db.DB2INST1.ORDEREVENTS\n```\n\nThe newly created `vaccine_lot_db` topic includes definition of the database and the connector. It does not aim to be used by application. The one to be used to get business events is `vaccine_lot_db.DB2INST1.ORDEREVENTS`.\n\nThe connector is doing a snapshot of the `DB2INST1.ORDEREVENTS` table to send existing records to the topic.\n\n## Start consumer\n\nStart a Kafka consumer, using the console consumer tool: \n\n```shell\ndocker-compose exec kafka /opt/kafka/bin/kafka-console-consumer.sh     --bootstrap-server kafka:9092     --from-beginning     --property print.key=true     --topic db2server.DB2INST1.ORDERS\n```\n\n## Create an order\n\nYou can use the user interface to add a new order, \n\n ![3](./images/new-order.png)\n\nor use the swagger operation at [http://localhost:8080/swagger-ui/#/default/post_api_v1_orders](http://localhost:8080/swagger-ui/#/default/post_api_v1_orders)\n\nUse the following JSON:\n\n ```json\n {\n    \"deliveryDate\": \"2021-07-25\",\n    \"deliveryLocation\": \"Milano\",\n    \"askingOrganization\": \"Italy gov\",\n    \"priority\": 1,\n    \"quantity\": 100,\n    \"type\": \"COVID-19\"\n }\n ```\n\nThe expected result in the topic consumer should have the following records in the Kafka topic:\n\n ```json\n {\"ID\":\"lvz4gYs/Q+aSqKmWjVGMXg==\"}\t\n {\"before\":null,\"after\":{\"ID\":\"lvz4gYs/Q+aSqKmWjVGMXg==\",\"AGGREGATETYPE\":\"VaccineOrderEntity\",\"AGGREGATEID\":\"21\",\"TYPE\":\"OrderCreated\",\"TIMESTAMP\":1605304440331350,\"PAYLOAD\":\"{\\\"orderID\\\":21,\\\"deliveryLocation\\\":\\\"London\\\",\\\"quantity\\\":150,\\\"priority\\\":2,\\\"deliveryDate\\\":\\\"2020-12-25\\\",\\\"askingOrganization\\\":\\\"UK Governement\\\",\\\"vaccineType\\\":\\\"COVID-19\\\",\\\"status\\\":\\\"OPEN\\\",\\\"creationDate\\\":\\\"13-Nov-2020 21:54:00\\\"}\"},\"source\":{\"version\":\"1.3.0.Final\",\"connector\":\"db2\",\"name\":\"vaccine_lot_db\",\"ts_ms\":1605304806596,\"snapshot\":\"last\",\"db\":\"TESTDB\",\"schema\":\"DB2INST1\",\"table\":\"ORDEREVENTS\",\"change_lsn\":null,\"commit_lsn\":\"00000000:0000150f:0000000000048fca\"},\"op\":\"r\",\"ts_ms\":1605304806600,\"transaction\":null}\n ```\n\n## References\n\n* [Outbox pattern for quarkus](https://debezium.io/documentation/reference/integrations/outbox.html)\n* [Blog on the outbox pattern](https://debezium.io/blog/2019/02/19/reliable-microservices-data-exchange-with-the-outbox-pattern/)\n* [Db2 Debezium connector](https://debezium.io/documentation/reference/connectors/db2.html)\n","type":"Mdx","contentDigest":"b9148b3c2c540cbf4109d3935b9c35b2","owner":"gatsby-plugin-mdx","counter":720},"frontmatter":{"title":"DB2 Change Data Capture with Debezium","description":"DB2 Change Data Capture with Debezium"},"exports":{},"rawBody":"--- \ntitle: DB2 Change Data Capture with Debezium\ndescription: DB2 Change Data Capture with Debezium\n---\n\nThis lab goes over how to implement a change data capture on order events table created using the [outbox pattern](/patterns/intro/#transactional-outbox) with the [Debezium open source](https://debezium.io/) project.\n\nWhat you will learn is:\n\n* DB2 settings for change data capture\n* Configuring Debezium DB2 connector to publish OrderEvents to Kafka topic\n* Validate the Kafka topic content.\n\nWe expect existing knowledge of Kafka, and Kafka connector.\n\n<InlineNotification kind=\"warning\">\n<strong>Updated 11/13/2020</strong> Ready for validation when running local. Need to be completed for OpenShift Deployment.\n</InlineNotification>\n\n\n<AnchorLinks>\n  <AnchorLink>Quick summary of Debezium</AnchorLink>\n  <AnchorLink>Use Case overview</AnchorLink>\n  <AnchorLink>Run locally</AnchorLink>\n  <AnchorLink>Verify starting states</AnchorLink>\n  <AnchorLink>Define the CDC connector</AnchorLink>\n  <AnchorLink>Start consumer</AnchorLink>\n  <AnchorLink>Create an order</AnchorLink>\n  <AnchorLink>References</AnchorLink>\n</AnchorLinks>\n\n## Quick summary of Debezium\n\n[Debezium](https://debezium.io/) is an open source project, led by Red Hat, to support capturing changes to a database and generate those changes to Kafka. It runs in Kafka Connect so support High availability and horizontal scaling. \n\nTo get started we recommend going into [the tutorial](https://debezium.io/documentation/reference/tutorial.html), review the [product documentation](https://debezium.io/documentation/reference/index.html) and for deeper dive you can leverage the [Debezium examples](https://github.com/debezium/debezium-examples). \n\n\nIn an data pipeline architecture, Change Data Capture, helps to inject existing data from existing Database to Kafka and the event-driven microservice. It is important to note that the data generated will be close to what is in the data base, it is possible to do some data transformation to generate some 'business event' from the database updates. Or use raw data and add a Kafka Streams processing to do the data transformation. \n\nDebezium supports DB2 as data source as [introduced by this project](https://github.com/debezium/debezium-connector-db2). As part of the Debezium tutorial in the [Debezium examples](https://github.com/debezium/debezium-examples), you can find a docker compose to start DB2 and Debezium.\n\nFor most of development effort, we are using Docker Compose to run a basic infrastructure with Kafka and Kafka Connect. \n\nOnce DB server and Kafka Connect are started, the approach is to register the DB connector using a json file like below. CDC uses a specific schema to keep source table update. We will detail that in next section.\n\n ```json\n  {\n    \"name\": \"order-connector\",\n    \"config\": {\n        \"connector.class\" : \"io.debezium.connector.db2.Db2Connector\",\n        \"tasks.max\" : \"1\",\n        \"database.server.name\" : \"vaccine_lot_db\",\n        \"database.hostname\" : \"db2\",\n        \"database.port\" : \"50000\",\n        \"database.user\" : \"db2inst1\",\n        \"database.password\" : \"db2inst1\",\n        \"database.dbname\" : \"TESTDB\",\n        \"database.cdcschema\": \"ASNCDC\",\n        \"database.history.kafka.bootstrap.servers\" : \"kafka:9092\",\n        \"database.history.kafka.topic\": \"db_history_vaccine_orders\",\n        \"topic.creation.default.replication.factor\": 1,  \n        \"topic.creation.default.partitions\": 1,  \n        \"topic.creation.default.cleanup.policy\": \"compact\", \n        \"table.include.list\" : \"DB2INST1.ORDEREVENTS\",\n        \"tombstones.on.delete\" : \"false\"\n    }\n  }\n ```\n\n### DB2 connector\n\nThe  [project documentation](https://debezium.io/documentation/reference/connectors/db2.html) presents in detail this connector, but below is a quick summary of the features:\n\n* Tables to monitor are in capture mode, so they have associated chage data table. \n* The Db2 connector reads change events from change-data tables and emits the events to Kafka topics.\n* The Debezium Db2 connector is based on the [ASN Capture/Apply](https://www.ibm.com/support/pages/q-replication-and-sql-replication-product-documentation-pdf-format-version-101-linux-unix-and-windows) agents. A capture agent:\n  * Generates change-data tables for tables that are in capture mode.\n  * Monitors tables in capture mode and stores change events for updates to those tables in their corresponding change-data tables.\n* A user defined function is needed to start or stop the ADN agent, put expected tables in capture mode, create the ASN schema abd change data tables. \n* The connector emits a change event for each row-level insert, update, and delete operation to a Kafka topic that has the same name as the changed table.\n* When the Db2 connector first connects to a particular Db2 database, it starts by performing a consistent snapshot of each table that is in capture mode\n* The connector keeps the log sequence number (LSN) of the change data table entry.\n* Database schema is also replicated so it supports schema updates\n* Each event contains the structure of its key and the payload. Or a reference for a schema registry entry.\n\n\n## Use Case overview\n\nThe use case is part of a larger scenario about order vaccines management. Vaccine orders are managed by an order microservice and using the outbox pattern order created and order updated events are produced to a specific table which is captured by the Debezium connector.\n\n ![0](./images/component-view.png)\n\nThe implementation of the outbox is done using Quarkus Debezium outbox extension and explained in [this separate note](https://ibm-cloud-architecture.github.io/vaccine-solution-main/solution/orderms/).\n\nIn this lab, you will get the component running on you computer or on OpenShift.\n\n## Run locally\n\nClone the order management service:\n\n ```shell\n git clone https://github.com/ibm-cloud-architecture/vaccine-order-mgr\n ```\n\nAnd then start the five processes (one Kafka broker, one ZooKeeper, one DB2 container for the persistence, one Kafka Connect with the Debezium code and DB2 JDBC driver and one vaccine-order-service) with Docker Compose.\n\n ```shell\n cd environment\n # with the option to build the db2, and debezium cdc container images\n docker-compose -f strimzi-docker-compose.yaml up -d --build\n # or with pre-existing images coming from dockerhub\n docker-compose -f strimzi-docker-compose.yaml  up -d\n ```\n\n* Create the needed topics\n\n```shell\n  # Under environment folder\n  ./createTopic.sh\n  # validate topics created\n  ./listTopics.sh\n\n  __consumer_offsets\n  db_history_vaccine_orders\n  src_connect_configs\n  src_connect_offsets\n  src_connect_statuses\n  vaccine_shipmentplan\n```\n\nThe `db_history_vaccine_orders` is the topic used to include database schema change on the vaccine orders table. \n\n## Verify starting states \n\nTo validate the DB2 settings, you can do one of the following troubleshooting commands:\n\n```shell\n# connect to DB2 server\ndocker exec -ti db2 bash\n# Access the database \ndb2 connect to TESTDB USER DB2INST1\n# use db2inst1 as password\n# list existing schemas\n db2 \"select * from syscat.schemata\"\n# list tables\ndb2 list tables\n# this is the outcomes if the order services was started\nTable/View                      Schema          Type  Creation time             \n------------------------------- --------------- ----- --------------------------\nORDERCREATEDEVENT               DB2INST1        T     2020-11-12-01.50.10.400490\nORDEREVENTS                     DB2INST1        T     2020-11-12-01.50.10.650172\nORDERUPDATEDEVENT               DB2INST1        T     2020-11-12-01.50.10.796566\nVACCINEORDERENTITY              DB2INST1        T     2020-11-12-01.50.10.874172\n# Verify the content of the current orders\ndb2 \"select * from vaccineorderentity\"\n# List the table for the change data capture\ndb2 list tables for schema asncdc\n```\n\nThe DB2 container was built to define ASNCDC schema to support table capture. The setup is described in [this note](https://debezium.io/documentation/reference/connectors/db2.html#setting-up-db2) and supported by [this script](https://github.com/ibm-cloud-architecture/vaccine-order-mgr/blob/master/environment/db2image/dbsetup.sh).\n\nWhen reusing this asset, the only thing you need to configure is the [startup-cdc.sql](https://github.com/ibm-cloud-architecture/vaccine-order-mgr/blob/master/environment/db2image/startup-cdc.sql) to specify the table(s) you want to capture.\n\n```shell\nVALUES ASNCDC.ASNCDCSERVICES('status','asncdc');\nCALL ASNCDC.ADDTABLE('DB2INST1', 'ORDEREVENTS' ); \nVALUES ASNCDC.ASNCDCSERVICES('reinit','asncdc');\n```\n\nand tune the content of the `register-db2.json` file to configure the Kafka Connector (see next section). \n\nThe application may have some issue to start as DB2 may take some time to configure, so it is important to verify the containers running (if you know how to add healthcheck on DB2 container... open a PR):\n\n```shell\ndocker ps \nCONTAINER ID         IMAGES                             NAMES\n5ddd45b5856e        ibmcase/vaccineorderms             vaccineorderms\n5bce18c820fc        ibmcase/cdc-connector              cdc-connector\n7fd6951972df        strimzi/kafka:latest-kafka-2.6.0   kafka\nb0f9127c874e        strimzi/kafka:latest-kafka-2.6.0   zookeeper\n7f356633ea2f        ibmcase/db2orders                  db2\n# Get come logs using the container name\ndocker logs vaccineorderms\n```\n\nIf for any reason the `vaccineorderms`, doing a `docker-compose up -d` will restart the container.\n\nYou can use the User interface to get the current order loaded. At the starting time there should be only one record. [http://localhost:8080/#/Orders](http://localhost:8080/#/Orders).\n\n ![2](./images/order-ui.png)\n\n## Define the CDC connector\n\nDeploy and start the Debezium DB2 connector. The connector definition is in [register-db2.json](https://github.com/ibm-cloud-architecture/vaccine-order-mgr/blob/master/environment/cdc/register-db2.json). The important elements of this file are below:\n\n```json\n# the namespace for the server that will be used in the topic created\n\"database.server.name\" : \"vaccine_lot_db\",\n# database credentials\n# The list of table to capture\n  \"table.include.list\" : \"DB2INST1.ORDEREVENTS\",\n# name for the topic to keep track of the database schema changes.\n \"database.history.kafka.topic\": \"db_history_vaccine_orders\",  \n```\n\nTo deploy to the Kafka Connector instance, perform a POST with the previous configuration as:\n\n ```shell\n # under environment/cdc\n curl -i -X POST -H \"Accept:application/json\" -H  \"Content-Type:application/json\" http://localhost:8083/connectors/ -d @cdc/register-db2.json\n ```\n\n* Get the status of the Kafka connector at:  [http://localhost:8083/connectors/orderdb-connector/](http://localhost:8083/connectors/orderdb-connector/)\n\n* Verify the newly created topics:\n\n```shell\n  ./listTopics.sh \n  vaccine_lot_db\n  vaccine_lot_db.DB2INST1.ORDEREVENTS\n```\n\nThe newly created `vaccine_lot_db` topic includes definition of the database and the connector. It does not aim to be used by application. The one to be used to get business events is `vaccine_lot_db.DB2INST1.ORDEREVENTS`.\n\nThe connector is doing a snapshot of the `DB2INST1.ORDEREVENTS` table to send existing records to the topic.\n\n## Start consumer\n\nStart a Kafka consumer, using the console consumer tool: \n\n```shell\ndocker-compose exec kafka /opt/kafka/bin/kafka-console-consumer.sh     --bootstrap-server kafka:9092     --from-beginning     --property print.key=true     --topic db2server.DB2INST1.ORDERS\n```\n\n## Create an order\n\nYou can use the user interface to add a new order, \n\n ![3](./images/new-order.png)\n\nor use the swagger operation at [http://localhost:8080/swagger-ui/#/default/post_api_v1_orders](http://localhost:8080/swagger-ui/#/default/post_api_v1_orders)\n\nUse the following JSON:\n\n ```json\n {\n    \"deliveryDate\": \"2021-07-25\",\n    \"deliveryLocation\": \"Milano\",\n    \"askingOrganization\": \"Italy gov\",\n    \"priority\": 1,\n    \"quantity\": 100,\n    \"type\": \"COVID-19\"\n }\n ```\n\nThe expected result in the topic consumer should have the following records in the Kafka topic:\n\n ```json\n {\"ID\":\"lvz4gYs/Q+aSqKmWjVGMXg==\"}\t\n {\"before\":null,\"after\":{\"ID\":\"lvz4gYs/Q+aSqKmWjVGMXg==\",\"AGGREGATETYPE\":\"VaccineOrderEntity\",\"AGGREGATEID\":\"21\",\"TYPE\":\"OrderCreated\",\"TIMESTAMP\":1605304440331350,\"PAYLOAD\":\"{\\\"orderID\\\":21,\\\"deliveryLocation\\\":\\\"London\\\",\\\"quantity\\\":150,\\\"priority\\\":2,\\\"deliveryDate\\\":\\\"2020-12-25\\\",\\\"askingOrganization\\\":\\\"UK Governement\\\",\\\"vaccineType\\\":\\\"COVID-19\\\",\\\"status\\\":\\\"OPEN\\\",\\\"creationDate\\\":\\\"13-Nov-2020 21:54:00\\\"}\"},\"source\":{\"version\":\"1.3.0.Final\",\"connector\":\"db2\",\"name\":\"vaccine_lot_db\",\"ts_ms\":1605304806596,\"snapshot\":\"last\",\"db\":\"TESTDB\",\"schema\":\"DB2INST1\",\"table\":\"ORDEREVENTS\",\"change_lsn\":null,\"commit_lsn\":\"00000000:0000150f:0000000000048fca\"},\"op\":\"r\",\"ts_ms\":1605304806600,\"transaction\":null}\n ```\n\n## References\n\n* [Outbox pattern for quarkus](https://debezium.io/documentation/reference/integrations/outbox.html)\n* [Blog on the outbox pattern](https://debezium.io/blog/2019/02/19/reliable-microservices-data-exchange-with-the-outbox-pattern/)\n* [Db2 Debezium connector](https://debezium.io/documentation/reference/connectors/db2.html)\n","fileAbsolutePath":"/home/runner/work/refarch-eda/refarch-eda/docs/src/pages/use-cases/db2-debezium/index.mdx"}}},"staticQueryHashes":["1054721580","1054721580","1364590287","2102389209","2102389209","2456312558","2746626797","2746626797","3018647132","3018647132","3037994772","3037994772","768070550"]}