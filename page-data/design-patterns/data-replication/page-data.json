{"componentChunkName":"component---src-pages-design-patterns-data-replication-mdx","path":"/design-patterns/data-replication/","result":{"pageContext":{"frontmatter":{"title":"Data replication in context of EDA","description":"Data replication in context of EDA"},"relativePagePath":"/design-patterns/data-replication.mdx","titleType":"append","MdxNode":{"id":"73c4b573-a741-53ac-9cf8-70c1298f581a","children":[],"parent":"874b9fbb-bdf8-54c5-b31f-10350468d2cd","internal":{"content":"---\ntitle: Data replication in context of EDA\ndescription: Data replication in context of EDA\n---\n\nAs an introduction to the scope of the data replication in the context of distributed system, we encourage to read our summary in [this article](https://ibm-cloud-architecture.github.io/refarch-data-ai-analytics/data/data-replication/).\n\nIn this section we are going to address the data replication in the context of Kafka using IBM Geo Replication and Kafka Mirror Maker 2.\n\n## Problem statement\n\nWe suppose we need to replicate data in Kafka topics between different Kafka clusters running in different availability zones or data centers. There are multiple motivations for such replication. We can list at least the followings:\n\n* Support disaster recovery, using different data centers to replicate microservice generated data in an active - passive mode.\n* Move data closer to end user to improve performance and latency, this is more an active - active model, where the same microservices are deployed on the different data centers.\n* The need to build on-premise data aggregation or data lake layer to perform batch analytics jobs from data gathered from different remote environments.\n* Isolate secure data from on-premise cluster, with data encryption and data transformation to remove personal identifiable information, but still exchange such data between environments.\n\nWe are proposing two environments:\n\n* One running a local, on-premise cluster using Kafka 2.4 open source packaging, like Strimzi vanilla Kafka or Red Hat AMQ Streams, and IBM Event Streams on Cloud.\n\n![Replication with mirror maker](images/replication-2.png)\n\nIn the figure above, Mirror Maker 2.0 is used to do bi-directional replication between topics defined in both cluster. The grey topic is replicated from right to left, and the Mirror Maker 2.0 source connector runs close to the target cluster, the left cluster. The light blue topic is replicated from left to right by the second Mirror Maker 2.0. Microservices on both data centers can consume messages from both topics.\n\n* One running Event streams on Openshift on-premise, and using Geo-replication to Event Streams on IBM cloud.\n\n![Replication with geo replication](images/replication-1.png)\n\nThen we want to address two main scenarios:\n\n* [Active - passive](#active-passive), which addresses more a disaster recovery approach where consumers reconnect to a new cluster after the first one fails.\n* [Active - active](#active-active) deployments where participant clusters have producers and consumers and some topics are replicated so the messages are processed by different consumers\n\nBut first we need to review the new replication capability introduced with Kafka 2.4, the [Mirror Maker 2.0](https://cwiki.apache.org/confluence/display/KAFKA/KIP-382%3A+MirrorMaker+2.0).\n\n## Mirror Maker 2.0\n\nMirror maker 2.0 is a new feature as part of Kafka 2.4 to support data replication between clusters. It is based on Kafka Connect framework, and it supports data and metadata replication, like the topic configuration, the offset and the consumer checkpoints are synchronously replicated to the target cluster.\n\nMirror maker uses the cluster name or identifier as prefix for topic, and uses the concept of source topic and target topic. The specification is described in detail in [this KIP 382](https://cwiki.apache.org/confluence/display/KAFKA/KIP-382%3A+MirrorMaker+2.0#KIP-382:MirrorMaker2.0-RemoteTopics,Partitions).\n\nTo test the tool, we can use the Strimzi Kafka latest docker image deployed on Openshift cluster (We address Strimzi deployment in [this note](../deployments/strimzi/deploy.md)). For mirror maker 2.0, the deployment descriptor are in the [Strimzi project](https://strimzi.io/downloads/) under the `examples/kafka-mirror-maker-2` folder (we have a copy of this yaml file, prepared for our replication, in the deployments/strimzi folder of this project).\n\nTo define the clusters and topic configuration we use a properties file. One simple example to replicate from IBM Cloud Event streams to Kafka on premise is in the folder [deployments/strimzi/es-mirror-maker.properties](https://github.com/ibm-cloud-architecture/refarch-eda/blob/master/deployments/strimzi/es-mirror-maker.properties)\n\nUsing the same kafka image we can start a mirror maker container with:\n\n```properties\nclusters = source, target\nsource.bootstrap.servers = my-cluster-kafka-bootstrap-jb-kafka-strimzi.gse-eda-demos-fa9ee67c9ab6a7791435450358e564cc-0001.us-east.containers.appdomain.cloud:443\nsource.security.protocol=SSL\nsource.ssl.truststore.password=password\nsource.ssl.truststore.location=/home/truststore.jks\ntarget.bootstrap.servers = kafka1:9092\n# enable and configure individual replication flows\nsource->target.enabled = true\nsource->target.topics = test\n```\n\n```bash\n./connect-mirror-maker.sh /home/strimzi.properties \n```\nWhen Mirror maker starts it will create some topics on source cluster to manage the offsets and topic metadata:\n\n```\nmm2-configs.target.internal                                   1            3\nmm2-offset-syncs.target.internal                              1            3\nmm2-offsets.target.internal                                   25           3\nmm2-status.target.internal                                    5            3\n```\n\nAnd on the target cluster:\n\n```\n__consumer_offsets\nheartbeats\nmm2-configs.source.internal\nmm2-offsets.source.internal\nmm2-status.source.internal\nsource.checkpoints.internal\nsource.heartbeats\nsource.test\n```\n\nThe `source.test` topic is the replicated `test` topic from the source cluster.\n\n![](images/mm-k-connect.png)\n\n## Active - Passive\n\nTo support active - passive, one site has producers and consumers on local topics, and topic data are replicated on active cluster without online consumers\n\n\n## Active - Active\n\n* producers, deployed on IBM cloud within Openshift, send messages to Event streams on cloud, on the 'reeferTelemetries` topic. The explanation of the telemetry simulator producer deployment is done [here.](https://ibm-cloud-architecture.github.io/refarch-reefer-ml/infuse/simul-app/#prepare-for-kubernetes-deployment)","type":"Mdx","contentDigest":"2d503da7dbee846c58849ae2a7075af9","counter":241,"owner":"gatsby-plugin-mdx"},"frontmatter":{"title":"Data replication in context of EDA","description":"Data replication in context of EDA"},"exports":{},"rawBody":"---\ntitle: Data replication in context of EDA\ndescription: Data replication in context of EDA\n---\n\nAs an introduction to the scope of the data replication in the context of distributed system, we encourage to read our summary in [this article](https://ibm-cloud-architecture.github.io/refarch-data-ai-analytics/data/data-replication/).\n\nIn this section we are going to address the data replication in the context of Kafka using IBM Geo Replication and Kafka Mirror Maker 2.\n\n## Problem statement\n\nWe suppose we need to replicate data in Kafka topics between different Kafka clusters running in different availability zones or data centers. There are multiple motivations for such replication. We can list at least the followings:\n\n* Support disaster recovery, using different data centers to replicate microservice generated data in an active - passive mode.\n* Move data closer to end user to improve performance and latency, this is more an active - active model, where the same microservices are deployed on the different data centers.\n* The need to build on-premise data aggregation or data lake layer to perform batch analytics jobs from data gathered from different remote environments.\n* Isolate secure data from on-premise cluster, with data encryption and data transformation to remove personal identifiable information, but still exchange such data between environments.\n\nWe are proposing two environments:\n\n* One running a local, on-premise cluster using Kafka 2.4 open source packaging, like Strimzi vanilla Kafka or Red Hat AMQ Streams, and IBM Event Streams on Cloud.\n\n![Replication with mirror maker](images/replication-2.png)\n\nIn the figure above, Mirror Maker 2.0 is used to do bi-directional replication between topics defined in both cluster. The grey topic is replicated from right to left, and the Mirror Maker 2.0 source connector runs close to the target cluster, the left cluster. The light blue topic is replicated from left to right by the second Mirror Maker 2.0. Microservices on both data centers can consume messages from both topics.\n\n* One running Event streams on Openshift on-premise, and using Geo-replication to Event Streams on IBM cloud.\n\n![Replication with geo replication](images/replication-1.png)\n\nThen we want to address two main scenarios:\n\n* [Active - passive](#active-passive), which addresses more a disaster recovery approach where consumers reconnect to a new cluster after the first one fails.\n* [Active - active](#active-active) deployments where participant clusters have producers and consumers and some topics are replicated so the messages are processed by different consumers\n\nBut first we need to review the new replication capability introduced with Kafka 2.4, the [Mirror Maker 2.0](https://cwiki.apache.org/confluence/display/KAFKA/KIP-382%3A+MirrorMaker+2.0).\n\n## Mirror Maker 2.0\n\nMirror maker 2.0 is a new feature as part of Kafka 2.4 to support data replication between clusters. It is based on Kafka Connect framework, and it supports data and metadata replication, like the topic configuration, the offset and the consumer checkpoints are synchronously replicated to the target cluster.\n\nMirror maker uses the cluster name or identifier as prefix for topic, and uses the concept of source topic and target topic. The specification is described in detail in [this KIP 382](https://cwiki.apache.org/confluence/display/KAFKA/KIP-382%3A+MirrorMaker+2.0#KIP-382:MirrorMaker2.0-RemoteTopics,Partitions).\n\nTo test the tool, we can use the Strimzi Kafka latest docker image deployed on Openshift cluster (We address Strimzi deployment in [this note](../deployments/strimzi/deploy.md)). For mirror maker 2.0, the deployment descriptor are in the [Strimzi project](https://strimzi.io/downloads/) under the `examples/kafka-mirror-maker-2` folder (we have a copy of this yaml file, prepared for our replication, in the deployments/strimzi folder of this project).\n\nTo define the clusters and topic configuration we use a properties file. One simple example to replicate from IBM Cloud Event streams to Kafka on premise is in the folder [deployments/strimzi/es-mirror-maker.properties](https://github.com/ibm-cloud-architecture/refarch-eda/blob/master/deployments/strimzi/es-mirror-maker.properties)\n\nUsing the same kafka image we can start a mirror maker container with:\n\n```properties\nclusters = source, target\nsource.bootstrap.servers = my-cluster-kafka-bootstrap-jb-kafka-strimzi.gse-eda-demos-fa9ee67c9ab6a7791435450358e564cc-0001.us-east.containers.appdomain.cloud:443\nsource.security.protocol=SSL\nsource.ssl.truststore.password=password\nsource.ssl.truststore.location=/home/truststore.jks\ntarget.bootstrap.servers = kafka1:9092\n# enable and configure individual replication flows\nsource->target.enabled = true\nsource->target.topics = test\n```\n\n```bash\n./connect-mirror-maker.sh /home/strimzi.properties \n```\nWhen Mirror maker starts it will create some topics on source cluster to manage the offsets and topic metadata:\n\n```\nmm2-configs.target.internal                                   1            3\nmm2-offset-syncs.target.internal                              1            3\nmm2-offsets.target.internal                                   25           3\nmm2-status.target.internal                                    5            3\n```\n\nAnd on the target cluster:\n\n```\n__consumer_offsets\nheartbeats\nmm2-configs.source.internal\nmm2-offsets.source.internal\nmm2-status.source.internal\nsource.checkpoints.internal\nsource.heartbeats\nsource.test\n```\n\nThe `source.test` topic is the replicated `test` topic from the source cluster.\n\n![](images/mm-k-connect.png)\n\n## Active - Passive\n\nTo support active - passive, one site has producers and consumers on local topics, and topic data are replicated on active cluster without online consumers\n\n\n## Active - Active\n\n* producers, deployed on IBM cloud within Openshift, send messages to Event streams on cloud, on the 'reeferTelemetries` topic. The explanation of the telemetry simulator producer deployment is done [here.](https://ibm-cloud-architecture.github.io/refarch-reefer-ml/infuse/simul-app/#prepare-for-kubernetes-deployment)","fileAbsolutePath":"/home/runner/work/refarch-eda/refarch-eda/docs-gatsby/src/pages/design-patterns/data-replication.mdx"}}}}