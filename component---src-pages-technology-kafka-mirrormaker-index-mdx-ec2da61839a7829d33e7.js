(window.webpackJsonp=window.webpackJsonp||[]).push([[41],{"6UeB":function(e,t,a){"use strict";a.r(t),a.d(t,"_frontmatter",(function(){return i})),a.d(t,"default",(function(){return l}));a("91GP"),a("rGqo"),a("yt8O"),a("Btvt"),a("RW0V"),a("q1tI");var r=a("7ljp"),n=a("013z");a("qKvR");function o(){return(o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var a=arguments[t];for(var r in a)Object.prototype.hasOwnProperty.call(a,r)&&(e[r]=a[r])}return e}).apply(this,arguments)}var i={},c={_frontmatter:i},s=n.a;function l(e){var t=e.components,a=function(e,t){if(null==e)return{};var a,r,n={},o=Object.keys(e);for(r=0;r<o.length;r++)a=o[r],t.indexOf(a)>=0||(n[a]=e[a]);return n}(e,["components"]);return Object(r.b)(s,o({},c,a,{components:t,mdxType:"MDXLayout"}),Object(r.b)("p",null,"This section introduces ",Object(r.b)("strong",{parentName:"p"},"Mirror Maker 2.0"),", the new replication feature of Kafka 2.4, and how it can be used, along with best practices, for data replication between two Kafka clusters. Mirror Maker 2.0 was defined as part of the Kafka Improvement Process - ",Object(r.b)("a",o({parentName:"p"},{href:"https://cwiki.apache.org/confluence/display/KAFKA/KIP-382%3A+MirrorMaker+2.0"}),"KIP 382"),"."),Object(r.b)("h2",null,"General concepts"),Object(r.b)("p",null,"As ",Object(r.b)("a",o({parentName:"p"},{href:"https://strimzi.io/docs/master/#con-configuring-mirror-maker-deployment-configuration-kafka-mirror-maker"}),"Mirror maker 2.0")," is using Kafka Connect framework, we recommend to review our summary of Kafka Connect ",Object(r.b)("a",o({parentName:"p"},{href:"../kafka-connect/"}),"here"),"."),Object(r.b)("p",null,"The figure below illustrates the MirrorMaker 2.0 internal components running within Kafka Connect."),Object(r.b)("span",{className:"gatsby-resp-image-wrapper",style:{position:"relative",display:"block",marginLeft:"auto",marginRight:"auto",maxWidth:"662px"}},"\n      ",Object(r.b)("span",o({parentName:"span"},{className:"gatsby-resp-image-background-image",style:{paddingBottom:"39.583333333333336%",position:"relative",bottom:"0",left:"0",backgroundImage:"url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAICAYAAAD5nd/tAAAACXBIWXMAAAsSAAALEgHS3X78AAABjklEQVQoz22SS2/TQBSF/fNBILGqkBA7FgjEgl3VqmZRFxohUiq3inkkMYYEO45rZ+wQP8b2x8ykRllwpDOPOzP33MdYKHRdT9drgpr2s7I3TU25y6nKQq0bZKfOlL2SmLW+o9GrRwOtruuMUY+y7WnazrBV++3mB97HF/juS3VBUOUBvmcjYhdRbAnjhOQuRUpJ27aGVprl3E48wjA0UWgVKRsjIuuUdeSySW6NZLG+xr95RbZ0SNOEszPbvBugg7OqqmI6nRKtVux2JXVdG0WNPxtBMB4xGzlUIuPum8vN8WuW4wvSZI1t2wRBQFmWCCFMQBYH0Aqa/X0Z8nDBxfMnvDt6wPbXjNXnS06OHvH99C1ZkuA4DnEcm6z+RTgU8xDDfhf/5oNyeP70IU30k+jqPc6zx3w9foPIUsbjKzzPY7FYsFIZ6uysww4dUqMqcpbuJ6ajc9WIkHj2hej6kmzmIVQ5fN9nMpkwn8+JomjvkP+g34dpvo+pZS1JlYMsL5D35/qr6a5qJ0MzNf8CiV5c/93+qbMAAAAASUVORK5CYII=')",backgroundSize:"cover",display:"block"}})),"\n  ",Object(r.b)("img",o({parentName:"span"},{className:"gatsby-resp-image-image",alt:"Kafka Connect",title:"Kafka Connect",src:"/refarch-eda/static/f6dcdf7aeb09f297e5f953dfe6b42b30/7a604/mm-k-connect.png",srcSet:["/refarch-eda/static/f6dcdf7aeb09f297e5f953dfe6b42b30/7fc1e/mm-k-connect.png 288w","/refarch-eda/static/f6dcdf7aeb09f297e5f953dfe6b42b30/a5df1/mm-k-connect.png 576w","/refarch-eda/static/f6dcdf7aeb09f297e5f953dfe6b42b30/7a604/mm-k-connect.png 662w"],sizes:"(max-width: 662px) 100vw, 662px",style:{width:"100%",height:"100%",margin:"0",verticalAlign:"middle",position:"absolute",top:"0",left:"0"},loading:"lazy"})),"\n    "),Object(r.b)("p",null,"MirrorMaker 2 uses the cluster name or identifier as prefix for topic, and uses the concept of source topic and target topic. In distributed mode, MirrorMaker 2.0 creates the following topics on the target cluster:"),Object(r.b)("ul",null,Object(r.b)("li",{parentName:"ul"},"mm2-configs.source.internal: This topic is used to store the connector and task configuration."),Object(r.b)("li",{parentName:"ul"},"mm2-offsets.source.internal: This topic is used to store offsets for Kafka Connect."),Object(r.b)("li",{parentName:"ul"},"mm2-status.source.internal: This topic is used to store status updates of connectors and tasks."),Object(r.b)("li",{parentName:"ul"},"source.heartbeats"),Object(r.b)("li",{parentName:"ul"},"source.checkpoints.internal")),Object(r.b)("p",null,"A typical MirrorMaker 2.0 configuration is done via a property file and defines the replication source and target clusters with their connection properties and the replication flow definition. Here is a simple example for a local cluster replicating to a remote IBM Event Streams cluster using TLS v1.2 for connection encryption and SASL authentication protocol.  IBM Event Streams is a support, enterprise version of Apache Kafka by IBM."),Object(r.b)("pre",null,Object(r.b)("code",o({parentName:"pre"},{className:"language-properties"}),'clusters=source, target\nsource.bootstrap.servers=${KAFKA_SOURCE_BROKERS}\ntarget.bootstrap.servers=${KAFKA_TARGET_BROKERS}\ntarget.security.protocol=SASL_SSL\ntarget.ssl.protocol=TLSv1.2\ntarget.ssl.endpoint.identification.algorithm=https\ntarget.sasl.mechanism=PLAIN\ntarget.sasl.jaas.config=org.apache.kafka.common.security.plain.PlainLoginModule required username="token" password=${KAFKA_TARGET_APIKEY};\n# enable and configure individual replication flows\nsource->target.enabled=true\nsource->target.topics=products\ntasks.max=10\n')),Object(r.b)("ul",null,Object(r.b)("li",{parentName:"ul"},"Topics are configured to be replicated or not using a ",Object(r.b)("em",{parentName:"li"},"whitelist")," and ",Object(r.b)("em",{parentName:"li"},"blacklist")," concept"),Object(r.b)("li",{parentName:"ul"},"White listed topics are set with the ",Object(r.b)("inlineCode",{parentName:"li"},"source->target.topics")," attribute of the replication flow and uses ",Object(r.b)("a",o({parentName:"li"},{href:"https://www.vogella.com/tutorials/JavaRegularExpressions/article.html"}),"Java regular expression")," syntax."),Object(r.b)("li",{parentName:"ul"},"Blacklisted topics: by default the following pattern is applied:")),Object(r.b)("pre",null,Object(r.b)("code",o({parentName:"pre"},{className:"language-properties"}),"blacklist = [follower\\.replication\\.throttled\\.replicas, leader\\.replication\\.throttled\\.replicas, message\\.timestamp\\.difference\\.max\\.ms, message\\.timestamp\\.type, unclean\\.leader\\.election\\.enable, min\\.insync\\.replicas]\n")),Object(r.b)("p",null,"We can also define the ",Object(r.b)("em",{parentName:"p"},"blacklist")," with the properties: ",Object(r.b)("inlineCode",{parentName:"p"},"topics.blacklist"),". Comma-separated lists and Java Regular Expressions are supported."),Object(r.b)("p",null,"Internally, ",Object(r.b)("inlineCode",{parentName:"p"},"MirrorSourceConnector")," and ",Object(r.b)("inlineCode",{parentName:"p"},"MirrorCheckpointConnector")," will create multiple Kafka tasks (up to the value of ",Object(r.b)("inlineCode",{parentName:"p"},"tasks.max")," property), and ",Object(r.b)("inlineCode",{parentName:"p"},"MirrorHeartbeatConnector")," creates an additional task. ",Object(r.b)("inlineCode",{parentName:"p"},"MirrorSourceConnector")," will have one task per topic-partition combination to replicate, while ",Object(r.b)("inlineCode",{parentName:"p"},"MirrorCheckpointConnector")," will have one task per consumer group. The Kafka Connect framework uses the coordinator API, with the ",Object(r.b)("inlineCode",{parentName:"p"},"assign()")," API, so there is no consumer group used while fetching data from source topics. There is no call to ",Object(r.b)("inlineCode",{parentName:"p"},"commit()")," either; rebalancing occurs only when there is a new topic created that matches the ",Object(r.b)("em",{parentName:"p"},"whitelist")," pattern."),Object(r.b)("h2",null,"Scenarios"),Object(r.b)("p",null,"The following table summarizes the different scenarios we have tested for data replication using both the Strimzi Operator and IBM Event Streams:"),Object(r.b)("table",null,Object(r.b)("thead",{parentName:"table"},Object(r.b)("tr",{parentName:"thead"},Object(r.b)("th",o({parentName:"tr"},{align:"center"}),"Environment"),Object(r.b)("th",o({parentName:"tr"},{align:null}),"Source"),Object(r.b)("th",o({parentName:"tr"},{align:null}),"Target"),Object(r.b)("th",o({parentName:"tr"},{align:null}),"Connect"))),Object(r.b)("tbody",{parentName:"table"},Object(r.b)("tr",{parentName:"tbody"},Object(r.b)("td",o({parentName:"tr"},{align:"center"}),"1"),Object(r.b)("td",o({parentName:"tr"},{align:null}),"Local"),Object(r.b)("td",o({parentName:"tr"},{align:null}),"Event Streams on Cloud"),Object(r.b)("td",o({parentName:"tr"},{align:null}),"Local")),Object(r.b)("tr",{parentName:"tbody"},Object(r.b)("td",o({parentName:"tr"},{align:"center"}),"2"),Object(r.b)("td",o({parentName:"tr"},{align:null}),"Strimzi on OCP"),Object(r.b)("td",o({parentName:"tr"},{align:null}),"Event Streams on Cloud"),Object(r.b)("td",o({parentName:"tr"},{align:null}),"OCP / ROKS")),Object(r.b)("tr",{parentName:"tbody"},Object(r.b)("td",o({parentName:"tr"},{align:"center"}),"3"),Object(r.b)("td",o({parentName:"tr"},{align:null}),"Event Streams on Cloud"),Object(r.b)("td",o({parentName:"tr"},{align:null}),"Local"),Object(r.b)("td",o({parentName:"tr"},{align:null}),"Local")),Object(r.b)("tr",{parentName:"tbody"},Object(r.b)("td",o({parentName:"tr"},{align:"center"}),"4"),Object(r.b)("td",o({parentName:"tr"},{align:null}),"Event Streams on Cloud"),Object(r.b)("td",o({parentName:"tr"},{align:null}),"Strimzi on OCP"),Object(r.b)("td",o({parentName:"tr"},{align:null}),"OCP / ROKS")),Object(r.b)("tr",{parentName:"tbody"},Object(r.b)("td",o({parentName:"tr"},{align:"center"}),"5"),Object(r.b)("td",o({parentName:"tr"},{align:null}),"Event Streams on OCP"),Object(r.b)("td",o({parentName:"tr"},{align:null}),"Event Streams on Cloud"),Object(r.b)("td",o({parentName:"tr"},{align:null}),"OCP / ROKS")))),Object(r.b)("p",null,"*","The connect column defines where the MirrorMaker 2 connect to."),Object(r.b)("p",null,"To deploy MirrorMaker2 the tool, we can use the Strimzi Kafka latest docker image deployed on Openshift cluster (We address Strimzi deployment in ",Object(r.b)("a",o({parentName:"p"},{href:"../../technology/kafka-mirrormaker/"}),"this note"),")."),Object(r.b)("p",null,"To define the clusters and topic configuration we use yaml files. One simple example to replicate from IBM Cloud Event streams to Kafka on premise is in the folder ",Object(r.b)("a",o({parentName:"p"},{href:"https://github.com/ibm-cloud-architecture/refarch-eda/blob/master/deployments/strimzi/es-mirror-maker.properties"}),"deployments/strimzi/es-mirror-maker.properties")),Object(r.b)("p",null,"Using the same kafka image we can start a mirror maker container with:"),Object(r.b)("pre",null,Object(r.b)("code",o({parentName:"pre"},{className:"language-properties"}),"clusters = source, target\nsource.bootstrap.servers = my-cluster-kafka-bootstrap-jb-kafka-strimzi.gse-eda-demos-fa9ee67c9ab6a7791435450358e564cc-0001.us-east.containers.appdomain.cloud:443\nsource.security.protocol=SSL\nsource.ssl.truststore.password=password\nsource.ssl.truststore.location=/home/truststore.jks\ntarget.bootstrap.servers = kafka1:9092\n# enable and configure individual replication flows\nsource->target.enabled = true\nsource->target.topics = test\n")),Object(r.b)("pre",null,Object(r.b)("code",o({parentName:"pre"},{className:"language-bash"}),"./connect-mirror-maker.sh /home/strimzi.properties\n")),Object(r.b)("p",null,"When Mirror maker starts it will create some topics on source cluster to manage the offsets and topic metadata:"),Object(r.b)("pre",null,Object(r.b)("code",o({parentName:"pre"},{}),"mm2-configs.target.internal                                   1            3\nmm2-offset-syncs.target.internal                              1            3\nmm2-offsets.target.internal                                   25           3\nmm2-status.target.internal                                    5            3\n")),Object(r.b)("p",null,"And on the target cluster:"),Object(r.b)("pre",null,Object(r.b)("code",o({parentName:"pre"},{}),"__consumer_offsets\nheartbeats\nmm2-configs.source.internal\nmm2-offsets.source.internal\nmm2-status.source.internal\nsource.checkpoints.internal\nsource.heartbeats\nsource.test\n")),Object(r.b)("p",null,"The ",Object(r.b)("inlineCode",{parentName:"p"},"source.test")," topic is the replicated ",Object(r.b)("inlineCode",{parentName:"p"},"test")," topic from the source cluster."),Object(r.b)("span",{className:"gatsby-resp-image-wrapper",style:{position:"relative",display:"block",marginLeft:"auto",marginRight:"auto",maxWidth:"662px"}},"\n      ",Object(r.b)("span",o({parentName:"span"},{className:"gatsby-resp-image-background-image",style:{paddingBottom:"39.583333333333336%",position:"relative",bottom:"0",left:"0",backgroundImage:"url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAICAYAAAD5nd/tAAAACXBIWXMAAAsSAAALEgHS3X78AAABjklEQVQoz22SS2/TQBSF/fNBILGqkBA7FgjEgl3VqmZRFxohUiq3inkkMYYEO45rZ+wQP8b2x8ykRllwpDOPOzP33MdYKHRdT9drgpr2s7I3TU25y6nKQq0bZKfOlL2SmLW+o9GrRwOtruuMUY+y7WnazrBV++3mB97HF/juS3VBUOUBvmcjYhdRbAnjhOQuRUpJ27aGVprl3E48wjA0UWgVKRsjIuuUdeSySW6NZLG+xr95RbZ0SNOEszPbvBugg7OqqmI6nRKtVux2JXVdG0WNPxtBMB4xGzlUIuPum8vN8WuW4wvSZI1t2wRBQFmWCCFMQBYH0Aqa/X0Z8nDBxfMnvDt6wPbXjNXnS06OHvH99C1ZkuA4DnEcm6z+RTgU8xDDfhf/5oNyeP70IU30k+jqPc6zx3w9foPIUsbjKzzPY7FYsFIZ6uysww4dUqMqcpbuJ6ajc9WIkHj2hej6kmzmIVQ5fN9nMpkwn8+JomjvkP+g34dpvo+pZS1JlYMsL5D35/qr6a5qJ0MzNf8CiV5c/93+qbMAAAAASUVORK5CYII=')",backgroundSize:"cover",display:"block"}})),"\n  ",Object(r.b)("img",o({parentName:"span"},{className:"gatsby-resp-image-image",alt:"mm k connect",title:"mm k connect",src:"/refarch-eda/static/f6dcdf7aeb09f297e5f953dfe6b42b30/7a604/mm-k-connect.png",srcSet:["/refarch-eda/static/f6dcdf7aeb09f297e5f953dfe6b42b30/7fc1e/mm-k-connect.png 288w","/refarch-eda/static/f6dcdf7aeb09f297e5f953dfe6b42b30/a5df1/mm-k-connect.png 576w","/refarch-eda/static/f6dcdf7aeb09f297e5f953dfe6b42b30/7a604/mm-k-connect.png 662w"],sizes:"(max-width: 662px) 100vw, 662px",style:{width:"100%",height:"100%",margin:"0",verticalAlign:"middle",position:"absolute",top:"0",left:"0"},loading:"lazy"})),"\n    "),Object(r.b)("h2",null,"Where to go next"),Object(r.b)("p",null,"You can read more about how to configure the different scenarios above, how they work, how to apply security in data replication, how to monitor Mirror Maker and much more detailed information on data replication ",Object(r.b)("a",o({parentName:"p"},{href:"https://ibm-cloud-architecture.github.io/refarch-eda-data-consistency/"}),Object(r.b)("strong",{parentName:"a"},"here"))))}l.isMDXComponent=!0}}]);
//# sourceMappingURL=component---src-pages-technology-kafka-mirrormaker-index-mdx-ec2da61839a7829d33e7.js.map