(window.webpackJsonp=window.webpackJsonp||[]).push([[13],{XzoS:function(e,t,a){"use strict";a.r(t),a.d(t,"_frontmatter",(function(){return b})),a.d(t,"default",(function(){return l}));var n=a("wx14"),r=a("zLVn"),i=(a("q1tI"),a("7ljp")),c=a("013z"),b=(a("qKvR"),{}),s={_frontmatter:b},o=c.a;function l(e){var t=e.components,a=Object(r.a)(e,["components"]);return Object(i.b)(o,Object(n.a)({},s,a,{components:t,mdxType:"MDXLayout"}),Object(i.b)("h3",null,"IBM Event Streams"),Object(i.b)("ul",null,Object(i.b)("li",{parentName:"ul"},Object(i.b)("a",Object(n.a)({parentName:"li"},{href:"https://ibm.github.io/event-streams/about/overview/"}),"IBM Event Streams presentation")),Object(i.b)("li",{parentName:"ul"},Object(i.b)("a",Object(n.a)({parentName:"li"},{href:"https://ibm.github.io/event-streams/getting-started/generating-starter-app/"}),"Validating Event Streams deployment with sample app.")),Object(i.b)("li",{parentName:"ul"},Object(i.b)("a",Object(n.a)({parentName:"li"},{href:"https://ibm.github.io/event-streams/installing/installing-openshift/"}),"Install IBM Event Streams on Red Hat OpenShift"))),Object(i.b)("h3",null,"Kafka"),Object(i.b)("ul",null,Object(i.b)("li",{parentName:"ul"},Object(i.b)("a",Object(n.a)({parentName:"li"},{href:"https://kafka.apache.org/intro"}),"Start by reading Kafka introduction - a must read!")),Object(i.b)("li",{parentName:"ul"},Object(i.b)("a",Object(n.a)({parentName:"li"},{href:"http://www.confluent.io/blog/introducing-Kafka-streams-stream-processing-made-simple"}),"Another introduction from Confluent, one of the main contributors of the open source.")),Object(i.b)("li",{parentName:"ul"},Object(i.b)("a",Object(n.a)({parentName:"li"},{href:"../technology/kafka-overview/"}),"Kafka summary and deployment on IBM Cloud Private")),Object(i.b)("li",{parentName:"ul"},Object(i.b)("a",Object(n.a)({parentName:"li"},{href:"https://ibm.github.io/event-streams/installing/planning/"}),"Planning event streams installation")),Object(i.b)("li",{parentName:"ul"},Object(i.b)("a",Object(n.a)({parentName:"li"},{href:"https://Kafka.apache.org/11/documentation/streams/"}),"Develop Stream Application using Kafka")),Object(i.b)("li",{parentName:"ul"},Object(i.b)("a",Object(n.a)({parentName:"li"},{href:"https://developer.ibm.com/tutorials/kafka-authn-authz/"}),"Tutorial on access control, user authentication and authorization from IBM.")),Object(i.b)("li",{parentName:"ul"},Object(i.b)("a",Object(n.a)({parentName:"li"},{href:"https://developer.ibm.com/messaging/event-streams/docs/learn-about-Kafka/"}),"IBM Developer article - learn kafka")),Object(i.b)("li",{parentName:"ul"},Object(i.b)("a",Object(n.a)({parentName:"li"},{href:"https://medium.com/@andrew_schofield/using-kafka-connect-to-connect-to-enterprise-mq-systems-5674d53fe55e"}),"Using Kafka Connect to connect to enterprise MQ systems - Andrew Schofield")),Object(i.b)("li",{parentName:"ul"},Object(i.b)("a",Object(n.a)({parentName:"li"},{href:"https://medium.com/@andrew_schofield/does-apache-kafka-do-acid-transactions-647b207f3d0e"}),"Does Apache Kafka do ACID transactions? - Andrew Schofield")),Object(i.b)("li",{parentName:"ul"},Object(i.b)("a",Object(n.a)({parentName:"li"},{href:"http://aseigneurin.github.io/2016/05/07/spark-kafka-achieving-zero-data-loss.html"}),"Spark and Kafka with direct stream, and persistence considerations and best practices")),Object(i.b)("li",{parentName:"ul"},Object(i.b)("a",Object(n.a)({parentName:"li"},{href:"https://www.madewithtea.com/processing-tweets-with-kafka-streams.html"}),"Example in scala for processing Tweets with Kafka Streams"))),Object(i.b)("h3",null,"Microservices and event-driven patterns"),Object(i.b)("ul",null,Object(i.b)("li",{parentName:"ul"},Object(i.b)("a",Object(n.a)({parentName:"li"},{href:"https://github.com/eclipse/microprofile-reactive-messaging/blob/master/spec/src/main/asciidoc/architecture.asciidoc"}),"API for declaring messaging handlers using Reactive Streams")),Object(i.b)("li",{parentName:"ul"},Object(i.b)("a",Object(n.a)({parentName:"li"},{href:"https://www.manning.com/books/microservices-patterns"}),"Microservice patterns - Chris Richardson")),Object(i.b)("li",{parentName:"ul"},Object(i.b)("a",Object(n.a)({parentName:"li"},{href:"https://github.com/ibm-cloud-architecture/refarch-integration/blob/master/docs/service-mesh/readme.md"}),"Service mesh"))),Object(i.b)("h3",null,"Stream Analytics"),Object(i.b)("ul",null,Object(i.b)("li",{parentName:"ul"},Object(i.b)("a",Object(n.a)({parentName:"li"},{href:"https://ibmstreams.github.io/samples/"}),"IBM Streams Samples")),Object(i.b)("li",{parentName:"ul"},Object(i.b)("a",Object(n.a)({parentName:"li"},{href:"https://cloud.ibm.com/docs/StreamingAnalytics/t_starter_app_deploy.html#starterapps_deploy"}),"Getting started with IBM Streaming Analytics on IBM Cloud"))),Object(i.b)("h3",null,"Integration"),Object(i.b)("ul",null,Object(i.b)("li",{parentName:"ul"},"Interesting article on ",Object(i.b)("a",Object(n.a)({parentName:"li"},{href:"https://developer.ibm.com/articles/mw-1606-clark-trs/"}),"the evolving hybrid integration reference architecture"),": How to ensure your integration landscape keeps pace with digital transformation."),Object(i.b)("li",{parentName:"ul"},Object(i.b)("a",Object(n.a)({parentName:"li"},{href:"https://ibm-cloud-architecture.github.io/refarch-integration"}),"Companion web site for hybrid integration reference architecture"))),Object(i.b)("h3",null,"Conferences, Talks, and Sessions"),Object(i.b)("ul",null,Object(i.b)("li",{parentName:"ul"},Object(i.b)("a",Object(n.a)({parentName:"li"},{href:"https://www.ibm.com/events/think/watch/replay/126541228/"}),"IBM THINK 2020 - From Monolithic Application to API Centric and Event-Driven Microservices â€“ the Cloud Journey of a Leading Health Care Organization")),Object(i.b)("li",{parentName:"ul"},Object(i.b)("a",Object(n.a)({parentName:"li"},{href:"https://www.ibm.com/events/think/watch/replay/126498392/"}),"IBM THINK 2020 - Change the Way You Integrate Applications with IBM Cloud Pak for Integration")),Object(i.b)("li",{parentName:"ul"},Object(i.b)("a",Object(n.a)({parentName:"li"},{href:"https://www.ibm.com/events/think/watch/replay/126543731/"}),"IBM THINK 2020 - Modernize Integration to Unlock Data and Applications Securely While Lowering Costs")),Object(i.b)("li",{parentName:"ul"},Object(i.b)("a",Object(n.a)({parentName:"li"},{href:"https://www.confluent.io/resources/kafka-summit-san-francisco-2016/"}),"Kafka Summit 2016 - San Francisco")),Object(i.b)("li",{parentName:"ul"},Object(i.b)("a",Object(n.a)({parentName:"li"},{href:"https://www.confluent.io/resources/kafka-summit-new-york-2017/"}),"Kafka Summit 2017 - New York")),Object(i.b)("li",{parentName:"ul"},Object(i.b)("a",Object(n.a)({parentName:"li"},{href:"https://www.confluent.io/resources/kafka-summit-san-francisco-2017/"}),"Kafka Summit 2017 - San Francisco")),Object(i.b)("li",{parentName:"ul"},Object(i.b)("a",Object(n.a)({parentName:"li"},{href:"https://www.confluent.io/resources/kafka-summit-san-francisco-2018/"}),"Kafka Summit 2018 - San Francisco")),Object(i.b)("li",{parentName:"ul"},Object(i.b)("a",Object(n.a)({parentName:"li"},{href:"https://www.confluent.io/resources/kafka-summit-san-francisco-2019/"}),"Kafka Summit 2019 - San Francisco")),Object(i.b)("li",{parentName:"ul"},Object(i.b)("a",Object(n.a)({parentName:"li"},{href:"https://www.confluent.io/resources/kafka-summit-london-2019/"}),"Kafka Summit 2019 - London"))))}l.isMDXComponent=!0}}]);
//# sourceMappingURL=component---src-pages-additional-reading-index-mdx-5cbe8a2ee01abcf3ae27.js.map