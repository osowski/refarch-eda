(window.webpackJsonp=window.webpackJsonp||[]).push([[56],{"4zw4":function(e,n,t){"use strict";t.r(n),t.d(n,"_frontmatter",(function(){return r})),t.d(n,"default",(function(){return u}));var a=t("wx14"),o=t("zLVn"),c=(t("q1tI"),t("7ljp")),s=t("013z"),r=(t("qKvR"),{}),i=function(e){return function(n){return console.warn("Component '"+e+"' was not imported, exported, or provided by MDXProvider as global scope"),Object(c.b)("div",n)}},l=i("InlineNotification"),b=i("AnchorLinks"),m=i("AnchorLink"),p={_frontmatter:r},d=s.a;function u(e){var n=e.components,t=Object(o.a)(e,["components"]);return Object(c.b)(d,Object(a.a)({},p,t,{components:n,mdxType:"MDXLayout"}),Object(c.b)(l,{kind:"warning",mdxType:"InlineNotification"},Object(c.b)("strong",null,"Work in progress")," - MQ Sink Connector on virtual or baremetal server, MQ and Event Streams on IBM Cloud not completed..."),Object(c.b)("p",null,"This scenario uses the ",Object(c.b)("a",Object(a.a)({parentName:"p"},{href:"https://github.com/ibm-messaging/kafka-connect-mq-sink"}),"IBM Kafka Connect sink connector for IBM MQ")," to pull streaming data into a MQ queue. We can have multiple deployment combinations but we will limit to two patterns:"),Object(c.b)(b,{mdxType:"AnchorLinks"},Object(c.b)(m,{mdxType:"AnchorLink"},"MQ Sink Connector, MQ, Kafka on OpenShift"),Object(c.b)(m,{mdxType:"AnchorLink"},"MQ Sink Connector on virtual or baremetal server, MQ and Event Streams on IBM Cloud")),Object(c.b)("h2",null,"Pre-requisites"),Object(c.b)("p",null,Object(c.b)("strong",{parentName:"p"},"Get a Git client")),Object(c.b)("p",null,Object(c.b)("strong",{parentName:"p"},"Clone the MQ Sink connector")," using the command:"),Object(c.b)("pre",null,Object(c.b)("code",Object(a.a)({parentName:"pre"},{className:"language-shell"}),"git clone https://github.com/ibm-messaging/kafka-connect-mq-sink.git\n")),Object(c.b)("p",null,Object(c.b)("strong",{parentName:"p"},"Clone the Lab repository")," to get configuration files. This lab is under ",Object(c.b)("a",Object(a.a)({parentName:"p"},{href:"https://github.com/ibm-cloud-architecture/refarch-eda-tools/tree/master/labs/mq-sink-lab/"}),"labs/mq-sink-lab/")," folder."),Object(c.b)("pre",null,Object(c.b)("code",Object(a.a)({parentName:"pre"},{className:"language-shell"}),"git clone https://github.com/ibm-cloud-architecture/refarch-eda-tools.git\n")),Object(c.b)("h2",null,"MQ Sink Connector, MQ, Kafka on OpenShift"),Object(c.b)("p",null,"The target deployment looks like in the following diagram:"),Object(c.b)("p",null," ",Object(c.b)("span",Object(a.a)({parentName:"p"},{className:"gatsby-resp-image-wrapper",style:{position:"relative",display:"block",marginLeft:"auto",marginRight:"auto",maxWidth:"1152px"}}),"\n      ",Object(c.b)("span",Object(a.a)({parentName:"span"},{className:"gatsby-resp-image-background-image",style:{paddingBottom:"57.98611111111111%",position:"relative",bottom:"0",left:"0",backgroundImage:"url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAMCAYAAABiDJ37AAAACXBIWXMAABYlAAAWJQFJUiTwAAACSUlEQVQoz2WTS2sUQRSF51+5ERHcutE/4CKoiARdCPoHBBVCFBcquBF8bAxxIa40btxESJA4GZMJMTrjzPS8p7r6Xd31eatnJky04HCrblcdzj33doUopEToYgTxAubn+Z0TWPweYd3eWipZmGLSnDw1Eg1pnJfIHJIZ4n+QGPJsijR27woIAmxRUOmODDtN2KrD9iH8Glp0YJFvFJbjmBelAFRcsNOAzT34ug+1lpUcUqGozHMqvUFEvRWy3wjZawY0+qFULy//W/OcwRuHtAZT9FRAKFXYQGxwhGqsydJQShbJRsgCXxQWBFGBP4tJaomT6fnDl5C1j4r1zz7rGw4Kb1CUvpYK257P71FOtZWy1cioNbXYkdOT3GY1YetHwkjlpbbuMOf8TY/TSx3OXfM4c7nD2SsdtvcyyCIKI4RHLc2nuuH995gXmwkbNS0qc6LE+WjJzBRuDYX44q0upy61uSDRkZ1eavOtvkCoxsEJp5I4ZqKmhMfu2em+0zfceTzi2ZrP83c+T976PF1T1I4MpDPCwI9RasLublWaocWrjPHESLTHzZgTdsWGGytDVl8pVl8rVl5OePRmQvXQTBU6DycjTa8/Yr/eoNtTQqZRfo4Oi7IRkTQkkoq0dL7VMdx+OOTq3T7LDwZcvzdg+X6fg8ZMoSNMpeXSedoe/OnIOMVCkEjpQiLzSxLmJDJonlfQ+JnRbablbC6uzM2ozGE5NtbXs99OWGNpvZt4rXF5K3nb7mDrBzAZO/byXqFn8B10eR/fL635C9OrhK1wZZupAAAAAElFTkSuQmCC')",backgroundSize:"cover",display:"block"}})),"\n  ",Object(c.b)("img",Object(a.a)({parentName:"span"},{className:"gatsby-resp-image-image",alt:"1",title:"1",src:"/refarch-eda/static/7f08c155d65695d6d8a840745ae86087/3cbba/all-ocp.png",srcSet:["/refarch-eda/static/7f08c155d65695d6d8a840745ae86087/7fc1e/all-ocp.png 288w","/refarch-eda/static/7f08c155d65695d6d8a840745ae86087/a5df1/all-ocp.png 576w","/refarch-eda/static/7f08c155d65695d6d8a840745ae86087/3cbba/all-ocp.png 1152w","/refarch-eda/static/7f08c155d65695d6d8a840745ae86087/12736/all-ocp.png 1206w"],sizes:"(max-width: 1152px) 100vw, 1152px",style:{width:"100%",height:"100%",margin:"0",verticalAlign:"middle",position:"absolute",top:"0",left:"0"},loading:"lazy"})),"\n    ")),Object(c.b)("p",null,"Kafka is runnning in its own namespace, and we are using Event Streams from Cloud Pack for Integration."),Object(c.b)("h3",null,"Pre-requisites"),Object(c.b)("p",null,"We assume that you have an instance of Event Streams already running on OpenShift, with a TLS authentication user type. See ",Object(c.b)("a",Object(a.a)({parentName:"p"},{href:"../../use-cases/overview/pre-requisites#getting-scram-authentication-from-event-streams-on-openshift"}),"those instructions")," to get them."),Object(c.b)("p",null,"The MQ broker is running on OpenShift and was created using kubernetes operators: we have documented a simple how to guide in ",Object(c.b)("a",Object(a.a)({parentName:"p"},{href:"../../technology/mq#installation-with-cloud-pak-for-integration"}),"this MQ summary"),". The instance is exposed via a Route so we can access the administration console using the admin credentials of Cloud Pak for Integration."),Object(c.b)("h3",null,"Setup MQ Channel"),Object(c.b)("p",null,"Open a shell on the remote container or use the user interface to define the communication channel to use for the Kafka Connection."),Object(c.b)("ul",null,Object(c.b)("li",{parentName:"ul"},"Using CLI: Change the name of the Q manager to reflect what you defined in MQ configuration.")),Object(c.b)("pre",null,Object(c.b)("code",Object(a.a)({parentName:"pre"},{className:"language-shell"}),"runmqsc EDAQMGR1\n# Define a app channel using server connection\nDEFINE CHANNEL(KAFKA.CHANNEL) CHLTYPE(SVRCONN)\n# Set the channel authentication rules to accept connections requiring userid and password\nSET CHLAUTH(KAFKA.CHANNEL) TYPE(BLOCKUSER) USERLIST('nobody')\nSET CHLAUTH('*') TYPE(ADDRESSMAP) ADDRESS('*') USERSRC(NOACCESS)\nSET CHLAUTH(KAFKA.CHANNEL) TYPE(ADDRESSMAP) ADDRESS('*') USERSRC(CHANNEL) CHCKCLNT(REQUIRED)\n# Set identity of the client connections\nALTER AUTHINFO(SYSTEM.DEFAULT.AUTHINFO.IDPWOS) AUTHTYPE(IDPWOS) ADOPTCTX(YES)\n\nREFRESH SECURITY TYPE(CONNAUTH)\n# Define inventory queue\nDEFINE QLOCAL(INVENTORY)\n# Authorize the IBM MQ user ID to connect to and inquire the queue manager\nSET AUTHREC OBJTYPE(QMGR) PRINCIPAL('admin') AUTHADD(CONNECT,INQ)\n# Authorize the IBM MQ user ID to use the queue:\nSET AUTHREC PROFILE(INVENTORY) OBJTYPE(QUEUE) PRINCIPAL('admin') AUTHADD(ALLMQI)\n# done\nEND\n")),Object(c.b)("ul",null,Object(c.b)("li",{parentName:"ul"},"As an alternate you can use the MQ administration console.")),Object(c.b)("p",null,"TBD"),Object(c.b)("h3",null,"Setup Kafka Connect Cluster"),Object(c.b)("p",null,"Connectors can be added to a Kafka Connect environment using OpenShift CLI commands and the source to image customer resource. We will use the Event Streams admin console to setup kafka connect environment which is based on OpenShift operator. The ",Object(c.b)("a",Object(a.a)({parentName:"p"},{href:"https://ibm.github.io/event-streams/connecting/connectors/"}),"Event Streams product documentation")," presents the deployment process within the admin console, the ",Object(c.b)("inlineCode",{parentName:"p"},"Setup a kafka connect environment")," tile guides developer thru those steps:"),Object(c.b)("p",null," ",Object(c.b)("span",Object(a.a)({parentName:"p"},{className:"gatsby-resp-image-wrapper",style:{position:"relative",display:"block",marginLeft:"auto",marginRight:"auto",maxWidth:"692px"}}),"\n      ",Object(c.b)("span",Object(a.a)({parentName:"span"},{className:"gatsby-resp-image-background-image",style:{paddingBottom:"87.15277777777777%",position:"relative",bottom:"0",left:"0",backgroundImage:"url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAARCAYAAADdRIy+AAAACXBIWXMAAAsSAAALEgHS3X78AAACM0lEQVQ4y5VUy27TQBS1xI5FlEgRKPE2+RlWLFmwBMQnsGHNlyCxS+w2UfsDEaWbdlNalZYktmOTB87DdmKPZw5zx3FIkJqGKx3deXjO3Ln3XGuVSgWmaWK1itHtduE4DmazGYIg2Iv5PMCvSQBvnPnR7wD+LICm61UYkjBlMex+RjidTtWhxWLxIAKJKPyLUCIIFtCqVR2tYxMLBri+ABnnQoL/JwTiJJGEuo6jIwOpJBrOcZAJIXZ8bowxirCqckg2GQ/h+77Mz1xtJvLG3OfYd4EiLJfLijCRk16vD89zVXE8z8NgMIDruiqv+TiKIkUcx7Es5Eo+kyHlUKCxVqvV0G631S29Xk8dtG17g36/v6k+zWnfsqwNIJbbj4ZWr9fRarXWxeAH5W7bzu+AkwuB00vg2paEhUIBjUZDbaYpU6R0cB84gRM5x4tPHM/ecDx5xfHxSwytVCqh2WwqwjBa7hTgMTCW4NZJcPkzwcV9Amu4glYsFnFsNjGNAWuSywGPRpl/t5sTlhEaRhO058+XYEm8fs5hWqRvU9UI6ypnhKZcSOHYlqrmaDRS/UygNiRdUivSnHRKkuFKKmILO4SGuolkQzLJ5UKyIE/ruWxoPh56MrQgj3WNtWyIMC/KoSZ/LOjcCHz7IXB2m/nODXDvJbuEaZruLQRLs2iMc4GnrwX09wKVdwLP3wpoLwU+fP6HkH5L1FoPIQwjrJYR3HGEzlWIr9cS30OcSd+5inDnhPgDN/vfR/nbQg8AAAAASUVORK5CYII=')",backgroundSize:"cover",display:"block"}})),"\n  ",Object(c.b)("img",Object(a.a)({parentName:"span"},{className:"gatsby-resp-image-image",alt:"4",title:"4",src:"/refarch-eda/static/1bb44d11f13930a64b18447c097d8d97/b53e5/es-kconnect.png",srcSet:["/refarch-eda/static/1bb44d11f13930a64b18447c097d8d97/7fc1e/es-kconnect.png 288w","/refarch-eda/static/1bb44d11f13930a64b18447c097d8d97/a5df1/es-kconnect.png 576w","/refarch-eda/static/1bb44d11f13930a64b18447c097d8d97/b53e5/es-kconnect.png 692w"],sizes:"(max-width: 692px) 100vw, 692px",style:{width:"100%",height:"100%",margin:"0",verticalAlign:"middle",position:"absolute",top:"0",left:"0"},loading:"lazy"})),"\n    ")),Object(c.b)("p",null," ",Object(c.b)("span",Object(a.a)({parentName:"p"},{className:"gatsby-resp-image-wrapper",style:{position:"relative",display:"block",marginLeft:"auto",marginRight:"auto",maxWidth:"803px"}}),"\n      ",Object(c.b)("span",Object(a.a)({parentName:"span"},{className:"gatsby-resp-image-background-image",style:{paddingBottom:"95.4861111111111%",position:"relative",bottom:"0",left:"0",backgroundImage:"url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAATCAYAAACQjC21AAAACXBIWXMAAAsSAAALEgHS3X78AAABmUlEQVQ4y4WUCavCMBCE+///oCCC9333sLVW9/kFpqw19RWGJNvNZPZIkrJqLCtqS69Xy7LMns+n8b1er3bsmzdN84UkzzMrivyNwm63m63Xa5vNZrZarWw0GoU5mEwmNp/PbTqd2ng8tsViEQR0kWRZ3i7yPLf9fm/L5dI2m007Hg4H2+12YQT4HI/H4N9FookIt9ttUIICVELg/3ukafqBoFDOgLAhGQ6HIURIUckBgNB1mGwCqWoV+pAJDRKIpRKwQXYP7D6SXkIcpVDO/yEaMjmkkgqL0AkVG1DVvQ2f0+kU9n8pRD4OIsKRhF/ffdqF9qkg0ZBpCcKlXRhZq1XUNqQl1jZtyN7weDzMf6z78tXFRx/KqaqqQHK/3wPquv7qQ81/EnonQjqfzyE3vxRFr16XDCLyI8KyLNt7HgP/hGhRaJXBYBBuC9AtoI3Ulx50BQUDH0URIe2gKlJRP/qDNUcleb5cLiGiaA4hUG91q9738Y5Gq0zONFJlRgE12Pxj6x/c9qZ4Qjbw8qJMrzBzgTVqusAO4R8FxKsgPeZlrgAAAABJRU5ErkJggg==')",backgroundSize:"cover",display:"block"}})),"\n  ",Object(c.b)("img",Object(a.a)({parentName:"span"},{className:"gatsby-resp-image-image",alt:"5",title:"5",src:"/refarch-eda/static/ba93aa66417a294f6df7f194ec7bf9ce/644bd/es-kconn-setup.png",srcSet:["/refarch-eda/static/ba93aa66417a294f6df7f194ec7bf9ce/7fc1e/es-kconn-setup.png 288w","/refarch-eda/static/ba93aa66417a294f6df7f194ec7bf9ce/a5df1/es-kconn-setup.png 576w","/refarch-eda/static/ba93aa66417a294f6df7f194ec7bf9ce/644bd/es-kconn-setup.png 803w"],sizes:"(max-width: 803px) 100vw, 803px",style:{width:"100%",height:"100%",margin:"0",verticalAlign:"middle",position:"absolute",top:"0",left:"0"},loading:"lazy"})),"\n    ")),Object(c.b)("p",null,"Once you downloaded the zip file, which is a yaml manifest, define the configuration for a KafkaConnectS2I instance. The major configuration settings are the server certificate settings and the authentication using Mutual TLS authentication, something like:"),Object(c.b)("pre",null,Object(c.b)("code",Object(a.a)({parentName:"pre"},{className:"language-yaml"}),"spec:\n  bootstrapServers: sandbox-rp-kafka-bootstrap.eventstreams.svc:9093\n  tls:\n    trustedCertificates:\n    - secretName: sandbox-rp-cluster-ca-cert\n      certificate: ca.crt\n  authentication:\n    type: tls\n    certificate: user.crt\n    key: user.key\n    secretName: sandbox-rp-tls-cred\n")),Object(c.b)("p",null,"If you change the name of the connect cluster in the metadata, modify also the name: ",Object(c.b)("inlineCode",{parentName:"p"},"spec.template.pod.metadata.annotations. productChargedContainers")," accordingly."),Object(c.b)("p",null,"The secrets used above, need to be accessible from the project where the connector is deployed. The simple way to do so is to copy the source certificates from the Event streams project to your current project with the commands like:"),Object(c.b)("pre",null,Object(c.b)("code",Object(a.a)({parentName:"pre"},{className:"language-shell"}),"oc get secret  sandbox-rp-cluster-ca-cert  -n eventstreams --export -o yaml | oc apply -f -\noc get secret  sandbox-rp-tls-cred  -n eventstreams --export -o yaml | oc apply -f -\n")),Object(c.b)("p",null,"If you do not have a TLS client certificate from a TLS user, use ",Object(c.b)("a",Object(a.a)({parentName:"p"},{href:"../../overview/pre-requisites#getting-tls-authentication-from-event-streams-on-openshift"}),"this note")," to create one."),Object(c.b)("ul",null,Object(c.b)("li",{parentName:"ul"},"Deploy the connector cluster")),Object(c.b)("pre",null,Object(c.b)("code",Object(a.a)({parentName:"pre"},{className:"language-shell"}),"oc apply -f kafka-connect-s2i.yaml \n")),Object(c.b)("p",null,"An instance of this custom resource represents a Kafka Connect distributed worker cluster. In this mode, workload balancing is automatic, scaling is dynamic, and tasks and data are fault-tolerant. Each connector is represented by another custom resource called KafkaConnector."),Object(c.b)("pre",null,Object(c.b)("code",Object(a.a)({parentName:"pre"},{className:"language-shell"}),"oc describe kafkaconnects2i eda-connect-cluster\n")),Object(c.b)("h3",null,"Add the mq-sink connector"),Object(c.b)("p",null,"The ",Object(c.b)("a",Object(a.a)({parentName:"p"},{href:"https://ibm.github.io/event-streams/connecting/mq/"}),"product documentation")," details the available MQ connectors and the configuration process. Using the event streams console, the process is quite simple to get a connector configuration as json file. Here is an example of the final form to generate the json file:"),Object(c.b)("p",null," ",Object(c.b)("span",Object(a.a)({parentName:"p"},{className:"gatsby-resp-image-wrapper",style:{position:"relative",display:"block",marginLeft:"auto",marginRight:"auto",maxWidth:"681px"}}),"\n      ",Object(c.b)("span",Object(a.a)({parentName:"span"},{className:"gatsby-resp-image-background-image",style:{paddingBottom:"90.625%",position:"relative",bottom:"0",left:"0",backgroundImage:"url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAASCAYAAABb0P4QAAAACXBIWXMAAAsSAAALEgHS3X78AAABjElEQVQ4y52Ua26CQBSF2f86TPzhCoyPqDyqy7AmGGEEYRgQUE4510DTJrXijxMd5vLNuY/BGo1GWK1WmM1mmM/nP36n02m/fibGLBYLkGWt12ucz2fs93v4vi86HA44nU5I0xR5nqOua1RV9afKskTTNGLM2mw2yLJMAJfLBVprxHHc/6cIfqYkSeTg5XL5AN7vdxhjUBSFbBDCQxjcQZ+JcXxXgJ7nycMoisQ6N67X62AxdQE67kfrykApJWA6HSpmQ2gPZEGZKh/S5TvqHXqeK7AgCKS4PG2omFlfQ9u2pSnc6FwOEUEUXQrQdb8dEtp1ugv8T4yleuB4PJYFB7pz+Y564GQykQVvS3cz3tF3lx1HgIRxBLp0h8CYGbvM8klTSD8ej1BhKFeO8CEjw/c5ervdDhYvtM4MwlAhSXU7OqlI6+xlMb6q6gfQdlyopManH8EPUsS6RkSl1ctSSYmsaLDdbmGxkMbk0hQjNSkGi7W/3W4PIL82bIJSYVuL9sPw4vz9nkVeDgK/AAJNTn6C6CPKAAAAAElFTkSuQmCC')",backgroundSize:"cover",display:"block"}})),"\n  ",Object(c.b)("img",Object(a.a)({parentName:"span"},{className:"gatsby-resp-image-image",alt:"6",title:"6",src:"/refarch-eda/static/a6a42bc9cb9e2ebc9badcde679b0bfa4/165d5/es-mq-sink.png",srcSet:["/refarch-eda/static/a6a42bc9cb9e2ebc9badcde679b0bfa4/7fc1e/es-mq-sink.png 288w","/refarch-eda/static/a6a42bc9cb9e2ebc9badcde679b0bfa4/a5df1/es-mq-sink.png 576w","/refarch-eda/static/a6a42bc9cb9e2ebc9badcde679b0bfa4/165d5/es-mq-sink.png 681w"],sizes:"(max-width: 681px) 100vw, 681px",style:{width:"100%",height:"100%",margin:"0",verticalAlign:"middle",position:"absolute",top:"0",left:"0"},loading:"lazy"})),"\n    ")),Object(c.b)("ul",null,Object(c.b)("li",{parentName:"ul"},"Once the json is downloaded, complete the settings")),Object(c.b)("pre",null,Object(c.b)("code",Object(a.a)({parentName:"pre"},{className:"language-json"}),'{\n  "name": "mq-sink",\n  "config":\n  {\n      "connector.class": "com.ibm.eventstreams.connect.mqsink.MQSinkConnector",\n      "tasks.max": "1",\n      "topics": "inventory",\n      "key.converter": "org.apache.kafka.connect.storage.StringConverter",\n      "value.converter": "org.apache.kafka.connect.storage.StringConverter",\n      "mq.queue.manager": "EDAQMGR1",\n      "mq.connection.name.list": "eda-mq-lab-ibm-mq(1414)",\n      "mq.user.name": "admin",\n      "mq.password": "passw0rd",\n      "mq.user.authentication.mqcsp": true,\n      "mq.channel.name": "KAFKA.CHANNEL",\n      "mq.queue": "INVENTORY",\n      "mq.message.builder": "com.ibm.eventstreams.connect.mqsink.builders.DefaultMessageBuilder"\n  }\n}\n')),Object(c.b)("ul",null,Object(c.b)("li",{parentName:"ul"},Object(c.b)("p",{parentName:"li"},"To run the connector within the cluster, we need to connector jar. You can download this jar file from the Event Stream adming console ",Object(c.b)("inlineCode",{parentName:"p"},"> Toolkit > Add connector to your Kafka Connect environment > Add Connector > IBM MQ Connectors"),","),Object(c.b)("span",Object(a.a)({parentName:"li"},{className:"gatsby-resp-image-wrapper",style:{position:"relative",display:"block",marginLeft:"auto",marginRight:"auto",maxWidth:"569px"}}),"\n      ",Object(c.b)("span",Object(a.a)({parentName:"span"},{className:"gatsby-resp-image-background-image",style:{paddingBottom:"128.4722222222222%",position:"relative",bottom:"0",left:"0",backgroundImage:"url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAaCAYAAAC3g3x9AAAACXBIWXMAAAsSAAALEgHS3X78AAADhklEQVRIx4VVu47kRBTtmISYDyBFItmYBCQSJEAiY8kIyUCkSHwDEgmQkoG0K1aIfQytRYJdEpjp7p3p6W67H3Z3+/0o2/3woU7Z5bGZHY2lM7dcU3XqnL63rntpmsJxHFxcXCiYponlcgnDMBS22y2yLAPX3YY4jtFrE47HY5yfn2MymTTj+XyuSDebjYpcq2MbrusiSRL0+CcMQ1iWhdVqpcCxbVsyrpTaxWLRgBs9z4Pveypq+L5fEVImB/+XH0aJwnVribSWIAgTNdZ7GZVlPdCIohipnLM3AS6nK2WVcxpc77gRpoaF9Xqt5vTeWiFPqcniioz/8INYKTge9gAOHUSxkEQh4iiqFXcI45owUafZ21DaieH50orIkYgSL8wDJqsDRsYetneEyAp5YKLWWXI993YI40ZhgsnCxcaJ4AUZ4rSAud7jx0cFfuoX+OfyAC86Ikl3cHyBtVw3njvKmXbaUlhNMlvaQpFn4BPGmTwgkcqEfCuR5zn0vqv1NWE7KbQchlEnASxqIdI6o6kcZ00RUxnXx9cVytOFaKDLQB/Gdz3fTkAXFalSSNm8cgRvhi0L22X1S7CAWeCz2UwVfPugLlqWKZ3V7rqesjaemHjc/wtP+n/i10dPcXFpSGsBgiDokF1XWWeZdnKZACEt8bn34ATvfXgXH3x0F2+98z5+vv+wSk4U3UjUEPKHprW5OcVibmC5oHUD05mBmWGq2FZ2q8J9HuPZiwRvf5Xj3a9z3PmywLcPEpRFIIu7ttnafKvCTMSYWQm++03gh4cC3/wi0P83QZ7KGxOEsnwi1Y1I3FZ4I6GQSVhaDk6em3jyfIH+3yasxRSGzDgbLLPL/sgxE/cyy+1x71DE+GMg8OYXJV7/rMQbnx+x9VLkmazFumW9rL21a7LTHPjH9QKYK5kYy8PS9rCRHZmNlJ2ZoDLdqfU8442fgO12g9FwgNFIY4TBYIDT01OcnZ1hOByqd44ZCX4ybNtWYMGzbzYKyczbwsKuWrqvFHBOq+O7/n5wbrfbqSahwcQxgc1d5gszqUEyzrHoq8YRdWJRFJKokM1DIt/J/hipRtHTZGzn1cfpygbVkJw/CxWRRCOTqg77XN4fiZKxUIlsrp623VbJg2iVLaz9lGUVLR/4fQg8HQEnA2DlZFeEtz2lZNHYH0rVaL9/XOLVT4547dMjXvm4xP1nAv8BukmlvH/Oy1wAAAAASUVORK5CYII=')",backgroundSize:"cover",display:"block"}})),"\n  ",Object(c.b)("img",Object(a.a)({parentName:"span"},{className:"gatsby-resp-image-image",alt:"es mq sink 1",title:"es mq sink 1",src:"/refarch-eda/static/666a96f7a21958a1b5f1f12c25ba5cf9/bded5/es-mq-sink-1.png",srcSet:["/refarch-eda/static/666a96f7a21958a1b5f1f12c25ba5cf9/7fc1e/es-mq-sink-1.png 288w","/refarch-eda/static/666a96f7a21958a1b5f1f12c25ba5cf9/bded5/es-mq-sink-1.png 569w"],sizes:"(max-width: 569px) 100vw, 569px",style:{width:"100%",height:"100%",margin:"0",verticalAlign:"middle",position:"absolute",top:"0",left:"0"},loading:"lazy"})),"\n    "))),Object(c.b)("p",null,"or as an alternate, we ",Object(c.b)("a",Object(a.a)({parentName:"p"},{href:"https://github.com/ibm-messaging/kafka-connect-mq-sink.git"}),"cloned the mq-sink code"),", so a ",Object(c.b)("inlineCode",{parentName:"p"},"mvn package")," command under ",Object(c.b)("inlineCode",{parentName:"p"},"kafka-connect-mq-sink")," folder will build the jar. Copy this jar under ",Object(c.b)("inlineCode",{parentName:"p"},"cp4i/my-plugins")," folder. "),Object(c.b)("ul",null,Object(c.b)("li",{parentName:"ul"},"Build the connector with source to image component.")),Object(c.b)("pre",null,Object(c.b)("code",Object(a.a)({parentName:"pre"},{}),"")),Object(c.b)("p",null,"With the correct credentials for IBM EventStreams and IBM MQ, Kafka Connect should connect to both services and pull data from the EventStreams topic configured to the MQ Queue configured.  You will see signs of success in the container output (via oc logs, or in the UI):"),Object(c.b)("pre",null,Object(c.b)("code",Object(a.a)({parentName:"pre"},{className:"language-shell"}),'+ curl -X POST -H Content-Type: application/json http://localhost:8083/connectors --data @/opt/kafka-connect-mq-sink/config/mq-sink.json\n...\n{"name":"mq-sink-connector","config":{"connector.class":"com.ibm.eventstreams.connect.mqsink.MQSinkConnector","tasks.max":"1","topics":"inventory","key.converter":"org.apache.kafka.connect.storage.StringConverter","value.converter":"org.apache.kafka.connect.storage.StringConverter","mq.queue.manager":"QM1","mq.connection.name.list":"mq-service(1414)","mq.user.name":"admin","mq.password":"passw0rd","mq.user.authentication.mqcsp":"true","mq.channel.name":"KAFKA.CHANNEL","mq.queue":"INVENTORY","mq.message.builder":"com.ibm.eventstreams.connect.mqsink.builders.DefaultMessageBuilder","name":"mq-sink-connector"},"tasks":[{"connector":"mq-sink-connector","task":0}],"type":"sink"}\n...\n[2020-06-23 04:26:26,054] INFO Creating task mq-sink-connector-0 (org.apache.kafka.connect.runtime.Worker:419)\n...[2020-06-23 04:26:26,449] INFO Connection to MQ established (com.ibm.eventstreams.connect.mqsink.JMSWriter:229)\n[2020-06-23 04:26:26,449] INFO WorkerSinkTask{id=mq-sink-connector-0} Sink task finished initialization and start (org.apache.kafka.connect.runtime.WorkerSinkTask:306)\n')),Object(c.b)("p",null,"You should now have the Kafka Connector MQ Sink running on OpenShift."),Object(c.b)("h2",null,"MQ Sink Connector on virtual or baremetal server, MQ and Event Streams on IBM Cloud"),Object(c.b)("p",null,"We are using our own laptop for the baremetal dedployment, but the current solution will work the same on virtual server."),Object(c.b)("p",null," ",Object(c.b)("span",Object(a.a)({parentName:"p"},{className:"gatsby-resp-image-wrapper",style:{position:"relative",display:"block",marginLeft:"auto",marginRight:"auto",maxWidth:"1152px"}}),"\n      ",Object(c.b)("span",Object(a.a)({parentName:"span"},{className:"gatsby-resp-image-background-image",style:{paddingBottom:"60.06944444444444%",position:"relative",bottom:"0",left:"0",backgroundImage:"url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAMCAYAAABiDJ37AAAACXBIWXMAABYlAAAWJQFJUiTwAAACIElEQVQoz2VSy24TQRDcf+LELyA+gQNC4gxHuCL4AnLlwAWJExJSDiQHFIGEhZEBEYSTYGInsWPY9Xq9j3nPFjX7ACNWKnVPd09tdU9H4FfXdTDwNNZ6KO1gTIBt4JkIJSHflrbn/t72F/XBvFAQpYAWFbyWKHIJ50LOE4Zwnf8vWbDbxFHvz+MKg4nAwbHC7qHEeF4gyx2+n1vC4ORM42iqGNMt6VZnqGv0buS9h3UWk2WF0ZnFpwWwP+Y5lnj5psLVmwtcu7PE9btLXLmxwNuPVaO2Vf9/25ExGo7BlH/2mqqSRdeaxouDCrcexLi/k+Le4xS3H8YYHekmX0kDY91W238ITeP8WmtMZwlGn79hdrFCXqqG8NGTNZ69KvF0t8DO8w2+/GjrpQUyYWD99iOR0JoQdEgLIEmACwqcE1kOnF46vB4K7L2X2B9K7A0EVpnr5kaViio7whYkDI7mauSCK6ItqspAK4uSZ6H7l/WcWms9562Yt6yVhndt4K4507b1KLCG+QomlSJCEVHRL2QNIaiESIvWSsaUZpyjzBUh2T59Y1rSRqEnM4Vhnnp8OKkxPK4xSzwKXlxtPA4nGqOxou8gpMem4jZMDd59tRhwI05j07TcEf4dalYYXCYFFsS6kE0sKE5Jes55/gw/KUMHDklWEQIx7aaUTbsNoTX9PnWybQtLhAWwnBE3C9kaWBObvI25ABLwPRs/1Ibd/A23xJfhP80yrAAAAABJRU5ErkJggg==')",backgroundSize:"cover",display:"block"}})),"\n  ",Object(c.b)("img",Object(a.a)({parentName:"span"},{className:"gatsby-resp-image-image",alt:"2",title:"2",src:"/refarch-eda/static/9aeea9730df667cad9efd461136a4d76/3cbba/hybrid.png",srcSet:["/refarch-eda/static/9aeea9730df667cad9efd461136a4d76/7fc1e/hybrid.png 288w","/refarch-eda/static/9aeea9730df667cad9efd461136a4d76/a5df1/hybrid.png 576w","/refarch-eda/static/9aeea9730df667cad9efd461136a4d76/3cbba/hybrid.png 1152w","/refarch-eda/static/9aeea9730df667cad9efd461136a4d76/41dda/hybrid.png 1222w"],sizes:"(max-width: 1152px) 100vw, 1152px",style:{width:"100%",height:"100%",margin:"0",verticalAlign:"middle",position:"absolute",top:"0",left:"0"},loading:"lazy"})),"\n    ")),Object(c.b)("h3",null,"Pre-requisites"),Object(c.b)("p",null,"We assume that you have an instance of Event Streams already running on IBM Cloud with at least on manager-level credentials created.  The credentials will come in the form of a JSON document as seen in the previous section.\nYou will need the ",Object(c.b)("inlineCode",{parentName:"p"},"kafka_brokers_sasl")," and ",Object(c.b)("inlineCode",{parentName:"p"},"password")," atribute to configure the sink connector."),Object(c.b)("p",null,"This scenario uses the ",Object(c.b)("inlineCode",{parentName:"p"},"inventory")," topic created in the Scenario Setup in previous section."),Object(c.b)("h3",null,"Create Local IBM MQ Instance"),Object(c.b)("p",null,"Here we will use Docker to create a local MQ instance.  First create a data directory to mount in the container."),Object(c.b)("p",null,Object(c.b)("inlineCode",{parentName:"p"},"mkdir qm1data")),Object(c.b)("p",null,"Then create the container."),Object(c.b)("pre",null,Object(c.b)("code",Object(a.a)({parentName:"pre"},{className:"language-shell"}),"docker run                     \\\n  --name mq                    \\\n  --detach                     \\\n  --publish 1414:1414          \\\n  --publish 9443:9443          \\\n  --publish 9157:9157          \\\n  --volume qm1data:/mnt/mqm    \\\n  --env LICENSE=accept         \\\n  --env MQ_QMGR_NAME=QM1       \\\n  --env MQ_APP_PASSWORD=admin  \\\n  --env MQ_ENABLE_METRICS=true \\\n  ibmcom/mq\n")),Object(c.b)("p",null,"You should be able to log into the MQ server on port 9443 with default user ",Object(c.b)("inlineCode",{parentName:"p"},"admin")," and password ",Object(c.b)("inlineCode",{parentName:"p"},"passw0rd"),"."),Object(c.b)("p",null,"Connect to the running MQ instance to create a Channel and Queue as described on the ",Object(c.b)("a",Object(a.a)({parentName:"p"},{href:"https://github.com/ibm-messaging/kafka-connect-mq-sink/blob/master/UsingMQwithKafkaConnect.md"}),"Using IBM MQ with Kafka Connect")," page."),Object(c.b)("pre",null,Object(c.b)("code",Object(a.a)({parentName:"pre"},{className:"language-shell"}),"docker exec -ti mq bash\nstrmqm QM1\nrunmqsc QM1\nDEFINE CHANNEL(KAFKA.CHANNEL) CHLTYPE(SVRCONN)\nSET CHLAUTH(KAFKA.CHANNEL) TYPE(BLOCKUSER) USERLIST('nobody')\nSET CHLAUTH('*') TYPE(ADDRESSMAP) ADDRESS('*') USERSRC(NOACCESS)\nSET CHLAUTH(KAFKA.CHANNEL) TYPE(ADDRESSMAP) ADDRESS('*') USERSRC(CHANNEL) CHCKCLNT(REQUIRED)\nALTER AUTHINFO(SYSTEM.DEFAULT.AUTHINFO.IDPWOS) AUTHTYPE(IDPWOS) ADOPTCTX(YES)\nREFRESH SECURITY TYPE(CONNAUTH)\nDEFINE QLOCAL(INVENTORY)\nSET AUTHREC OBJTYPE(QMGR) PRINCIPAL('admin') AUTHADD(CONNECT,INQ)\nSET AUTHREC PROFILE(INVENTORY) OBJTYPE(QUEUE) PRINCIPAL('admin') AUTHADD(ALLMQI)\nEND\n")),Object(c.b)("p",null,"Exit the session and continue on to create the MQ Connector Sink."),Object(c.b)("h3",null,"Create MQ Kafka Connector Sink"),Object(c.b)("p",null,"The MQ Connector Sink can be downloaded from ",Object(c.b)("a",Object(a.a)({parentName:"p"},{href:"https://github.com/ibm-messaging/kafka-connect-mq-sink"}),"Github"),".  The Github site includes exhaustive instructions and an abridged version follows."),Object(c.b)("p",null,"Clone the repository with the following command:"),Object(c.b)("p",null,Object(c.b)("inlineCode",{parentName:"p"},"git clone https://github.com/ibm-messaging/kafka-connect-mq-sink.git")),Object(c.b)("p",null,"Change directory into the kafka-connect-mq-sink directory:"),Object(c.b)("p",null,Object(c.b)("inlineCode",{parentName:"p"},"cd kafka-connect-mq-sink")),Object(c.b)("p",null,"Build the connector using Maven:"),Object(c.b)("p",null,Object(c.b)("inlineCode",{parentName:"p"},"mvn clean package")),Object(c.b)("p",null,"Next, create a directory to contain the Kafka Connector configuration."),Object(c.b)("p",null,Object(c.b)("inlineCode",{parentName:"p"},"mkdir config && cd config")),Object(c.b)("p",null,"Create a configuration file called ",Object(c.b)("inlineCode",{parentName:"p"},"connect-distributed.properties")," for Kafka Connect based on the template below."),Object(c.b)("pre",null,Object(c.b)("code",Object(a.a)({parentName:"pre"},{className:"language-properties"}),'# A list of host/port pairs to use for establishing the initial connection to the Kafka cluster.\nbootstrap.servers=broker-1- ... kafka.svc01.us-east.eventstreams.cloud.ibm.com:9093,broker-0- ... kafka.svc01.us-east.eventstreams.cloud.ibm.com:9093,broker-4- ... kafka.svc01.us-east.eventstreams.cloud.ibm.com:9093,broker-2- ... kafka.svc01.us-east.eventstreams.cloud.ibm.com:9093,broker-5- ... kafka.svc01.us-east.eventstreams.cloud.ibm.com:9093,broker-3- ... kafka.svc01.us-east.eventstreams.cloud.ibm.com:9093\nssl.enabled.protocols=TLSv1.2\nssl.protocol=TLS\nsecurity.protocol=SASL_SSL\nsasl.mechanism=PLAIN\nsasl.jaas.config=org.apache.kafka.common.security.plain.PlainLoginModule required username="token" password="bA ... Qp";\n\n# Consumer side configuration\nconsumer.bootstrap.servers=broker-1- ... kafka.svc01.us-east.eventstreams.cloud.ibm.com:9093,broker-0- ... kafka.svc01.us-east.eventstreams.cloud.ibm.com:9093,broker-4- ... kafka.svc01.us-east.eventstreams.cloud.ibm.com:9093,broker-2- ... kafka.svc01.us-east.eventstreams.cloud.ibm.com:9093,broker-5- ... kafka.svc01.us-east.eventstreams.cloud.ibm.com:9093,broker-3- ... kafka.svc01.us-east.eventstreams.cloud.ibm.com:9093\nconsumer.security.protocol=SASL_SSL\nconsumer.ssl.protocol=TLSv1.2\nconsumer.sasl.mechanism=PLAIN\nconsumer.sasl.jaas.config=org.apache.kafka.common.security.plain.PlainLoginModule required username="token" password="bA ... Qp";\n\n# Producer Side\nproducer.security.protocol=SASL_SSL\nproducer.ssl.protocol=TLSv1.2\nproducer.sasl.mechanism=PLAIN\nproducer.sasl.jaas.config=org.apache.kafka.common.security.plain.PlainLoginModule required username="token" password="bA ... Qp";\nproducer.bootstrap.servers=broker-1- ... kafka.svc01.us-east.eventstreams.cloud.ibm.com:9093,broker-0- ... kafka.svc01.us-east.eventstreams.cloud.ibm.com:9093,broker-4- ... kafka.svc01.us-east.eventstreams.cloud.ibm.com:9093,broker-2- ... kafka.svc01.us-east.eventstreams.cloud.ibm.com:9093,broker-5- ... kafka.svc01.us-east.eventstreams.cloud.ibm.com:9093,broker-3- ... kafka.svc01.us-east.eventstreams.cloud.ibm.com:9093\n\n\nplugin.path=/opt/kafka/libs\n\n# unique name for the cluster, used in forming the Connect cluster group. Note that this must not conflict with consumer group IDs\ngroup.id=mq-sink-cluster\n\n# The converters specify the format of data in Kafka and how to translate it into Connect data. Every Connect user will\n# need to configure these based on the format they want their data in when loaded from or stored into Kafka\nkey.converter=org.apache.kafka.connect.json.JsonConverter\nvalue.converter=org.apache.kafka.connect.json.JsonConverter\n# Converter-specific settings can be passed in by prefixing the Converter\'s setting with the converter we want to apply\n# it to\nkey.converter.schemas.enable=true\nvalue.converter.schemas.enable=true\n\n# Topic to use for storing offsets. T\noffset.storage.topic=connect-offsets\noffset.storage.replication.factor=3\n#offset.storage.partitions=25\n\n# Topic to use for storing connector and task configurations; note that this should be a single partition, highly replicated, and compacted topic.\nconfig.storage.topic=connect-configs\nconfig.storage.replication.factor=3\n\n# Topic to use for storing statuses. This topic can have multiple partitions and should be replicated and compacted.\nstatus.storage.topic=connect-status\nstatus.storage.replication.factor=3\nstatus.storage.partitions=5\n\n# Flush much faster than normal, which is useful for testing/debugging\noffset.flush.interval.ms=10000\n')),Object(c.b)("p",null,"Save this file in the ",Object(c.b)("inlineCode",{parentName:"p"},"config")," directory."),Object(c.b)("p",null,"Next, create a log4j configuration file named ",Object(c.b)("inlineCode",{parentName:"p"},"connect-log4j.properties")," based on the template below."),Object(c.b)("pre",null,Object(c.b)("code",Object(a.a)({parentName:"pre"},{className:"language-properties"}),"log4j.rootLogger=DEBUG, stdout\n\nlog4j.appender.stdout=org.apache.log4j.ConsoleAppender\nlog4j.appender.stdout.layout=org.apache.log4j.PatternLayout\nlog4j.appender.stdout.layout.ConversionPattern=[%d] %p %m (%c:%L)%n\n\nlog4j.logger.org.apache.kafka=INFO\n")),Object(c.b)("p",null,"Save this file to the ",Object(c.b)("inlineCode",{parentName:"p"},"config")," directory as well."),Object(c.b)("p",null,"Finally, create a JSON configuraiton file for the MQ sink.  This can be stored anywhere but it can be conveniently created in the ",Object(c.b)("inlineCode",{parentName:"p"},"config")," directory.  We name this file ",Object(c.b)("inlineCode",{parentName:"p"},"mq-sink.json"),"."),Object(c.b)("pre",null,Object(c.b)("code",Object(a.a)({parentName:"pre"},{className:"language-json"}),'{\n    "name": "mq-sink",\n    "config":\n    {\n        "connector.class": "com.ibm.eventstreams.connect.mqsink.MQSinkConnector",\n        "tasks.max": "1",\n        "topics": "inventory",\n\n        "key.converter": "org.apache.kafka.connect.storage.StringConverter",\n        "value.converter": "org.apache.kafka.connect.storage.StringConverter",\n\n        "mq.queue.manager": "QM1",\n        "mq.connection.name.list": "mq(1414)",\n        "mq.user.name": "admin",\n        "mq.password": "passw0rd",\n        "mq.user.authentication.mqcsp": true,\n        "mq.channel.name": "KAFKA.CHANNEL",\n        "mq.queue": "INVENTORY",\n        "mq.message.builder": "com.ibm.eventstreams.connect.mqsink.builders.DefaultMessageBuilder"\n    }\n}\n')),Object(c.b)("p",null,"Back out one directory to the ",Object(c.b)("inlineCode",{parentName:"p"},"kafka-connect-mq-sink")," directory."),Object(c.b)("p",null,Object(c.b)("inlineCode",{parentName:"p"},"cd ..")),Object(c.b)("p",null,"Build docker image\n",Object(c.b)("inlineCode",{parentName:"p"},"docker build -t kafkaconnect-with-mq-sink:1.3.0 .")),Object(c.b)("p",null,"Finally, run the Kafka Connect MQ Sink container."),Object(c.b)("pre",null,Object(c.b)("code",Object(a.a)({parentName:"pre"},{}),"docker run                                 \\\n  --name mq-sink                           \\\n  --detach                                 \\\n  --volume $(pwd)/config:/opt/kafka/config \\\n  --publish 8083:8083                      \\\n  --link mq:mq                             \\\n  kafkaconnect-with-mq-sink:1.3.0\n")),Object(c.b)("p",null,"You should now have a working MQ sink."),Object(c.b)("p",null,"As an alternate approach, when you have a Kafka Connect isntance up and running, with the dependant jar files, it is possible to configure the connector with a POST operation like:"),Object(c.b)("pre",null,Object(c.b)("code",Object(a.a)({parentName:"pre"},{className:"language-Shell"}),'curl -X POST -H "Content-Type: application/json" http://localhost:8083/connectors   --data "@./mq-sink.json"\n\n# The response returns the metadata about the connector\n{"name":"mq-sink","config":{"connector.class":"com.ibm.eventstreams.connect.mqsink.MQSinkConnector","tasks.max":"1","topics":"inventory","key.converter":"org.apache.kafka.connect.storage.StringConverter","value.converter":"org.apache.kafka.connect.storage.StringConverter","mq.queue.manager":"QM1","mq.connection.name.list":"ibmmq(1414)","mq.user.name":"admin","mq.password":"passw0rd","mq.user.authentication.mqcsp":"true","mq.channel.name":"KAFKA.CHANNEL","mq.queue":"INVENTORY","mq.message.builder":"com.ibm.eventstreams.connect.mqsink.builders.DefaultMessageBuilder","name":"mq-sink"},"tasks":[{"connector":"mq-sink","task":0}],"type":"sink"}\n')),Object(c.b)("p",null,"Once the connector is up and running, we can use some tool to send inventory message. In the ",Object(c.b)("inlineCode",{parentName:"p"},"integration-tests")," folder we have some python code to produce message. If you have a python environment with kafka api you can use yours, or we have also provided a Dockerfile to prepare a local python environment, which will not impact yours."),Object(c.b)("pre",null,Object(c.b)("code",Object(a.a)({parentName:"pre"},{className:"language-shell"}),"# if you change the name of the image\ndocker build -t ibmcase/python37 .\n# ... then update the script ./startPython.sh\n./startPython.sh\n# Now in the new bash session you should see ProduceInventoryEvent.py,... start it by sending 2 events\npython ProduceInventoryEvent.py --size 2\n# Events are random but use stores and items known by the database downstream.\n sending -> {'storeName': 'NYC01', 'itemCode': 'IT06', 'quantity': 15, 'price': 163, 'id': 1, 'timestamp': '23-Jun-2020 04:32:38'}\n# the following trace demonstrates Kafka received the message\n[KafkaProducer] - Message delivered to inventory [0]\nsending -> {'storeName': 'SC01', 'itemCode': 'IT06', 'quantity': 15, 'price': 178, 'id': 2, 'timestamp': '23-Jun-2020 04:32:38'}\n[KafkaProducer] - Message delivered to inventory [0]\n")),Object(c.b)("p",null,"In the Kafka Connect trace we can see:"),Object(c.b)("pre",null,Object(c.b)("code",Object(a.a)({parentName:"pre"},{className:"language-shell"}),"kconnect_1  | [2020-06-23 04:23:16,270] INFO WorkerSinkTask{id=mq-sink-0} Committing offsets asynchronously using sequence number 26: {inventory-0=OffsetAndMetadata{offset=44, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)\nkconnect_1  | [2020-06-23 04:32:46,382] INFO WorkerSinkTask{id=mq-sink-0} Committing offsets asynchronously using sequence number 83: {inventory-0=OffsetAndMetadata{offset=48, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)\n")),Object(c.b)("p",null,"And in the IBM MQ Console, under the Local Queue: Inventory we can see the messages:"),Object(c.b)("span",{className:"gatsby-resp-image-wrapper",style:{position:"relative",display:"block",marginLeft:"auto",marginRight:"auto",maxWidth:"1152px"}},"\n      ",Object(c.b)("span",Object(a.a)({parentName:"span"},{className:"gatsby-resp-image-background-image",style:{paddingBottom:"43.75%",position:"relative",bottom:"0",left:"0",backgroundImage:"url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAJCAYAAAAywQxIAAAACXBIWXMAAAsSAAALEgHS3X78AAABJklEQVQoz52STW6EMAyFc/WepifoBbqv1N0sK0BAANGZAPlPeLUzhUWlkdouPoU4trGfLYbxE33fY55njONYzn3f/41Y1wXLcscYA2stUkp/IsYEHxLFOohhGCClxO12o4dYCCH8Gu8DkAnQtzMQxmis61oquzv4HwH+IY7IyeNDBry8JbQTJazrBtM0oaoqtG1b9Oy6Dk3ToK5rcAePkHLAdZZ4fR/x9HzFpVogrspCG0caKiiloLUuWnLVfD/0ZdjGnDZ6N8ZSy55atvB2g1AacCQBt85O3CYLzRJw8LZtJ/wz5rizf0oRO6WLGVQYtawdaEIZztnizAl5MM65s9rjPLbgsHFS9uV1yTkXu1BqLZPiCyfhB+a+DvHBmsSTMpzvOM7xBcMFuQhTD0V4AAAAAElFTkSuQmCC')",backgroundSize:"cover",display:"block"}})),"\n  ",Object(c.b)("img",Object(a.a)({parentName:"span"},{className:"gatsby-resp-image-image",alt:"ibmq q inventory",title:"ibmq q inventory",src:"/refarch-eda/static/447c1faaa01eaff3324f6362e0215573/3cbba/ibmq-q-inventory.png",srcSet:["/refarch-eda/static/447c1faaa01eaff3324f6362e0215573/7fc1e/ibmq-q-inventory.png 288w","/refarch-eda/static/447c1faaa01eaff3324f6362e0215573/a5df1/ibmq-q-inventory.png 576w","/refarch-eda/static/447c1faaa01eaff3324f6362e0215573/3cbba/ibmq-q-inventory.png 1152w","/refarch-eda/static/447c1faaa01eaff3324f6362e0215573/e1971/ibmq-q-inventory.png 1256w"],sizes:"(max-width: 1152px) 100vw, 1152px",style:{width:"100%",height:"100%",margin:"0",verticalAlign:"middle",position:"absolute",top:"0",left:"0"},loading:"lazy"})),"\n    "),Object(c.b)("p",null,"To remove the connector do the following command. Do this specially if you go to scenario 2 next."),Object(c.b)("pre",null,Object(c.b)("code",Object(a.a)({parentName:"pre"},{className:"language-shell"}),"curl -X DELETE http://localhost:8083/connectors/mq-sink\n")))}u.isMDXComponent=!0}}]);
//# sourceMappingURL=component---src-pages-use-cases-connect-mq-index-mdx-7b1ff347c22f9e70ff20.js.map